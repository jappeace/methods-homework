\documentclass{article}
\usepackage{txfonts}
\usepackage{booktabs}
\usepackage{color}
\usepackage{bussproofs}
\usepackage{graphicx}
\usepackage{pifont}
\usepackage{qtree}
\usepackage{tikz}
\usepackage{listings}
\usepackage{hyperref}
\newenvironment{scprooftree}[1]%
{\gdef\scalefactor{#1}\begin{center}\proofSkipAmount \leavevmode}%
{\scalebox{\scalefactor}{\DisplayProof}\proofSkipAmount \end{center} }


\newcommand{\brcell}[2][l]{%
	\begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}
\begin{document}
\author{Jappie Klooster}
\title{Evolutionary stretegies}
\maketitle

\section{difference from GA}
GA's are local searches, while ES are global searches.
\section{Comenly used settings}
Coveriance = the angle, no coveriance means semetrical

The closer to the optimum the smaller your variance should be. This reduces
the chance of jumping over the optimum.

Normally distributed = gausian

\section{mutation}

\section{reccombination}
the parents is the entire population

\section{selection}
 methods $(u,\lambda)$ and $(u+\lambda)$, $(u+\lambda)$ appears better from
 an optimization standpoint but self adoptation works worse with this one.

feet4, each edge = a weight, every neuron is a function.

\section{Combinatorial}
is a finite set of solutions and you have to optimize it.

\subsection{Local search}
always try to improve the current solution by applying small changes.

Meta heuristics, for example taboo list


\section{Second practical}

MLS, ILS and GLS for graph Bipartioning.

the easiest thing to do is how long and see on waht
percentage they from the total??


Graph biportitioning, cut the graph into 2 groups
of 250

if the hamming distance is bigger than 2, just take
the complement of the 2?

\section{Knapsack}
Adaptive pursuit, pick one random with probability x, change
probability while running.

\section{Adaptive pursuit}
probability matching is used most often in literature, but its not
really that good.

Markov!

\subsection{Strategy}
the learning pase is a prarameter you have to play with.

\end{document}
