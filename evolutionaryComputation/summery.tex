\documentclass[8pt,landscape]{extarticle}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{color,graphicx,overpic}
\usepackage{hyperref}


\pdfinfo{
  /Title (EC cheatsheet)
  /Creator (TeX)
  /Producer (pdfTeX 1.40.0)
  /Author (Jappie Klooster)
  /Subject (Evulotionary computing)
  /Keywords (Evolutionary, Computing, Gentic, Algorithm, Heuristics, Strategy)}

% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
    {\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
        {\geometry{top=0.5cm,left=0.5cm,right=0.5cm,bottom=0.5cm} }
        {\geometry{top=0.5cm,left=0.5cm,right=0.5cm,bottom=0.5cm} }
    }

% Turn off header and footer
\pagestyle{empty}

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-0.8ex plus -.5ex minus -.2ex}%
                                {0.2ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-0ex plus -.5ex minus -.2ex}%
                                {0.1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}

%My Environments
\newtheorem{example}[section]{Example}
% -----------------------------------------------------------------------

\begin{document}
\raggedright
\footnotesize
\begin{multicols}{4}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\begin{center}
     \Large{\underline{Evolutionary Computing}} \\
\end{center}

\section{Genetic algorithms}
Darwinian system $\Rightarrow$ GA: 
Information structures $\Rightarrow$ binary strings, real-valued vectors,
programs etc. Structures are copied $\Rightarrow$ Selection algorithm.
Copies partially vary from original $\Rightarrow$ mutation \& crosover
operators. Structures are competing for a limited resource $\Rightarrow$
selecting fixed size parent pool. Reproductive succes depends on env
$\Rightarrow$ user defined fitness function.
\subsection{Schema}
$o(h)$: schema order $o(11\#\#0)$ ie nonwildcard \# elements.
$\delta(h)$: schema defining length, maximum distance between two defining
symbols. $m(h,t)$: number of schema h instances at generation t.
$f(h,t)=\sum_{i\in P}f_i$ schema fitness is average fitness of members.

\emph{Buidling blocks} low order high performance schemate receive exponentiaonally
(geometrically) increasing trials. ie there exists some schemas that when combined
will produce a near optimal solution, the building blocks.

\subsubsection{Growth by selection}
reproduction ratio $\phi(h,t)=\frac{m(h,t^s)}{m(h,t)}$.

\emph{Proportionate selection}
$f_i$ fitness ind i. Probability individiual i selected: $\frac{f_i}{\sum f_i}$.
$N$ pop size. Expected number of copies
$\frac{f_i}{\sum f_i} \cdot N = \frac{f_i}{f(t)}$.
Expected number of copies of schema $h$ members:
$m(h,t^s) = m(h,t)\phi(h,t)=m(h,t)\frac{f(h,t)}{f(t)}$.

\emph{Tournament selction}
tournament size $s: 0 \leq \phi(h,t) \leq s$.

\subsubsection{Distruption by mutation}
probability bit flipped: $p_m$.
schema $h$ survives iff all the bit values are \emph{not} mutated
$p_{survival}=(1-P_m)^{o(h)}$. for small values $p_m << 1$,
$(1-p_m)^{o(h)}\approx 1 - o(h)\cdot p_m$.
disruption factor $\epsilon(h,t)$ by mutation: $\epsilon(h,t)=o(h)\cdot P_m$.

\subsubsection{Distruption by recombination}
Probablity crossover applied $P_c$. Bit swap probability: $p_x$.

\emph{1-point crossover} schema $h$ survives iff cutpoint \emph{not}
withing defining length $\delta$: $p_{survival} = 1-\frac{\delta(h,t)}{l-1}$

\emph{Uniform crossover} Schema $h$ survives iff none or all bits
swapped together. $p_{survival}=p^{o(h)}_x + (1-p_x)^{o(h)}$.

\emph{Distruption factor} $\epsilon(h,t)$ by recombination:
$\epsilon(h,t)=P_c\cdot(1-p_{survival})$

\subsubsection{Theorem}
Selection mutation and recombination combined:
$m(h,t+1)\leq m(h,t)\phi(h,t)[1-\epsilon(h,t)]$.
Net growth factor: $\gamma(h,t)=\frac{m(h,t+1)}{m(h,t)}$.
\subsection{Permutation problems}
2-opt m, select 2 points and reverse a subsequance.
adjacency of elements is important, 2-opt has minimal change.
relative ordering is important: 2-opt large change.
\subsubsection{Crossover}
std. crosover won't work cause they can make invalid solution.
ie : $abcd+CBDA\to Cbcd$. Order crossover: rnd select 2 points,
copy subseq between crosspoints from p1, starting at 2nd crosspoint
fill in missing elements retaining order from p2. partially
mapped crosover: rnd select 2 points, copy p2 to child, copy
elements between crospoint from p1 to childe while placing
the replaced element from p2 at the location where the replacer is.
Position crossover: rnd select k postitions, copy unmarked elements from
p1 to child, scan p2 from lft to rght and fill in missing elemnts. Max 
preservative cross: rnd select two points, copy subseq between crospoints
from p1, add succesivily an adjecent element from p2 starting at
last element in child, if already placed take and adjecent elemnt form
p1. Cycle crossover: mark cycles, cross full cycles.

\subsection{Fitness Correlation coefficents}
Genetic operators should perserve usefull fitness characaristics.
Calcualte the fitness coorlation coeficient to quantify this.
$F_p$: mean fitness of the parents. $F_c$: mean fitness of the children.
$\sigma(F_p) =$ standard deviation of fitness parents
$\sigma(F_c) =$ std. dev. of children. coveriance fitness between parents and children:
$cov(F_p,F_c)=\sum^n_{i=1}\frac{(f(p_{gi})-F_p)(f(c_{gi})-f_c)}{n}$.
Operator fitness correlation coeficient
$\rho_{op}=\frac{cov(F_p,F_c)}{sigma(F_p)\sigma(F_c)}$.

\section{Metaheursitics}
Crossover can have mutliple search biases:
1. Random sampling witin a specific subspace. 2. place together for contrast
partial solutions from two parent solutions.

\subsection{PBMS}
Probablistic Modal Building: Probability distributions model dependencies 
between variables present in good solutions. sSelection makes these fitness 
based dependencies stand out. Estimating a probablity modal over the selected
solutions identifies these dependencies. Drawing new samples form the probability
modal will respect the dependencies.
PMBLS = PBM + LS. Bivariate probalbistic modal learns the pairwise dependencies
between problem dependencies. Buildign a dependency tree=maximum spanning tree
over the dependency graph. New solutions obtained by sampling from the dependency
tree.
For graphbipartitioning. Probablistic model: count the frequnceis that two
verticies are in the same parition. Dep tree build over most extreme frequency
values. reduce computational complexity by only considering the
pairwise interactions between connected vertices
\section{ES representation}
Fitness function: $f(x_1,\dots,x_n):\mathbb{R}^n\to \mathbb{R}$.
Genotype representation of an individual solution:
$(x_1,\dots,x_n,\sigma^2_1,\dots,\sigma^2_n, c_{12},\dots,c_{n-1,n})$,
paremeters $(x_1, \dots,x_n)$ need to be optimized.
Individiual solution consists of 3 parts: $\vec{x}$: problem vairables
$\Rightarrow$ Fitness $f(\vec{x})$. $\vec{sigma}$: standard deviations
$\Rightarrow$ variances. $\vec{\alpha}$: rotation angles $\Rightarrow$
covariances. The $n$-dimensional normal probability density function:
$p(X=x_1,\dots,x_n)=\frac{exp(-\frac{1}{2}X^TC^{-1}X)}{\sqrt{(2\pi)^n|C|}}$.
$C$: correlation matrix ($c_{ij}$; $|C|$ determinant $\Rightarrow$ rotation 
angles $\alpha_{ij}$: tan $2\alpha_{ij}=2c_{ij}/(\sigma^2_i-\sigma^2_j)$.
1-dimensional gaussian function:
$f(x)=\frac{1}{\sqrt{2\pi \sigma^2}}exp\frac{(x-\mu)^2}{2\sigma^2}$
\subsection{Mutation}
Complete covairance matrix: $\sigma_1,\dots,\sigma_n$; $c_{ij}\neq 0 (i\neq j)$.
The strategy paremeters are mutated:
$\sigma'_i=\sigma_ie^{
	\frac{\mathbb{N}(0,1)}{\sqrt{2n}}+
	\frac{\mathbb{N}_i(0,1)}{\sqrt{2\sqrt{n}}}
}$
$\alpha'_j=\alpha_j+\beta\mathbb{N}_j(0,1)$.
$\beta = 5$ degree in radians. $\mathbb{N}(0,1)$: standard normal
distribution. Then the problem paremeters are mutated with the new
strategy: $\vec{x}'=\vec{x}+\vec{N}(\vec{0},\vec{\sigma},\vec{\alpha}')$.
$\vec{N}$: n-dimensional normal distribution.
Often this is simplified by not doing angles or even just having a single
standard deviation (ie no index at $\sigma$ and nothing after the + 
in the power $e$).
\subsection{Recombination}
create one offspring from several parents selected randomly. Problem parameters
are averaged. The std devation is selected from one of the parents. Rotation
angles are not recombined
\subsection{Selection}
ES applies a high selection pressure: from $\mu$ parents $\lambda$ offspring
are generated with $\lambda >> \mu$ (~5 to 10 times). The best $\mu$ solutions
of the $\lambda$ offspring are selected, (or from both offspring and parents,
but experiments show just offspring has better selfadaptation).
\section{Ada pursuit}
Given: Set of $K$ \emph{operators} $A=\{a_1,\dots,a_k\}$. 
\emph{Probability vector} $P(t) = \{P_1(t),\dots,P_k(t)\}$. operator $a_i$ 
applied at time t in proportion to probability $P_i(t)$. env. returns rewards
$R_i(t) \geq 0$. Goal: Adapt $P(t)$ so that expected value of cumalitive
reward $\varepsilon[R]=\sum^T_{t=1}R_i(t)$ is maximized.

\subsection{Probabilty matching}
update $P(t)$ so probability of applying operator $a_i$ matches
the proportion of the estimated reward $Q_i(t)$ to the sum of all reward 
estimates $\sum^K_{a=1} Q_a(t)$
\subsubsection{PM: Reward estimate}
compute an estimate of the rewards, and older rewards should be less
influantial in non-stationary envs:
$Q_a(t+1)=Q_a(t)+\alpha[R_a(t)-Q_a(t)]$

\subsubsection{PM: Probability adaptation}
In non-stationary envs the probabilty of applying
any operator should never be less than some minmal \emph{thershold} $P_{min} > 0$.
For $K$ operators maximal probablity $P_{max} = 1-(K-1)P_{min}$. updating rule
for $P(t)$: $P_a(t+1)=P_{min}+(1-K\cdot P_{min})\frac{Q_a(t)}{\sum^K_{i=1}Q_i(t)}$.
\subsubsection{PM: Problem}
If one operator is consistently better probablity will still converge to average.

\subsection{Adaptive Pursuit strategy}
Update $P(t)$ so \emph{operator} $a^*$ that currently has the max estimated
reward $Q_{a^*}(t)$ is \emph{persued}. To achieve this the pursuit method
\emph{increases} selection probability $P_{a^*}$ and decreases all other
probabilities $P_a(t),\forall a\neq a^*$. So here it can deal with non-static envs.
\subsubsection{APS: Adaptive method}
Similiar to probability matching:
$Q_a(t+1)=Q_a(t)+\alpha[R_a(t)-Q_a(t)]$. Different from probablity matching:
Selection probability $P(t)$ is adapted in a greedy way.
\subsubsection{APS: Probability adoptation}
The selection probability of the current best operator
$a^*=argmax_a[Q_a(t+1)]$ is \emph{increased} $(0<\beta<1)$:
$P_{a^*}(t+1)=P_{a^*}(t)+\beta[P_{max}-P_{a^*}(t)]$.
The others are \emph{decreased}: 
$\forall a\neq a^*: P_a(t+1)=P_a(t)+\beta[P_{min}-P_a(t)]$

%TODO: the psuedo code??

\section{Convergence models}
Number of fitness function evaluations is proportional to the
number of generations run and pop size $FitFunc.count = Gen.count * Popsize$.
Selection algorithm and variation operators can be ignored.

\emph{Convergence speed:}
High selection presure is faster covnergence. Bigger popsize give better solutions.
Minimal fitness function evals is a tradeoff between selection presure and popsize.
\subsection{Selection Intensity}
Quantifies the speed of convergence. $I$ selection intensity. Response to
selection $R(t)$ is difference between mean fitness of generation $t+1$ and fitness
of generation $t$. Selection differential $S(t)$ is the diff between parent pop
at generation $t$ and mean fitness of generation $t$. 
$S(t)=\overline{f(t^s)}-\overline{f(t)}$. Assuming the pop fitness is normally
distributed $N(\overline(f),\sigma^2)$ we can scale the selection differential
by thestandard deiation $\sigma(t)$. This scaled selection differential is 
called selection intensity $I(t)$. This is a dimensionless number since 
the std deiation has the same units as the selection response:
$I(t)=\frac{S(t)}{\sigma(t)}=\frac{\overline{f(t^s)}-\overline{f(t)}}{\sigma(t)}$.
Standerdizing the normal distribution $(\overline(f)=0,\sigma=1)$ shows that
selection intensity $I$ is simply the epected average fitness
of the population after applying the selection scheme to a population
with standardized normal distibuted fitness $(N(0,1))$.
The relation between the response to selection $R$ and the selection
differential $S$ is given by the heritability $h^2$: $R(t)=h^2S(t)$ or
$R(t)=h^2\sigma(t)I(t)$.

\subsection{Proportionate selection}
$P_i(t)$ the proportion of occurences of individual $i$ at generation $t$.
$i$ has fitness $f_i$ and the mean fitness of generation $t$ is $\overline{f(t)}$.
$P_i(t^s)$ the proportion of individual $i$ in the parent pool
after applying proportionate selection: $P_(t^s)=P_i(t)\frac{f_i}{\overline{f(t)}}$.
The selection differential of proportiaonate selection is: 
$S(t)=\overline{f(t^s)}-\overline{f(t)}=\frac{\sigma^2(t)}{\overline{f(t)}}$
The selection intensity $I(t)=\frac{S(t)}{\sigma(t)}$ is tus eaual
to the ratio of the std devation of the fitness and the pop mean fitness:
$I(t)=\frac{\sigma(t)}{\overline{f(t)}}$

\subsection{Rank based selection}
Proporitionate selection has not a constant selection pressure.

\section{Population sizing}
Selection viewed as descision making proscess withing partitions:
schama competition. When best schema looses comptetition we have a 
selection descision error. The amount of decision errors that
can be afforded at a given pop size can be explained by random walks.
\subsection{Selection error}
Probablity selection error is equal to the probablity that the best schema is represented
by a string with fitness less than the representative worst schema. wich is also equal
to the probability that the fitness difference is nagative.
%TODO: add fancy pants maths.

\subsection{Random walks}
One dim space of size $N + 1$. A particle in above
space in postition $x\in \{0,\dots,N\}$. The particle can move
left with probability $p$ and right with probability $1-p$.
when the particle reaches the boundries the walk ends.
$P_N(x)$ the probability that the particle is absorbed
by boundry $N$. When it currently is at pos $x$.
Diff equation:
$P_N(x)=pP_N(x+1)+(1-p)P_N(x-1)$

\subsection{Population sizing \& gambler's ruin}
The number of optimal bit values `1' in the population at a certain
position. - this is, for the partition considered - corresponds
to the position $x$ in the gambler's ruin model.
The boundries correspond to all bit vlaues in the population being
equal to a bit value. WHen the boudaries are reached the random walk
ends. The proba bility that the amount of optoimal string values in the
population at the partition is increased by one is equal to the probability
that the selection decision making is correct for that partition. This
corresponds to the probability that the particle moves to the right(p).
Desired convergence corresponds to the particle reaching the $x=N$ boundary.
Premature convergence - this is, loosing the optimal bit value in the
population - correspons the the particle reaching the $x=0$ boundary.
$P[OptConv]=\frac{1-(\frac{P[SellErr]}{1-P[SellErr]})^{N/2}}{1-(\frac{P[SellErr]}{1-P[SellErr]})^N}
\approx 1-(\frac{\sqrt{\pi l}-2}{\sqrt{\pi l}+2})^{N/2}$
Critical pop size: $N \approx ln(1-P[OptConv]\frac{\sqrt{pi l}}{-2}$

\section{Multi objective EA's}
\subsection{Pareto}
\emph{Dominance} A solution $x^0$ is said to (Paretor) \emph{dominate} a
solution $x^1$ (denoted $x^0\succ x^1$) iff
$(\forall i \in \{0,1,\dots,m-1\}:f_i(x^0)\leq f_i(x^1))\wedge
 (\exists i \in \{0,1,\dots,m-1\}:f_i(x^0)< f_i(x^1))$.
A solution is pareto optimal iff $\neg\exists x^1:x^1\succ x^0$.
The parote optimall set: $P_s=\{x^0|\neg\exists x^1:x^1\succ x^0\}$.
The paroto optimal front is the $P_f$ of all objective function values
correspoinding to the solutions in $P_s$: $P_F=\{f(x)=(f_0(x),f_1(x),\dots,
	f_{m-1}(x))|x\in P_s$
\subsection{Weighted aggregation}
The graphs with the linerider lines. It doesn't work with bowl
like objectives because only the edges are found.
\subsection{Multi-objective Optimization}
Desired result: representative subset of $P_s$.
\emph{Domination count}
For each solution count how many times
its dominatad. Then use one-dimensional selection (truncate or tournament).
\emph{Domination rank} solutions of rank 0 have domination count 0, solutions
of rank i are solutions of rank 0 when solutions of lower ranks are disregarded.

\subsection{Elitism}
What if number of rank 0 solutions is bigger than the next generation?
Must diregard some of the rank 0 solutions. The space dominated by
elitist solutions changes, this can cause the elitist solutions/front to
become \emph{worse}. This isn't true eltism!
For this reason an elitistarchive is often used. Current best solutions
are stored in the archive if they dominate at least one solution in the
archive or if they are not dominated by any solution in the archive.
Dominated solutions are removed from the archive. It can grow exponentially
large. Pruning the archive causes the same problems again. One solution:
discretize objective space, store at most one solution per
discretization box. Typically for better convergence also select
solutions from archive.
\subsection{Performance indicators}
Performance indicator is a function: Input approximation set, output: single
value representing a certaing goodnes. However no single or combination of
performance indiciators taht compare approximation sets can always tell wether
one approximation set is better than another.

\section{Model EAs: Est. dist. algorithms}
Model based evolutionary algorthms: Population based stochastic search
algorithms. Exploitation: selection, Exploration: Learn model from selected
solutions, generate new solutions from the model (\&pop).
\subsection{Univariate PMBGA}
No statistical interaction between variables considered.
Model: probability vector $[p_1,\dots,P_l]$($l$:string length).
$p_i$: probability of value 1 at string position $i$.
$p(x)=\Pi^l_{i=1}p(x_i) \quad$ ($p(x_i)$: univariate marginal distribution).
Learn modal: count proportions of 1 in selected population. Sample model:
Generate new solutions with specified probabilities.

%TODO: lack of space remove variants
\subsubsection{Variants}
PBIL: Prob. vector incrementally updated over successive generations.
UMDA: No incremental updates. Compact GA: Models steady-state GA with
tournament selection. DEUM: Uses markov random field modeling.

\subsection{Bivariate PMBGA}
Need more than just probabilities of bit values, model pairwise interactions:
conditional probablities.

\subsubsection{Ntropy}
Random variable $X$ with probability istrubtion function $p(X)$. Entropy
$H(X$ is a measure of unceartainty about a random variable $X$:
$H(X) =\sum_{x\in X}-p(x)\mbox{log }p(x)$. Conditionaly entropy $H(Y|X)$ is
a measure of uncertainty remianing about $Y$ after $X$ is known (what $X$
does not say about $Y$):
$H(Y|X) =\sum\limits_{x\in X}\sum\limits_{y\in Y}p(x,y)\mbox{log }
\frac{p(x)}{p(x,y)}$. The mutual information $I(X,Y)$ of two random variables
is a measure of the variables' mutual dependence. Mutual information determines
how similiar the joint distribution $P(X,Y)$ is to the products of factored
marginal distribution $p(X)p(Y)$:
$I(Y,X) =\sum\limits_{x\in X}\sum\limits_{y\in Y}p(x,y)\mbox{log }
\frac{p(x,y)}{p(x)p(y)}$. Mutual information in relation to Ntropy:
$I(X,Y) = H(Y)-H(Y|X)=H(X)+H(Y)-H(X,Y)$.

\subsubsection{COMIT}
Optimal dependency tree. Compute fully connected weighted graph between problem
variables. Weights are the mutual infromation $I(X,Y)$ between the variables.
Commit computes the maximam spanning treee of the weighted graph. The approximating
probability model is restricted to factorization in which the conditional
probabilty distribtuion for any random vraiable depends on the value of at
most one other random variable
$p(x)=\overset{n}{\underset{i=1}{\Pi}}p(X_i|X_{parent(i)})$.
$p(X)$ is the class of distubtions with a tree as graphical model.
The optimal tree model: Create a fully connected weighed graph $G$,
each vertix $V_i$ corresponds to randome variable $X_i$ each weight $W_{ij}$
for the edge betweeen $V_i$ and $V_j$ is equal to the mutal information
$I(X_i, X_j)$. The edges in the maximum spanning tree of $G$ determine an
optimal set $n-1$ conditional probabilites with which to aproximate the joint
probability distribution. Note that all ordered trees conforming the unorderd
spanning tree model identical distributions.
\emph{Algorithm} Calculate unconditional and conditinoal probabilties
$p(X_i)$ and $p(X_i,X_j)$, and the mutual information $I(X_i,X_j)$.
Select arbitrary random variable $X_r$ as root of the tree. Finda the
pair of variables $X_{in}$ and $X_{out}$ where $X_{in}$ is already in the
tree and $X_{out}$ is not, with the maximum mutual information
$I(X_{in}, X_{out})$. Add $X_{out}$ to the tree with $X_{in}$ as parent,
reapeat untill all variables are in the tree.

\subsection{Multivariate PMBGA}
MDL is a measure of complexity (Information Theroy).
$MDL(M,D)=D_{Model}+D_{Data}$ Model complexity $D_{Model}$:
complexity of describing the model. Compressed population complexity
$D_{Data}$: complexity of describing the data within the model (=measure
of goodness of the probability distribution estimation).
Best model = the one with the lowest MDL score.
$D_{Model}=log_2(N+1)\sum_i(2^{s_i}-1)$. Compressed pop complexity
$D_{Data}=N\sum_i H(M_i)$. $N$ pop size. $S_i$ size of partition $i$.
$M_i$ marginal distribution of the partition $i$. $H(M_i)$ entropy of the
marginal distribution of the partition i.

\subsubsection{Extended compact GA}
Greedily searches for the marginal product model that minzimizes the MDL.
$p(X)=\Pi^G_{g=1}p(x_g)$ Choose the probability distribution with the lowest
MDL score. Start from the simplest model: the univariate factorization.
Join two grousp that result in the largest improvemnt in the used scoring
measure. Stop when no jioning of two groups impvoes the score further.
\section{Model EAs: Linkage Tree GA}
Identify groups of problem variables that together make an important
contribution to the quality of solutions.
These variable groups are interacting in a non-linear way and should
be processed as a block = \emph{building block} the dependency struct
is a set of subsets of the problem.
\subsection{Family of subsets (dep struct)}
Let there be $l$ problem vars $x_0,\dots,x_{l-1}$. Let $S$ be a set of all
variable indecies $\{0,\dots,l-1\}$. A FOS $F$ is a set of subsets of the
set $S$. FOS $F$ i a subset of the powerset of $S(F\subseteq P(S))$.
FOS can be written more specifically as $F=\{F^0,\dots,F^{|F|-1}\}$. where
$F^i \subseteq \{0,\dots,l-1\}, i\in\{0,\dots,|F|-1\}$. Every var is
in at least one subset in the FOS: $\forall i \in \{0,\dots,l-1\}:(
\exists j \in \{0,\dots,|F|-1\}:i\in F^j)$.
\subsection{Linkage tree learning}
start from univariate structure (ie all vars in independent sets). Build
linkage tree using bottum-up hierarchial clustering algortim.
Similiartiy measuer: Between individual vairables X and Y: Mutual
informaiton I(X,Y).  Between clusture groups $X_{F^i}$ and $X_{F^j}$:
average pairwise linkage clustering (=unweighted pair group method
with arithmic mean).
$I^{UPGMA}(X_{F^i}, X_{F^j} = \frac{1}{|X_{F^i}||X_{F^j}|}
\sum\limits_{X\in X_{F^i}}\sum\limits_{Y\in X_{F^i}} I(X,Y)$
\subsubsection{Reciprocal nearest neighbor chain clustering}
Construct a nearsest neighbor chian: start from an arbitrary
start cluster which is followed by its nearest neigbro, which
again is followed by its nearest neigbor from among the remaining
points and so on.
When the nearest neigbor for the last chain element $n$ is the elements
$n-1$ we stop with the generation with the NNchan, we have found
a $RNN$ pair and can agglomerate it.
The nearest neigbor assignment stay valid for the remaining chain members,
which can thus be reused for the next iteration of agglomeration. If
we do not find any more RNN pairs in the remaining NN chain we create a new one
starting from a random start point.
\subsection{Optimal Mixing Evolutionary Algorhms}
OMEA is a model building EA that uses a FOS as its linkage model.
It uses intermediate function evalutations (inside variation).
Can be regarded as greedy improvment of exisiting solutions.
Coined ``optimal'' mixing because better instances for substructures
are imediatly accepted and not dependent on noise coming form other parts
of te solution.
\subsection{GOMEA}
FOS liknage models to specify the linked vars. A subset of the fos is used
as crosover mask. Crosover is greedy: only improvments (or equal) are accepted.
Each generation a new FOS model is build from selected solutions. For each solution
in the population all subsets of the FOS are treid with a donor solution
randomly picked fro mthe population. Recombainative OM is GA-like: select single
donor solution to perform OM with. GOM is EDA-like: select donor solution for each
subset in OM.
\subsection{Linkage Tree genetic algorithm.}
The LTGA is an instance of GOMEA that uses a linkage tree as fos model. Each
generation a new hierechial cluster tree is build. For each solution in
population, traverse tree starting at the top. Node (=clusters) in the linkage
tree used as crosover masks. Select random donor solution and its values at
the crossover mask replace the variable values from the current solution.
Evaluate new solution and accept if better/equal, otherwise reject.
\section{Seminars}
\subsection{ILS for Qaudratic assignment problem}
Population based extension work by replacing the worst. Using evolution
strategies. and don't do recombination?
\subsection{GA with ILS for solving location routing}
Assignment Configuration $A(x)$: location. Permutation vector $P(x)$: routing.
\emph{crossover} $A(x)$ one point cross. $P(x)$ focus on relative ordering.
\subsection{GASAT}
\emph{Corrective clause crossover} set all the bits of the child to undefined.
Go over all false clauses of both parents (and child), find the best to flip,
keep the sum of parents' fitness the lowest, flip this bit in the child.
End step: all undefined bits of the child are uniformly crossed over.
\emph{Corrective clause and truth maintance crossover} Obvious problem
with CC: Child may make clause false that is true for both parents. A possible
olution: CCTM. DO CC except for end step. Go over all clauses that are true
for parents, false for child. Look at the bits of the clause but only those
different from the child and at least one parent. Find the best bit to flip,
keep the sum of the parents' fitness the lowest. Flip this bit in the cild.
End step of CC.
\emph{Fleuent and ferland's crossover} Go over all clauses true for one parent
and false for another. Copy all of the former's bits for that clause. End
step of CC.
\emph{Also uniform crossover} copy a bit of x or y with equal probablity.
\subsection{Fitness landscapes in graphbitpart}
Researh suggest that the optimal soution is often found near the
center of local-optimum space. Thus a good idea for a search
tactic is to find a way to get near this center and use a lcoal
optimization function to try and get near the global optimum.
\subsection{Solving bus terminal problems}
Standar rollete wheel with linear ranking is assigning fitness to
possible solutions. The higher the fitness the more chance of being
selected.
\subsection{GLS w. dist preserv recombo}
Order crossover (see earlier). single parent cross, select with probability 0.5
from the parent for customers not inserted pick one at random and insert at the
best position. Convert into chromosone.
String cross
\end{multicols}
\end{document}
