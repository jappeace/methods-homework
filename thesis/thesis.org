#+TITLE: Composable personality parts
#+SUBTITLE: Jungian types as endomorphisms in dialogue
# A serious communication game with personalities
#+LANGUAGE: en

# TODO: this title is to vague
# Jungian functions as endomorphisms:
  # Personality for dialogue agents
# Pure functional serious communication in-game
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper,drafting]

# disable toc so it doesn't appear at the top but where we want it instead
#+Options: toc:nil ^:nil 

# we have our own title
#+Options: title:nil

# we don't want numbering to appear in front of headings untill
#+OPTIONS: H:5

# table alternating colors
#+LATEX_HEADER: \usepackage[table,fancyvrb]{xcolor}

# bibtex stuff
#+LATEX_HEADER: \usepackage[square,sort,comma,numbers]{natbib}
#+LATEX_HEADER: \renewcommand{\bibsection}{}

# todo notes
#+LATEX_HEADER: \usepackage[obeyFinal, colorinlistoftodos]{todonotes}
#+LATEX_HEADER: \newcommand{\ask}[1]{\todo[color=cyan]{#1}}
#+LATEX_HEADER: \newcommand{\drafting}{\todo[noline, color=gray]{Working draft}}
#+LATEX_HEADER: \newcommand{\toReview}{\todo[noline, color=yellow]{To review}}
#+LATEX_HEADER: \newcommand{\newlyCleared}{\todo[noline, backgroundcolor=white, bordercolor=red]{Newly cleared}}
# (something cleared that was under discussion last time)
#+LATEX_HEADER: \newcommand{\cleared}{\todo[noline, color=white]{Cleared}}

# alternating table rows
#+LATEX: \rowcolors{1}{white}{gray!15}

# Title page
#+LATEX: \input{title}

# The order of this thesis will be done in a way to let future researcher
# decide the value of the thesis quickly
# 1. First the abstract to let a researcher quickly discard this thesis if necessary.
# 2. The toc, to let a researcher jump to interesting pages quickly.
# 3. The introduction and main body of the thesis. If all else fails a
# researcher can use this as fallback

# smaller code font size (cause mostly boring xml)
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}
# Make listing captions smaller, to fit with smaller code size
#+LATEX_HEADER: \usepackage[skip=0pt]{caption}
#+LATEX_HEADER: \captionsetup[listing]{font=footnotesize}
#+LATEX_HEADER: \captionsetup[table]{skip=5pt}
#+LATEX_HEADER: \captionsetup[figure]{skip=10pt}

# Inline code has a light grey background
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{soul}
#+LATEX_HEADER: \definecolor{Light}{gray}{.95}
#+LATEX_HEADER: \sethlcolor{Light}

#+LATEX_HEADER: \let\OldTexttt\texttt
#+LATEX_HEADER: \renewcommand{\texttt}[1]{\OldTexttt{\hl{#1}}}%

# for \FloatBarrier, prevents figures from floating over sections etc
#+LATEX_HEADER: \usepackage{placeins}

** Abstract                                                          
:PROPERTIES:
:UNNUMBERED: t
:END:

#+BEGIN_CENTER

\todo[inline]{abstract}

#+END_CENTER
\todo{keywords}
\todo[inline]{Figures should to be able to be placed in the appendix}

\newpage
#+TOC: headlines 2

\newpage

* Introduction
\todo[inline]{since this was written so long ago, I think we should reread it (some are as old as 2016-12-05)}
\cleared
Communication is the foundation of our modern society.
Having good communication skills can help individuals in both professional as
well as in their personal lives.
However training people in communication skills can be difficult.
Another party is required to communicate with,
and a tutor or teacher has to be there to give feedback.
Serious games can be used to train people with these kind of skills
cite:swartout2013virtual.
Therefore a general "communicate!" game was developed.
Wherein teachers can create scenarios to let their students practice with
communication cite:jeuring2015demo.

\cleared
This game was script based, the teacher made a scenario and the student would
follow the choices predefined by the teacher.
A script based game has of course the weakness that a student can't use
creative responses,
all possible responses are scripted into the scenario
and replying correctly relies on a simple /abc/ choice.
To combat this an alternative serious game was made based on the
chat bot Alice cite:weiderveld2016chat bot.
To measure performance a rule engine was used, and to limit the domain
to that of a doctor's appointment social practices were used.
In this thesis we are interested in extending this work with personalities,
where we consider personalities to be a preference for a process rather than
content cite:campos_mabs2009.
This is useful because it turns out that the issues most doctors struggle
with isn't so much being sensitive,
but rather being sensitive to the people who appreciate it. cite:clack2004personality
Therefore extending the game to allow doctors to train for different
personalities will help addressing this issue.

\cleared
Since the personality topic has become quite popular in recent years
some thoughts will be devoted to related work.
After that,
to validate our work according to personality research
we'll look at existing personality theories and their advantages and disadvantages,
keeping practical considerations in mind.
Then we'll have a look at idiomatic AI programming and how in theory personality
could be combined with AI.
We continue by taking a close look at the state of the existing software that
we're planning to extend.
After this we'll discuss the implementation.
Finally we'll compare the different implementations.

** Related work
<<Related work>>
\cleared
  To simulate personality in communication games there have been already several
works proposed.
Etheredge used the OCEAN personality theory to create argumentative
agents cite:etheredge2016personality.
Although argumentation is not the same as communication we can consider the
method used to make the personality.
In this paper a personality model is introduced based on OCEAN.
To move from personality values in OCEAN towards action selection fuzzy logic
is used.
However this has a major disadvantage in that a lot of rules need to be
added to do action selection.
This can make action selection opaque.
It is for example not immediately clear how a higher anxiety will influence
action selection.
Having a lot of rule also make maintenance hard, if for example there is an
unwanted behavior many rules need to be inspected before the change can be made.

\cleared
In agents with with personalities cocu tried making a complete game based
on MBTI cite:cocu2015agents.
However communication was never implemented and personality got reduced to
doing a single action.

\cleared
Van den bosch also chose to use OCEAN to model characters in a serious
communication game cite:van2012characters.
He used a nested probabilistic if else structure to decide on how agents should
interact.
His methodologies had some shortcomings however,
for example a not agreeable person was defined as someone who'd had a high
probability of telling facts about himself.
Which in certain situations could be considered strange,
for example a spy who was captured.
This kind of methodology is called content orientated cite:campos_mabs2009,
the personality, would and should change depending on context.

\cleared
Campos used the MBTI to create BDI based agents cite:campos_mabs2009.
We will use a more fine grained version of MBTI but his architecture is used,
in which personality will be processed orientated rather than content
orientated.


\clearpage
* Background
\cleared
In this chapter we will discuss the work that is the foundation of this thesis.
First we will look at personality theories developed by psychology.
Then we will look at some to the literature in AI and argue for the
methodologies used,
and finally we will look at the serious game in its existing form.

** Personality theories
 <<personality theories>>
   \cleared
   A personality is a set of identifiers that can be used with
   reasonable consistency to predict behavior
   cite:mischel2008introductionp3_definition.
   What we want from this model is a guideline of implementation for the program,
   that is to say,
   the more the theory says about internal workings of a person the better it is.
   We want it to model to be realistic of course,
   but we also want it to be implementable.
   This is where we have a conflict of interest with the field of
   psychology since they do not necessarily care about implementation details.

   \cleared
   This conflict of interest can be seen for example in
   cite:mischel2008introductionp4_defpoints, where a criteria of personality is
   that it should be stable and coherent. However this is a poor
   software specification since there is no unit of measurement
   (how long should it be stable, and what range is acceptably stable),
   but for psychology it is a good definition, because a human can determine out
   of context what these things are.

   \cleared
   The field of psychology has been somewhat active in trying to model human
   personality cite:pervin2008handbook. 
   Several frameworks have been developed to figure out people's
   personality and what this in turn would mean for their lives.
   We are interested in two ways in existing personality theories:
   1. Accuracy, if a personality thoery does not fit the reality at all it won't
       help anyone in the serious game.
   2. Ease of implementation. If the personality theory is too hard (or impossible)
       to implement in the serious game than we can't use it.
   The field of psychology is very interested in the first requirement. 
   However the second requirement not so much.
   Therefore our first job will be to list existing psychology personality
   frameworks,
   and filter out those that are unfeasible to implement.


*** The big five
  <<OCEAN>>
 \cleared
 The first framework we'll discuss is called the big five.
 The term big five first coined in 1981 by Goldberg cite:goldberg1981language.
 The big five were not big because of their intrinsic greatness,
 but rather to emphasize how broad these factors were.

 \cleared
 This framework was not really invented, but rather discovered trough
 lexical analyses by for example Tupes cite:tupes1961recurrent.
 Although the labels used were different,
 they conveyed the same idea as the big five model used now.
 The methodology used is something which is called factor analyses[fn::
 In the paper the term 'varimax rotational program' is used,
 but if we look this term in wikipedia, we can see the result is called factor
 analyses cite:varymaxrotanonalprogram].
 Factor analyses is a statistical methodology that tries to find underlying
 hidden variables.
 This methodology has become widely used in psychology cite:fabrigar1999evaluating.

 \cleared
 The data Tupes used is from Catell cite:cattell1947confirmation and several
 others. Catell used a rating scheme,
 where a trait was introduced and all test subjects then had to rate all other
 test subjects else as average, below or above average for that specific trait.
 Persons could also use one extreme rating per trait for one person.
 These traits in the test were based on the /personality sphere/ concept which
 tried to cover the entire surface of personality by providing many small trait
 areas.
 Examples of the traits are: "Attention getting vs Self sufficient", or
 "Assertive vs Submissive".

 \cleared
 In the begining of the 1990's there were many ways to measure personality that
 didn't agree with each other.
 For example at Berkley alone block used a 2 dimensional ego-resilience and
 ego-control method cite:block1980role,
 whereas Gough measured folk concepts such as self-control, well-being and
 tolerance cite:gough1987california.
 Personality researchers hoped that they would be the one to discover a structure
 that would then be adopted by other researchers cite:pervin2008handbookp114.

 \cleared
 The goal of the big five was not to present a new structure that convinced
 others to use it,
 but rather to provide a taxonomy that all psychologist could agree upon.
 Since the big five was so broad (because of the statistical methods used),
 this worked.
 Therefore the researchers could keep on exploring there niche with their
 proffered structure,
 but once they would present their work they could use the big five to
 communicate clearly what their research meant without having to redefining the
 words every time cite:pervin2008handbookp114..116.

 \cleared
 The big five as in the OCEAN definition
 has the following units of measurement:
 - Openness or originality, if you score high on this you enjoy learning new
   things just for the sake of learning. If you score low then you don't enjoy
   this
 - Conciseness, how tidy you are, if you score high the dishes don't stack up
   in the sink.
 - Extroversion, a high score indicates you enjoy leading the conversation and
   you'll speak up when you disagree with someone.
 - Agreeableness or altruism, a low score would indicate that you don't want to
   share and generally don't trust people.
 - Neuroticism or nervousness, a high score indicates that you like to brag and
   get upset when someone is angry at them.

 \cleared
 The big five has been extensively tested and the result has been replicated
 in multiple studies cite:pervin2008handbookp119.
 One can measure his big five score trough a test called the NEO-PI, or the
 NEO-FFI. The FFI variant is shorter but less precise cite:costa1992revised.

 \cleared
 Although these terms may provide a great taxonomy,
 it does not have any theoretical foundation cite:eysenck1992four.
 This means it becomes difficult to speak about implementation.
 To make this more clear we use a thought experiment:
 Lets say you have a score of 0.8 for Neuroticism,
 how does this influence my decision for selecting action $a$ or $b$?
 Now you could say, use a mixed strategy where in you choose 80% of the time
 the neurotic typical neurotic approach.
 Then we need a valuation function to decide which of the two actions is more
 neurotic.
 But once we've done this we still haven't taken into account any of the
 other factors.
 Solving this is a non-trivial endeavor.

 \cleared
 There are some existing solutions in which OCEAN is implemented, for
 example allbeck used it as a mapping to the EMOTE system cite:allbeck2002toward,
 whereas cite:durupinar2008creating used the OCEAN values as a low level mapping
 in steering behaviors
 and finally cite:etheredge2016personality used the values for action selection
 in a dialogue, but extended the descriptions of OCEAN with IPIP
 with an entire chapter devoted to explaining this.
 Although these implementation are based on the same OCEAN model,
 the influence of it has starkley different effects on their
 respective implementations.
 Since each of them decided to change the OCEAN model in some kind of way
 we can conclude that although OCEAN is good for discussing the psyche,
 it is incomplete for a software specification role. 
 
*** Personality types
 <<sec:types>>
 \cleared
 To address the big five's issue of having no thoeretical foundation we'll
 have a look into personality types.
 We begin with the theoretical foundation proposed by the grandfather of
 personality research, Carl Jung.
 After which we'll look at a thoeretical evolution proposed by Myers and
 Myers-Brigs, which also introduced a structered method of measuring types.
 Then we'll discuss some critique on this method.
 With this critisim in mind we'll look at alternatives to the MBTI that have been
 proposed afterwards.

**** Jung's theory of psychological types
<<Jungian types>>
 \cleared
 Jung describes several concepts, firstly each person has two attitudes:
 /Introversion/ and /extroversion/.
 Extroversion means dealing with the outside world and therfore is called
 objective (or observable).
 Intoversion is the world inside a person, and therefore is subjective,
 or private.
 This privacy however may bo so great that the consiouness can't even access it.
 These attitudes are mutually exclusive,
 you can't do introversion and extroversion at the same time.
 For example if you're day dreaming you're not paying attention to your
 surroundings.
 A person who spends most of his time in the introversion attitude is called
 an /introvert/.
 But he is not totally the one or the other, ie an introvert can still have
 extravert moments and vice versa.
 It should also be noted that the unconsciousness according to Jung is
 flipped in attitude. cite:hall1973primer97-98attitude

 \cleared
 Then there are four functions.
 The first two functions are called the /rational functions/
 because they act as a method of making judgements.
 /Thinking/ is a function that connects ideas with each other to arrive at
 generalizations or conclusions. 
 /Feeling/ evaluates ideas by determinging if its good or bad, pleasant
 or unpleasant, beautifull or ugly.
 Note that this is /not/ the same as being emotional,
 although you can be emotional and use this function.
 The /irrational functions/ are called this because they require no reason.
 /Sensation/ is sense perception created by the stimulation of the senses,
 it can always be rooted to a sense,
 such as "I see a balloon" or "I feel hungry".
 /Intuition/ is like a sensetion but its not produced by a sense.
 Therefore it has no origin in the same way as sensation has,
 by which its explained as "just a hunch" or "I feel it in my bones".
 cite:beauchamp2005communication,hall1973primer98-100functions

 \cleared
 To use these functions they have to be combined with attitudes, producing
 /function attitudes/.
 Therefore a person will never be of a thinking type,
 but rather either a thinking introvert or thinking extrovert.
 cite:hall1973primer100-101combo
 We can now imagine what this means,
 an extroverted thinker will for example make judgement about the real world,
 and therefore be more like a natural scientist or biology researcher,
 where they would study natural objects and behaviors.
 An introverted thinker will make judgement about ideas in his mind,
 and therefore will be an excellent philosopher, or mathematician, where
 consistency of the internal reasoning process is important.

 \cleared
 Let $\mathcal{J}$ denote the set of all possible jungian function attitudes
 such that:
 \[ \mathcal{J} = \{ T_e, T_i, F_e, F_i, S_e, S_i, N_e, N_i\}\]
 Where
 + $T_e$ stands for extroverted thinking, which is thinking about objects in the
   real world. This is thinking with a goal, a problem to solve,
   to check weather certain laws are upheld, or a system to check.
   As said before a typical example of $T_e$ based reasoning would be a
   biologist studying natural behavior.
 + $T_i$ stands for introverted thinking,
   this kind of thinking could be called deductive,
   it tries to construct a framework to explain the world.
   This is consistent reasoning based on internal believes,
   which does not necessarily solve a problem.
   A typical example of $T_i$ based reasoning is a mathematician creating or
   combining new mathematical structures with help of axiomatic logic.
 + $F_e$ stands for extroverted feeling, where objective or external criteria
   is used to judge, for example something is beautifull or ugly.
   Established standards may be used to decide this and therefore its a
   conservative function.
   Decisions are based on interpersonal and cultural values.
   A typical example of $F_e$ based reasoning is about fashion and fads.
   Deciding what is fashionable at the moment is an $F_e$ based process.
   A typical profession would be working at a clothes shop,
   where the knowledge of the latest trends is crucial.
 + $F_i$ stands for introverted feeling, decisions based on personal values and
   believes.
   People who have this as dominant function attitude could be characterized by
   "still waters run deep".
   A typical profession for this type is in counseling or health care, because
   empathy comes rather natural to them cite:fiproffesionadvice.
 + $S_e$ stands for extroverted sensing, Act on concrete data from the here and
   now. Then lets it go.
   People of this type are often realistic and practical.
   A typical profession driver of heavy machinery or athlete cite:seproffesionadvice, 
   because living in the moment is most important for those professions,
   this comes natural to $S_e$ based personalities.
 + $S_i$ stands for introverted sensing, acts on concrete data from memories and
   passed experience.
   A possible profession for the people with $S_i$ as dominant function is in
   quality assurance,
   where the perfect model in their mind can be easily
   compared to the product in question cite:siproffesionadvice.
 + $N_e$ stands for extroverted intuition, try to find possibilities in every
   situation.
   Extroverted intuition can be very good entrepreneurs, seeing ideas in
   almost every situation,
   this also makes them very inspiring leaders because
   they are very excited about their ideas cite:neproffesionadvice.
 + $N_i$ stands for introverted intuition. Looks new possibilities in ideas.
   A typical occupation of this type is artist or visionary
   cite:hall1973primer104nitype,
   this is because connecting ideas with each other comes natural to this type.
   However just like the typical artist it may not always be understood why by
   his peers or even himself.

 \cleared
 <<Jungian alternating functions>>
 Another important concept is the idea of the /principal/ and /auxiliary/
 function cite:hall1973primer105principal.
 The principal function is the one that is most preferred.
 The auxiliary renders its services to the principal function,
 however this function cannot be the opposite of the principal.
 So if /Feeling/ is the principal function than thinking connot be the auxiliary.
 This is also true for the irrational functions.

**** MBTI
 \cleared
 The meyer brigs type indicator is based upon Carl Jung's theory of personality
 types.
 However it brings two important changes, first of all the way
 of measuring personality type is changed. 
 It uses a strutured approach rather than Carl Jungs projective approach.
 The responses to items are finite and therefore can be deduced based on theory.
 In contrast to Jung's technique where he used open ended answering with word
 associations cite:hall1973primer23method.
 Then there is the introduction of an extra index used to order function
 attitudes cite:carlson1985recent.
 Which is either a $J$ for judging (rational in jung terms)
 or a $P$ for perceiving (irrational in jung terms).
 This dimension indicates together with the $I/E$ dimension which function
 attitude is dominant and which is auxiliary.

 \cleared
 <<sec:mbti:order_comparison>>
 Once completed with the MBTI you'll get charatcter string as outcome,
 for example "INTJ".
 This label tells you inderectly which of carl jung's functions is dominant,
 auxiliary, tetriary and inferior cite:mccaulley2000myers.
 In other words it provides a sequence of preferences
 cite:website.mbtitypedynamics.
 In case of INTJ it would be:
 \[N_i > T_e  > F_i > S_e\]
 So the most preferred function to be used by someone of type INTJ would be $N_i$,
 then $T_e$ and so forth.
 These are the same function as Jung used, the MBTI
 just imposed an order on them cite:mccaulley2000myers,website.mbtisequence.
 How much preference there is for a function is not encoded in MBTI, just an
 order of preference.
 An ENTJ would be simialar to INTJ but with a different order:
 \[T_e > N_i > S_e > F_i\]
 With this definition the interplay of the judging/perceiving dimension becomes
 more obvious if we look at INTP: \[T_i > N_e > S_i > F_e\]
 It's similar to an ENTJ, but the attitudes have flipped.

 \cleared
 A possible grouping of the sixteen type exists using the middle letters:
 \[\{NT, ST, NF, SF\}\]
 This grouping goes under the rationale that the first two functions only
 differ in either attitude, order or both.

 \cleared
 Before continuing we would like to say a word about a popular
 interpertation of MBTI which is based on Kersey's book "Please understand me",
 and later "Please understand me II".
 In this interpertation the sixteen types are also placed in general groups
 of four but here the $ST$ and $SF$ distinction is replaced by $SJ$ and $SP$
 cite:keirsey1998please.
 It turns out however that Kersey invented this distinction because
 "He thought it made sense to group them this way" cite:whyaretypesdistinct.
 In doing this he rejected the work of Jung and also that of cognitive functions.
 Which is problematic because the theory he presented then does not make any
 thoeretical sense.
 Therefore Kersey's MBTI will not be used in this thesis.

 \cleared
 The MBTI is extremly popular in a subfield called Organizational Developement
 (OD) cite:sample2004myers. 
 But it has gotton some heavy critism in from the field of psycology.

 \cleared
 MBTI has always used a continues scoring system in the results.
 However the creators insist that type is enough for making assessment judgments.
 Since MBTI reduces the test scores to type,
 it is expected that most of the population would fall into either proposed
 dimensions.
 For example $I$ or $E$.
 This is called a bimodal distribution.
 However cite:bess2002bimodal suggests this is not the case,
 but this could be the result of the scores being biderictional
 cite:salter2005two.
 In an extended investigation cite:arnau2003jungian into weather jungian
 constructs are truly categorical suggested however that this was maybe not
 the case and a continues scale for assessment judgements are required.

 \cleared
 In cite:sipps1985item the MBTI is put trough a method called factor analyses.
 This is the same technique where OCEAN is based upon (see section [[OCEAN]]).
 With this technique the desired outcome is that there are 4 question clusters
 (or factors), one for each dimension.
 These factors should also be independent,
 a question that influences I/E score should not influence S/N.
 Finally we expect the factors to indicate differences between individuals.
 Random questions won't do that.
 However the study indicated that the MBTI had more than 4 factors (6),
 cite:sipps1985item explains the first extra factor as questions that assessed
 people being "unconditional positive",
 but could not explain the other extra factor.
 Something else of note worth cite:sipps1985item indicated was that there
 were questions doing no discrimination at all (not being scored). 

 \cleared
 Reliability indicates how often the same result will come out of the test,
 for example if you take the mbti a 100 times you may be classified the same
 type for 70 times,
 which would be an indication it has a reliability of around 70%.
 But in psycology another aspect is important,
 namely the interval in between which the tests are taken,
 if for example two tests produce starkly different results but a long time
 has passed between them its not considered a big issue.
 In cite:pittenger1993measuring it is suggested that after a period of 5 weeks 50%
 of the participants changed in score.
 However one should take into consideration that after taking the test a first time 
 people could consciously decide to change their opinion because they think its
 more desirable to have a different type.
 Jung said that type is decided very early on in life cite:hall1973primer106inborn
 so having reliable scoring is important.

**** PPSDQ
 \cleared
 The PPSDQ keeps basically the same theory as MBTI cite:kier1997new,king1999score,
 but uses a different measuring method.
 Instead of forced questions it uses a word-pair checklist for
 $I/E, S/N$ and $T/F$, and for the $J/P$ self describing sentences are used
 cite:melancon1996measurement.
 An example of a word pair checklist can be found in table [[tab:word-pair-example]].
 The word pairs themselves were obtained by prescribing an exploratory test(s) to a
 sample in which the proto PPSDQ was submitted and also the MBTI itself, factor
 analyses was used to determine correlation, this is done in
 cite:thompson1994concurrent.
 The optimal amount of points (options to choose from)
 presented in such a test is a subject for debate.
 Common sense would suggest that more points would give more precision,
 but in cite:matell1971there it is suggested that reliability and validity
 do not increase with more points. In cite:garland1991mid however they
 state the importance of an available midpoint.
 The 5 point choice format in the PPSDQ is not motivated.
 
#+CAPTION: An example of a word pair checklist, where the test taker should choose the  word that he identifies most with
#+NAME: tab:word-pair-example
 | Word          |   |   |   |   |   | Word      |
 |---------------+---+---+---+---+---+-----------|
 | Empathy       | 1 | 2 | 3 | 4 | 5 | Logic     |
 | Dispassionate | 1 | 2 | 3 | 4 | 5 | Emotional |

 \cleared
 The result of the PPSDQ would look something like: I-30 N-20 T-80 J-60, with
 a scale of 0 to 100. To calulate the jungian functions as a probability measure
 some math is required. Our subject is $70\%$ of the time introverted and $30\%$ of the 
 time extroverted. $60\%$ of the time judging and $40\%$ of the time perceiving.
 therefore N_i would be calulated as: 0.7 \times 0.4 \times 0.8 = 0.224 or $22.4\%$.
 N_e would be $0.3 \times 0.4 \times 0.8 = 0.096$ etc.
 From this you can make a preference sequence or create a mixed strategy.

 \cleared
 The PPSDQ is measuring the same thing as MBTI but lacks the critisms of MBTI.
 The reliability is for example between 90% to 95% with a delay of two weeks.
 The internal consistency was also measured which proved to be better than
 MBTI but there was still a dependency between S/N and P/J which remains
 unexplained cite:kier1997new.
 The PPSDQ is internally most consistent of the discussed alternatives
 (excluding OCEAN) cite:arnau1999alternative.

**** SL-TDI
 \cleared
 SL-TDI measures functions by presenting 20 situations and then giving subject
 possible actions which corrolate with the functions.
 The subjects then have to indicate how likely it is that they would choose that
 particular action cite:arnau2000reliability.

 \cleared
 It becomes rather staight forward to make a function preference of the 
 measurement of SL-TDI since the qeustion directly measure the jungian
 functions.
 A possible personality type therefore would be:
 \[ S_i \geq T_i \geq S_e \geq F_e \geq N_i \geq T_e \geq N_e \geq F_i \]
 To determine the preference we just used the observed value in the test.
 Since every situation offers a choice for each function with a 5 point value
 there is no need for normalization.

 \cleared
 This denotion is much less strict than the MBTI or PPSDQ since it does not force
 alternating attitudes or pairing of rational/irrational functions in the
 preference.
 Therefore the amount of personality types SL-TDI supports drastically exceeds
 that of the PPSDQ. In other words, there always exists a mapping from PPSDQ
 to SL-TDI, but not always from SL-TDI to PPSDQ.
 The reason for doing this is because there is experimental evidence
 that there exist personalities outside of the stucture orignally imposed by
 MBTI and the subsequent PPSDQ cite:loomis1980testing.

 
*** Comparison of theories
 \cleared
 To re-iterate, we are interested in a framework that is realistic, and easy to
 implement.
 The Big Five falls short on the easy to implement,
 there is no underlying theoretical framework to support it cite:eysenck1992four,
 therefore we cannot base our implementation on anything except our own
 interpertation.

 \cleared
 The MBTI has been criticized a lot from the field of psychology,
 but it does have a solid theoretical foundation.
 There is some relation between the big five and MBTI cite:furnham1996big.
 Therefore its somewhat realistic, but quite easy to implement.

 \cleared
 Both of the alternatives of MBTI use a continues scale and have a high
 correlation with the big five cite:arnau1997measurement.
 This means is that they are measuring something which is also measured by the
 big five in some way.

 \cleared
 The PPSDQ is based on the same thoery as MBTI, but with scaled type letters.
 To convert the type to function attitudes some extra work has to be done,
 namely calulate their respective probabilities.
 To decide which function attitude to use some kind of mixed strategy
 has to be used.
 The PPSDQ is more realistic, but at the cost of being more difficult to
 implement.

 \cleared
 The SL-TDI is even harder to implement than the PPSDQ because the function
 attitudes no longer have to alternate.
 This either means that functions are independent (thereby rejecting some of Jung's work),
 or that they have to work in some kind of combination.
 If they work in some kind of combination and we have to following preference:
 \[ T_e > T_i > S_i > N_i > F_e > N_e > S_e > F_i\]
 We select the first function to work with, but it requires some information now,
 what to do?
 Select $S_i$, thereby skipping $T_i$, or select $T_i$ and let it decide to
 select $S_i$, but this would basially give $T_i$ censorship rights.
 This is difficult to answer therfore it is a lot more difficult to implement
 than PPSDQ.
 Since SL-TDI drops an assumption, which is shown with experimental evidence
 to be false cite:loomis1980testing, we can say SL-TDI's theory is most realistic.
 This comes however at the cost of being even more difficult to implement.

 \cleared
 Therefore our preference for implementation is the following:
 \[ \text{MBTI} > \text{PPSDQ} > \text{SL-TDI} > \text{OCEAN} \]

 \cleared
 There is another hidden reasoning behind this, the work of PPSDQ can built on
 that of MBTI, and that of SL-TDI can build on that of PPSDQ.
 OCEAN builds on nothing, we'll leave that for future work.

** Artificial intelligence literature
 # How do I measure that the persnoality created is in fact in complience with
 # the personality I aimed for?
 # Can I let the personality take the test somehow?
 \cleared
 In this section we will look at some of the AI based literature.
 For example we will have a look at the intelligent agent approach and the BDI
 architecture.
 We will also look at some theoretical attempts at implementing personality.
 Theoretical attempts are often a logic in contrast to the topics
 discussed in [[Related work]] which include executable implementations.

*** Agents background
 \cleared
 In the literature there is little consensus on what exactly an agent is,
 however there is a general consensus that an agent is /autonomous/
 cite:wooldridge2009introduction.
 To make this more clear we'll use Wooldridges' definition:

 #+BEGIN_QUOTE
 An /agent/ is a computer system that is /situated/ in some /environment/ and
 that is capable of /autonomous action/ in this environment in order to meet its
 delegated objectives. -- Wooldridge
 #+END_QUOTE

 \cleared
 In another older definition cite:wooldridge1995intelligent Wooldridge highlights
 /autonomy/, /social ability/, /reactivity/, and /pro activity/.
 Where autonomy means that no human intervention is required,
 social ability means it can talk to other agents,
 reactivity is that it can reply on input and pro activity means that it can
 show behavior while not reacting to something.
 However he later continues on with a stronger claim about an agent is a
 piece of software that uses concepts which are attributed to humans.
 Such as believes desires and intentions.

 \cleared
 This is the reason why we can't call any program an agent.
 For example an operating system kernel is
 autonomous (a user would never interact with it),
 social (can do networking),
 reactive (it will comply to hardware interprets for example)
 and proactive (a process hogging to much memory will be killed without the
 process asking for it).
 However we won't call a kernel an agent because it doesn't even come close to
 having believes, desires or intentions.

 \cleared
 Something to keep in mind is that there are three "branches" of agent research
 cite:wooldridge1995intelligent.
 The first one is /agent theory/ in which /specifications/ and methods of 
 specifications are developed. They ask what are agents and what are they
 ought to do and how do we tell them that.
 Then there are the /agent architectures/, these address questions of how
 to implement the specifications written by the theorists.
 In this paper we won't discuss architectures since we work in an existing
 system described in section [[The serious game]].
 Finally there are the /agent languages/, which ask the question how to write
 agent programs.
 Again this is mostly preditermined for us, but we will give a small overview.

**** Belief desires and intentions
 \cleared
 The belief desire intention model of human practical reasoning was first
 introduced by bratman cite:bratman1987intention.
 It is based upon a "common sense" framework of human reasoning.

 \cleared
 The idea of BDI is that an agent has believes, these can be anything, such as
 I believe the grass is green, or I believe the keys are on the table.
 Note that we never speak about facts, an agent can believe something to be a
 fact, but that doesn't make it a fact.
 Desires are special kind of believes that give agents a reason to be, they
 may also be called goals.
 Intentions are (partial) plans to make a desire come to fruition.
 How to formalize this properly turns out to be a hard question, which is
 analyzed in the following section [[bdi logics]].

 \cleared
 A number of reasons have been stated to use this methodology.
 The foremost is to make agent orientated systems less expensive in maintenance,
 verification and construction according to Rao and Georgeff cite:rao1995bdi. 
 However they don't cite a source for this.

 \cleared
 Another paper argues in favour of agent orientated design cite:jennings2001agent.
 It has the following major arguments:
 It is effective to divide a complex problem domain into several smaller problems,
 abstracting in an agent orientated way is more "natural",
 and complex systems dependencies and interactions can be easily modeled.
 # A case study is presented as proof of these claims.

**** Logic of BDI
 <<bdi logics>>
 \cleared
 \todo[inline]{This paragraph can remain either way: 1 we say we didn't use it in this thesis because we didn't quite require it (although a description of the bot should be possible in it) 2. We make an actual description of the bot in the logic, once the description is done we should also make a fact sheet for the scenario (to show it works I guess), this is low priority}
 Logic of BDI is an attempt to formalize how agents behave.
 One of the first formalization of Bratman's theory was that of Cohen and
 Levesque cite:cohen1990intention. It was based on linear time logic and
 used operators for actions and modalities for goals and beliefs cite:meyer2014logics.
 It was also used a tiered formalism, with at the bottom belief goals and
 actions which provided the basis for the higher achievement and persistent goals
 and intentions to do and be.
 Rao and Georgeff introduced a different formalism that used branching time logic. 
 They use modal operators for belief desires and intentions and then put 
 constraints on them to make interactions meaning full cite:meyer2014logics.
 Therefore this formalism is much closer to that of bratman cite:rao1991modeling.
 Finally there is the KARO formalism which is based on dynamic logic.
 This is the logic of actions and computation. They extend this logic with
 epistemics to add believes to it cite:meyer2014logics.

**** Drools
<<Drools background>>
\drafting
what are drools?
I guess so that we can reffer to this chapter in implementation and architecture.
So we need to explain at least:
+ Fact base
+ Query mechanism
+ Then is java code
+ commincuation between java and drools?

*** Social practices
 <<social practice>>

 \todo[inline]{(extra) possible sources: Weber, Durkleim, Hobermas, latour/reckwitz}
 \todo[inline]{ difference between norms and sp is that sp has no moral value, but you *violate* norms }
 \cleared
 In cite:smolka2001social it is stated that the research in activity theory
 led to the development of social practices.
 It was Karl Marx who made the roots who thought of the "roots" of activity
 theory cite:engestrom1999perspectivesp3_marx,
 Activity theory tries to bridge the gap between a single actor and the system
 it resides in cite:engestrom1999perspectivesp10_broad_definition
 trough the activity in progress.
 Another way of describing activity in this sense is "a way of doing things".
 A problem with this model however was, how do cultures move activities from the
 collective towards the individual cite:smolka2001social.
 Social practices were therefore introduced to make the notion of activity more
 concrete.

 \cleared
 An early adoption of social practice can be found in cite:shove2005consumers,
 where it was used to analyze the spread of Nordic Walking.
 In his analyses he uses the following overarching concepts to analyze the practice:
 1. /Material/, which is just stuff in the real world. Such as cars, lamps etc.
 2. /Meanings/, which covers issues that are relevant to the material and/or the
    practice. Think of health, price or even emotions. Consider the an example
    practice of cycling.
    In cite:shove2005consumers meanings and images is used interchangeably,
    however in cite:holtz2014generating its labeled as just meanings.
    For clarity we will be using the word /Meanings/ since its more descriptive.
 3. /Competence/, it is rather obvious to say you need to be able to cycle to
    participate in the social practice of cycling. This is why this is
    introduced.

\cleared
In cite:dignum2014contextualized a model of social practices for agents was
developed.
This model is extended specifically to allow software agents to use it.
In this model /physical context/ describes the physical environment,
it contains resources, places and actors.
Note that resources is equivelant to material from the model used by
cite:shove2005consumers,holtz2014generating.
/Social context/ contains a social interpretation, roles and norms.
In the previous model this was all part of /Meanings/.
/Activities/ are the normal activities in the social practice,
in nordic waling this can be for example talking with your partner,
or stopping to get a stone out of your shoe.
They don't need to all be performed but are there just as options.
This is the first construct that wasn't covered by the other model.
/Plan patterns/ are blue prints for the eventual plan.
An example of a doctor appointment plan pattern can be seen in
figure [[fig:sp-activity]].
If you go to the doctor the first thing you do is some kind of greeting.
Then the doctor goes onto data gathering and diagnoses mode until he figured
out what's wrong.
After which he will tell in the finishing phase what to do about it.
Now what these phases entail is not clear at all.
Finishing may for example contain the prescription of medicine,
or an appointment to go to the hospital. 
However plan patterns do not describe such an implementation.
The plan pattern construct wasn't represented in the previous model either.
/Meaning/ in this model is soley related to the social effects of activities,
and finally /Competences/ is the same as in the previous model.

 \cleared
 The interest for this model comes from  the potential heuristic use of social
 practices.
 Once in a particular situation that fits for a social practice the amount of
 reasoning can be sped up by having actions and their preconditions be grouped
 under that social practice,
 if no preconditions match an agent could consider trying other social practices
 he knows, or ask its peers for more information.

 \cleared
 The social practice theory in this thesis should be considered as a
 /foundation/ rather than a separate element.
 We will be using it as a domain limiting device,
 however it should be noted that it could act as much more than that,
 potentially it could give the notion of culture to agents.
 In this thesis we are interested in implementing personality for a serious game
 in a single social practice.
 So right now the social practice just gives an ordered overview in what domain our program
 should work.
 We can formulate the social practice that is relevant for this thesis 
 in the following manner:

 + Practice name: Doctor appointment
 + /Physical context/,
   - Resources: Computer, chair, diagnostic tools..
   - Places: waiting room, doctor's office...
   - Actors: doctor, patient, assistant, ...
 + /Social context/,
   - Roles: Doctor, Patient...
   - Norms: doctor is polite, patient is polite, doctor is inquisitive
   - Social interpretation: Can sit on chair, cannot sit on table.
 + /Activities/, share information, do diagnostics, minor treatments,
   prescribing drugs...
 + /Plan patterns/, see figure [[fig:sp-activity]].
 + /Social meaning/, awkwardness, gratitude, ...
 + /Competences/, Give injection, empathetic talk

#+NAME: fig:sp-activity
#+BEGIN_SRC plantuml :cache yes :file img/uml/sp-activity.png :exports results
start
:greeting;
while (has diagnoses?)
fork
:data gathering;
fork again;
:diagnoses;
end fork
endwhile
:finishing;
stop
#+END_SRC
#+CAPTION: Plan pattern example
#+LABEL: fig:sp-activity
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[35679ceefcd43b1884cc8c502d27ae59aaa34043]: fig:sp-activity
[[file:img/uml/sp-activity.png]]

  \cleared
  We can imagine personality should have /a/ influence on social practice
  selection and of course plan influence. As far as the authors are aware however,
  there hasn't been any prior work on this subject. But we can speculate for
  example that when considering physical context someone that is domination by a
  Sensing function would check all artifacts more rigorously than someone
  dominated by an Intuition.

  \cleared
  If the social practices are defined more formally they could be 
  used in a bigger system such as in cite:augello2015social and
  cite:augello2016model.
*** Speech act theory
<<Speech act thoery>>
\cleared
Since a large part of this thesis is about communication we will give here a
brief overview of speech act theory.
There are three levels at which speech acts can be analyzed according to
cite:shoham2008multiagent_speechact_p241..245.
/Locutionary/ acts simply convey information form the speaker to the listener.
All speech acts do this, as long as they carry meaning.
/Illocutionary/ acts are the speech acts that do something by saying it.
It captures the intend of the speaker. This includes giving orders or uttering a
warning.
/Perlocutionary/ acts are the acts that bring an effect to the hearer, such as
scaring or saddening.

\cleared
There are some basic assumptions of conversation, commonly described as the
/rules of conversation/ developed by Grice cite:shoham2008multiagent_speechact_p241..245.
Humans communication happens on the assumption that both parties want to be
clear to each other, even when other motivations apply.
This is called the /cooperation principle/.
To accomplish this share goal the Grice's maxims cite:gricemaxims are
used:
/Quantity/ has to do with the amount of information transferred in a single
utterance, a human wants to transfer just enough to get the right meaning across.
/Quality/ is the assumption where people will say things they believe to
be true.
/Relation/ states that the things uttered should be relevant to the subject
being discussed.
/Manner/ is about being as brief and clear as possible while avoiding ambiguity
and being orderly.

*** Dialogue systems
<<Dialogue systems>>
\cleared
Dialogue systems are the systems that try to analyze how dialogue works.
This is a sub field of AI that tries to combine linguistics with computer
science.

\cleared
First of all are of course the chat bot systems, which are based upon case based
reasoning. A good example of this is the A.L.I.C.E. bot cite:wallace2001dont.
These are mostly reactive systems that use pattern matching rules paired with
"good" responses,
sometimes with conditions to allow for more variety.
A more extended example of such a system is Eliza bot which is described in
cite:galvao2004persona,
where they also added personality to the bot with the OCEAN model.

\cleared
Traum cite:traum2003information describes the information state approach for
dialogues. 
The approach Traum proposes is modeling:
+ Informal components, which aren't part
  of the model but are just there. This can include domain knowledge for example.
+ Formal representations, which are data structures.
+ Dialogue moves, which entail the set of possible utterances to make.
+ Update rules, that allow or prohibit the taking of certain moves.
+ Update strategy, to decide what rules to apply at a particular point.
The dialogue is the information state itself cite:walterapproaches.
This is an extremely general way of describing a dialogue system.

\cleared
In cite:wobcke2005bdi a BDI based methodology is proposed to handle dialogue
between a user and an agent.
However we want to point out that this solution fits into the rough model Traum
sketched. So we could say its a information state approach too.

\newlyCleared
An interesting paper on dialogue modeling can be found in cite:bilange1991task.
What is interesting is that they treat having multiple options available in
their implementation (see 3.3 in the paper).
This is similar to what we present in section [[Dialogue tree]].
Although their solution is quite different,
rules were made to select according to a single strategy,
whereas we saw it as an opportunity to make composable strategies.
This is of course an information state approach too.

*** BDI + Personality
<<BDI + Personality>>
 \cleared
 \todo[inline]{other proposed systems and argue for campos}
 Campos discussed an architecture in which personality emerged not from things
 you like,
 but rather than trying to determine which content a personality preferred,
 the personality was encoded in the process they preferred.
 This was called /process orientated/ rather than contend orientated.
 cite:campos_mabs2009
 For example in their interpretation of MBTI a Sensing agent would make a plan
 in complete details whereas an intuitive agent would just continue planning as
 needed.
 Thinking agents would base their decision process upon their own believes
 whereas feeling agents would consider what other agents want.
 In our model we conceptualize the Jungian functions also as a process.
 We comment more on this in section [[Jungian BDI]].
 
** The serious game

 <<The serious game>>
 \cleared
 This chapter describes the game we inherited from our predecessors.
 We have to discuss precisely what they did for two reasons:
 1. To help understand the design constraints we work under
 2. To distinct our changes from theirs'

  \cleared
 There have been several distinct versions of the "communicate!" game. 
 The first version was a web based game, with a scenario editor.
 cite:jeuring2015demo
 However it had some drawbacks,
 for example each dialog was scripted by the teacher and the answers the student
 could give were specified by the teacher.
 This made practicing on it somewhat unrealistic.
 Practicing in this case would mean memorising what button to click rather
 than to figure out what to say.

 \cleared
 To address this issue the a new implementation was made. 
 This version was based around the idea of a chat bot, in the form of the ALICE
 bot.
 The AIML language was extended to allow emotional reactions of the agent.
 This new language was called S-AIML cite:augello2016model. 

 \cleared
 A specific scenario was created for doctor/patient interaction     
 cite:augello2015social.                                            
 The game in this version also has the ability to judge the skills practiced
 cite:augello2016social,
 such as following certain protocols (politeness, medical standards), and empathy.  

 \cleared
 There is a difference between the architecture in the published papers and
 the source code received.
 This is because the source code is actively being worked on, whereas the
 papers are snapshots of the source code at the time of publishing.
 An example of such a difference can be seen if we take cite:augello2016social
 in consideration,
 the judgement of these practices was for example encoded within the S-AIML
 language, however in the source code AIML has taken a step back.
 It is only used for text processing and not deliberation
 (which is now being taken over by drools as discussed in [[existing architecture]]).
 We will be using the source code as a guideline in discussing the existing
 work because it is more relevant and constructive.

*** Functionality
    \cleared
 There are two major functionality perspectives to consider,
 that of the student, and that of the teacher.
 We will consider these in separate subsections since in game they
 don't interact.
**** Student usage

    \cleared
 For a student to use the application he has to first start a client.
 He can now choose to start a new game.
 There are options to list existing games but these have not been completed.
 Once in game the user enters a screen as can be seen in [[fig:client]]:
  #+CAPTION: Client view
  #+NAME:   fig:client
  [[./img/client.png]]

    \cleared
From here the student can start practicing, the game will track his progress
on the server.
**** Teacher usage
    \cleared
For the teacher there is right now no client.
The way a teacher can setup a scenario is trough modifying AIML and drool files.
The teacher probably needs an expert to do this since these are right now
combined with the war.
It would be difficult to modify these files on a running instance.

*** Abstract architecture
\cleared
An abstract architecture was already in place and described very well
by cite:augello2016social. This can be seen in figure [[fig:abstract-architecture]],
which was directly taken from cite:augello2016social.
 
  #+CAPTION: Abstract architecture as described by cite:augello2016social
  #+NAME:   fig:abstract-architecture
  [[./img/abstract-architecture.png]]
  
\cleared
The interaction module handles user interaction, where the GUI can show the
dialogue and the mood of the agent.
The Dialogue module inside it however handles low level string interpretation
with help of AIML (see [[Text Processing]]), this basically works trough string
matching.
Note that although represented in the abstract architecture as the same module,
the GUI resides in  the implementation on the client side whereas the dialogue
module resides on the server. 

\cleared
The dialogue module calls directly the Representation and interpretation module
with help of specialized tags (see [[Deliberation]]) information can be inserted in
the representation and interpretation module.

\cleared
Both the 'representation and interpretation' module and the score module use
drools to do their respective tasks.
The only real separation in implementation is trough directory and file
structure, but at runtime there is little distinction.
The only other thing of note is the direct connection between the emotion module
and the GUI,
this is because the emotion module sends directly messages to the GUI whilst
ignoring all of AIML.

*** Application Architecture
<<existing architecture>>
\cleared
The game uses a client server architecture (see figure [[fig:components]]).
The client is written in unity and the server is a Java servlet running on
wildfly.
Communication between the two applications happens trough a web socket.
A web socket is used because it allows the chat bot to pro-active,
which is not possible with a technology such as REST.

#+NAME: fig:components
#+BEGIN_SRC plantuml :cache yes :file img/uml/components.png :exports results
[Unity Client] <--> Websocket : json
[Wildfly Server] <--> Websocket : json
#+END_SRC
#+CAPTION: Component diagram of the application
#+LABEL: fig:components
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[6554c350da9b80944f22f0c6c29686b4608b9b50]: fig:components
[[file:img/uml/components.png]]

**** Source tree
    \cleared
    There are two major source trees tracked in separate version control systems.
    The first manages
    the client[fn::received on commit 40b55c0da1f556ba2b66ea8322d72008c9df1e72]
    and the second the
    server[fn:: received on commit 92f12fc26a7da83554903bfe7c6ed1cc64dd5a53].
    The protocol is tracked separately in the respective client and server
    folders with the folder name "dto".

**** Protocol
    \cleared
    The protocol is setup to be intended for a much larger system.
    There are hints of a registration system but further inspection
    revealed that only logging in only worked and but was required.
    This is tied into the server's ability to run multiple games. 
    there is also a limited monitoring functionality, the active games can
    be listed with a specialized message.
    A typical happy path scenario of protocol messages is listed in
    figure [[fig:sequence]].

#+NAME: fig:sequence
#+BEGIN_SRC plantuml :cache yes :file img/uml/sequence.png :exports results
  actor client
  entity server
  client -> server : login(userid,password)
  client -> server : newGameRequest
  server --> client : newGameResponse(idNewGame)
  client -> server : startGame(idGame)
  server --> client : log(text)
  == Chat start (example) ==
  client -> server: userUtt(text)
  server --> client: agentUtt(text)
  server -> client: agentUtt(text)
  client --> server: userUtt(text)
#+END_SRC
#+CAPTION: Sequence diagram of a typical game
#+LABEL: fig:sequence
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[db5e6bada22b64bf70a330d1219fedc990f11453]: fig:sequence
[[file:img/uml/sequence.png]]

\FloatBarrier
*** Server architecture
<<Server architecture>>
  \cleared
We will discuss the server architecture in more detail since it contains the
"brains" of the application.
The most important classes are shown in figure [[fig:class]].
WebSocket is the entry point for the program where the messages from the client
enter.

#+NAME: fig:class
#+BEGIN_SRC plantuml :cache yes :file img/uml/class.png :exports results
  interface ChatBotEngine{
    +String chat(String request)
    +void setSession(Session session)
  }
  class ChatBotEngineImpl {
    -KieSession kSession
    -Chat chatSession
    -Session session
  }
  ChatBotEngine <|-- ChatBotEngineImpl
  class WebsocketService{
    -ChatBotEngine cbe
    +void onMessage(Session session, String message)
    -void chat(Session session, Strin message)
  }
  WebsocketService --> ChatBotEngine

  package org.kie.api.runtime{
  KieSession <-- ChatBotEngineImpl
  class KieSession{
      +Facthandle insert(Object obj)
      +void setGlobal(String identifier, Object value)
  }
  }
  package org.alicebot.ab{
  Chat <-- ChatBotEngineImpl
    class Chat{
      +HashMap<String, Object> predicates
      +String multisentenceRespond(String str)
      +setKieSession(KieSession kie)
    }
  }
#+END_SRC
#+CAPTION: Class diagram of the server, where kie is the engine that handles the drools
#+LABEL: fig:class
#+RESULTS[0b594e175f82f51e7db78f2340ecb9fa14f3e0e6]: fig:class
[[file:img/uml/class.png]]

\cleared
The Websocket uses a Chat BotEngine to determine how to reply to userUtterances,
Where Chat BotEngineImpl is the concrete implementation.
Chat BotEngineImpl uses a KieSession for the drools and a Chat which is the alicebot.
Once the startGame message is received the kie service is started,
which runs on a dedicated thread to do drool deliberation.
At this point facts can be inserted for the drools to react upon, in case
of the anmnesi scenario the GameStart fact was inserted, which was a marker
object to indicate that the game has started.
This allow drools to take the initiative, for example when the user
hasn't replied after 20 seconds the agent will ask the user why he hasn't
replied yet.
A detailed overview of construction can be seen in figure [[fig:construction]].

\cleared
In the class diagram (figure [[fig:class]]), we can see an attribute to the Chat
class called predicates.
This is a bag of variables the drools can use to keep track of the scenario
progression.
The setGlobal method of KieSession is used to expose global objects to drools.
In this case the Chat BotEngineImpl is exposed.
Insert can be used to insert facts.
The difference between facts and globals is that facts are evaluated by
the  rule base, where as globals are used by the rule base.
A fact can be considered as "just a value".
Currently globals are used as communication with external libraries
(for example the websocket and chat session).

#+NAME: fig:construction
#+BEGIN_SRC plantuml :cache yes :file img/uml/construction.png :exports results
|WebSocket|
start
:Receve StartGame message;
:Construct a chat botengine;
|#CCDDDD|Engine|
:Start kie thread;
:Register engine as controller in kie;
:Insert GameStart fact;
|#AntiqueWhite|Drool|
:Load aiml files;
:Construct a Chat object with help of AIML;
:Chat inserted in controller;
:Log to client;
|WebSocket|
:put game id in websocket user prefs;
stop
#+END_SRC
#+CAPTION: Activity diagram of a server game construction
#+LABEL: fig:construction
#+RESULTS[d725d50fe0747c0393ea2a3b6e93ac437492271a]: fig:construction
[[file:img/uml/construction.png]]

\FloatBarrier
**** Text processing
<<Text Processing>>
    \cleared
     Text processing is done with help of the ALICE chat bot.
     This bot does the parsing and validation of AIML,
     with help of the knowledge encoded in AIML it can specify a response.
     AIML links a pattern to a template, where the pattern is a user input and
     a template a response.
     An example of a pattern template pair can be seen in
     listing [[code:aiml-example-why-here]].

#+CAPTION: AIML example: why are you here?
#+NAME: code:aiml-example-why-here
#+BEGIN_SRC xml
	<category>
		<pattern>
			What is the problem
		</pattern>
		<template>
			<srai>why are you here</srai>
		</template>
	</category>
	
    <category>
		<pattern>
			* why are you here
			</pattern>
		<template>
			<srai>why are you here</srai>
		</template>
	</category>
#+END_SRC
    \cleared
     In this example the first category indicates that if a user types
     "What is the problem" (pattern tags), then the answer can be found in a
     category with pattern "why are you here".
     The second category does the same but the star indicates that any amount of
     characters
     [fn::It is not really 'any' character, we investigate this further in section [[Star tags]]]
     before the pattern can be ignored to match with the category.

**** Deliberation
<<Deliberation>>
\cleared
     AIML has been extended to allow updating of the drools knowledge base,
     as can be seen in listing [[code:s-aiml-inserts]].

#+CAPTION: Extended AIML that communicate knowledge
#+NAME: code:s-aiml-inserts
#+BEGIN_SRC xml
<category>
    <pattern>why are you here</pattern>
    <preconditions>not healthProblemAsked</preconditions>
    <template>
        <insert packageName="sp.anamnesi.health_problem" typeName="HealthProblemAsked" />
        I'm experiencing a <getDroolsTemplate />. It's quite strong.
    </template>
</category>
#+END_SRC

\cleared
     In this case if a user utters the sentence: "why are you here", the bot
     will check the drool database what his problem is and also update the
     scenario.
     Once the scenario is updated the possible responses of the chat bot are
     changed, as can be seen by the precondition tag.
     The template tag has some extra tags. The insert tag inserts a fact into
     the drools knowledge base, the getDroolsTemplate tag queries the drools
     knowledge base for a string.

**** User utterance processing 
<<user utterance processing>>

\cleared
An important process to describe is the way currently user messages are processed.
Figure [[fig:utterance-proccesing]] gives a detailed overview of utterance processing.



#+NAME: fig:utterance-proccesing
#+BEGIN_SRC plantuml :cache yes :file img/uml/utterance-proccesing.png :exports results
          |WebSocket|
          start
          :Utterance received;
          :call chat;
          |#CCDDFF|Alice|
          if (AIML matched
          results?) then (No)
          :Default
          response;
          else (Yes)
          if (Has insert tag?) then (No)
          else (Yes)
          |#AntiqueWhite|Drool|
          :Insert fact into drools;
          |#CCDDFF|Alice|
          :Combine droolsting
                  with AIML;
          endif
          if (Has getDroolTemplate tag?) then (No)
          :Use template text;
          else (Yes)
          |#AntiqueWhite|Drool|
          while (Has reaction fact?) is (No)
          :Wait;
          endwhile (found reaction)
          |#CCDDFF|Alice|
          :Combine
            reaction
            with
            template;
          endif
          endif
          |WebSocket|
          :Send response
          to client;
          stop
#+END_SRC
#+CAPTION: Activity diagram of user utterance processing
#+LABEL: fig:utterance-proccesing
#+ATTR_LATEX: :width 1.0\textwidth
#+RESULTS[2be41360a975175f4a0734807235d7983de36beb]: fig:utterance-proccesing
[[file:img/uml/utterance-proccesing.png]]

\newlyCleared
As can be seen in the diagram the message processing happens inside the Alice
bot.
Tags were added to AIML to allow the drool engine to be updated.
The drool system can be relatively easily be bypassed.
If there are no tags in the AIML the drool system will be oblivious of chat
messages.
We represented this situation in figure [[fig:state:aiml]],
there is a clear choice between going from a pattern either to drools or to the
template.
If there is an insert tag then the Drools state is visited,
if not we go directly to the Template state.
Then the Template state can use =getDroolTemplates= tags to read information
from drools.
Note that there is a loop for the =getDroolTemplates= tag
in figure [[fig:utterance-proccesing]].
This is because a blocking queue is used,
which will block the thread until there is an item in the list.
This is represented in the state diagram as the =ReadDroolTag= state,
which is a read only operation on drools.

#+NAME: fig:state:aiml
#+BEGIN_SRC plantuml :cache yes :file img/uml/figstateaiml.png :exports results
[*] -> Pattern
Pattern -> Template
Pattern --> Drools
Drools --> Template
Template --> ReadDroolTag
ReadDroolTag --> Template
Template -> [*]
#+END_SRC
#+CAPTION: State diagram of utterance processing
#+LABEL: fig:state:aiml
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[e004be8f35a1f147fb2883719a5fb53bf630e02b]: fig:state:aiml
[[file:img/uml/figstateaiml.png]]

** Personality influence case study
<<Personality influence case study>>

\cleared
To make the influence of personality more concrete,
and to get a possible expectation of what the chat bot should be able to do.
We want to make a scenario of a doctor appointment where each
patient has different personalities.
First we have Sander the INTJ, secondly Susie the ENFP and Chris the ISTP.
This type selection will give a rough usage of most Jungian functions.
In all cases the patients have the same problem, a back pain.
The cause of this problem in all cases is a worn out back.

\cleared
After the dialogue we will also discuss the motivations for saying things the
way they do.
This is important since because we are doing AI and not just computer science
we need to have an understanding what is going on in the mind of our test
subjects.


*** Sander the INTJ
\cleared
First we should note the dominant and auxiliary functions of the someone with an
INTJ mbti type.
An INTJ has as dominant function introverted intuition $N_i$ and as auxiliary
thinking extroverted $T_e$.
We would expect these function to be most obvious in the dialogue
(as discussed in section [[sec:types]]).
$N_i$ mainly focuses on connecting ideas and extroverted analyses objects
in the external world.
Combined with each other we get a personality that focuses on getting to goals
by analyzing situation far ahead of time.
This results in the expected dialogue which can be seen in table
[[tab:sander-conv-doct]].

#+CAPTION: Sander in conversation with the doctor
#+NAME:   tab:sander-conv-doct
| Who      | Utterance                                         |
|----------+---------------------------------------------------|
| Doctor   | Hi                                                |
| /Sander/ | /Hello/                                           |
| Doctor   | How can I help you?                               | 
| /Sander/ | /I have a back pain./                             |
| Doctor   | When did this first occur?                        |
| /Sander/ | /When I lifted a heavy object./                   |
| Doctor   | Oh, yes then you need some pain killers for this. |
| /Sander/ | /Thank you doctor/                                |

\cleared
Sander gives the doctor the information he needs to come to the conclusion he
himself probably already had drawn.
We could even expect him to ask for the medicine immediately,
however since this could make the doctor question his motives
(he could be addicted for example) he decides not to do this.
Doctor however doesn't go into the source of the problem.
He just assumed the patient overstretched himself because he lifted something
heavy.

*** Susie the ENFP
\cleared
As an ENFP, Susie has the dominant function of extroverted intuition $N_e$ and
as auxiliary function of introverted feeling $F_i$.
Therefore these functions should be most dominant in the dialogue.
$N_e$ focuses on finding possibilities in situations and $F_i$ is a internal
value based judgement function.
Combined with each other they make a personality who has strong ideals and is
enthusiastic about them.
The expected dialogue can be seen in [[tab:suzie-conv-doct]].

#+CAPTION: Susie in conversation with the doctor
#+NAME:   tab:suzie-conv-doct
| Who     | Utterance                                                          |
|---------+--------------------------------------------------------------------|
| Doctor  | Hi                                                                 |
| /Susie/ | /Hello/                                                            |
| /Susie/ | /How are you today doctor?/                                        |
| Doctor  | I'm good, how can I help you?                                      |
| /Susie/ | /I'm afraid I need some medicine/                                  |
| Doctor  | Medicine? Why do you need that?                                    |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |
| /Susie/ | /I got this pain in my back./                                      |
| /Susie/ | /Do you think I'm allergic to plants?/                             |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |
| Doctor  | Because a watering can is a little to light to get back-pain from. |
| /Susie/ | /Of course doctor./                                                |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |
| /Susie/ | /Yes, I will go then./                                             |

\cleared
We can now see a stark difference with the INTJ personality.
First of all being dominated by extroversion it was Susie who took the initiative.
Secondly she directly asked for medicine, without thinking about the
consequences but knowing she probably needs it.
Then when explaining the situation she jumped to an idea of why she could have
this sudden pain,
without thinking about if it even makes sense that you are all the sudden
allergic to plants that have been in your home for a while.
The doctor does however come to the conclusion that something is odd about
getting a back pain from lifting a watering can.
So because Susie is more talkative the doctor decides to do more tests rather
than just giving some pain killers.
*** Chris the ISTP
\cleared
With his ISTP type, Chris has the dominant function of $T_i$ and then the
auxiliary function of $S_e$.
We therefore would expect these functions to do most of the work in the dialogue.
$T_i$ uses an internal reasoning structure to make judgments about the world
and $S_e$ uses the senses to gather information.
The conversation can be seen in table [[tab:chris-conv-doct]].

#+CAPTION: Chris in conversation with the doctor
#+NAME:   tab:chris-conv-doct
| Who     | Utterance                                                         |
|---------+-------------------------------------------------------------------|
| Doctor  | Hi                                                                |
| /Chris/ | /Hello/                                                           |
| Doctor  | How can I help?                                                   |
| /Chris/ | /I have back pain doctor./                                        |
| Doctor  | When did this first occur?                                        |
| /Chris/ | /Well I was watering the plants,/                                 |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |
| Doctor  | Yes, that could be the case.                                      |
| Doctor  | However I would like to make a scan of your back just to be sure. |
| /Chris/ | /Can't you just give some pain killers to help me?/               |
| Doctor  | Yes but that will only work temporary.                            |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |
| Doctor  | I can give you some pain killers meanwhile.                       |
| /Chris/ | /Okay, thanks doctor/                                             |

\cleared
So this dialogue looks a lot more like that Sander (INTJ) than that of Susie (ENFP).
However the motivation for the responses are quite different than that of Sander.
Chris hadn't figured out yet that he needed pain killers when he arrived,
since his auxiliary function is $S_e$, he hadn't thought that deep about the
problem.
He just knew he was in much pain, and knew the doctor could help with that.

\cleared
The difference with the dialogue of Susie is again quite obvious.
He didn't took the initiative because his dominant function isn't extroverted,
and unlike Susie he correctly asserted when the doctor asked about it
that the object he lifted may have been to heavy.

\cleared
The conclusion is again different.
Because one of the main functions of Chris is $S_e$ he wants to deal with the
pain /now/.
Therefore he asks the doctor explicitly for pain killers,
without considering that only the tests could actually solve the problem
permanently. 
However the doctor comes to a middle ground and besides ordering the test also
prescribes painkillers.

*** Influence of personality
\cleared
So we had 3 different doctor appointments all with the same problem but with
different personalities being at play.
The end result was three different outcomes for each patient.
Sander probably will be back next week with the same complaints at the doctor.
However this time his situation may have worsened.
Susie will get her problem eventually diagnosed like Chris,
however Susie won't have access to painkillers meanwhile.
Which may be uncomfortable to her.

\cleared
From this case study we can conclude that training doctors to deal with
different personalities is in fact very desirable because it can allow
patients to be treated sooner and more effective.
Sander could have had his problem diagnosed a week earlier and Susie could have
had access to pain killers for example.


\clearpage
* BDI and Jung 
<<Jungian BDI>>
\todo{I think we should remove BDI from bdi and jung}
# In this chapter we talk about the abstract ideas, any information neccasarry
# to execute the thesis without considering implementation details.
# so I guess height and node count aren't neccasarry.
\cleared
This chapter tries to anwser the question,
"what is personality from a computationally perspective".
In where we imagine personality being a preference towards a process rather
than a preference towards content.
We will however not consider yet how to place this in the existing system,
but will consider how to combine Jungian psycology with BDI.

** Differences from campos
\cleared
Campos cite:campos_mabs2009 first considered how to combine MBTI with BDI.
His reasoning domain was however in action space (rather than just dialogue),
but we still want to use the idea that personality is a preference for a
process rather than a preference for content as discussed in section
[[BDI + Personality]].
However rather than using MBTI dimensions we want to use Jungian functions.
This is because Jungian function attitudes are the underlying construct of
MBTI and several other instruments (such as the PPSDQ and SL-TDI).

\cleared
There are some differences from the theory discussed in [[sec:types]] and Campos'
process.
The difference is that in the discussed theory we would translate MBTI to the
underlying Jungian functions, whereas Campos used the measured dimensions.
Translating to the functions has some advantages,
by doing so we are for example not bound to just the MBTI.
We also get more accurate descriptions of what Jungian functions are,
Jung described in his work people with that particular function as dominant.
This is harder to do with the dimensions, because if you take an INTJ type and an
INTP type the semantics of both the N and T change because of the P/J dimension, 
as can be seen in their respective order (see [[sec:mbti:order_comparison]]).
Campos avoids this by ignoring the I/E and J/P dimensions, resulting in a
simplified theory.
However we would like to note that it is not an easily extendable simplification.
Therefore we chose to translate types to orders in Jungian function attitudes,
something which is already done by MBTI (see [[sec:mbti:order_comparison]]).

\cleared
Another consideration to make is what are these function attitudes?
By which I mean what do they represent in computer science terms: programs,
objects or functions? What should they be?
Since Jung wasn't much of a mathematician cite:jungonfunctions its just an
informal definition.
However we can make a mapping to certain BDI processes
based upon their description,
but before that is done we need to make several structural observations.

\cleared
Firstly functions attitudes are not independent, by which I mean that
if we have a function attitude $a$, followed by $b$ then the resulting
behavior is different than $b$ followed by $a$ (see [[sec:mbti:order_comparison]]).

\cleared
Secondly all functions should be used and their order matters.
The first function used should be most prevalent.
This means that we can't just execute all functions and use a do preference
selection on the result.

\cleared
We will interpret the Jungian functions attitudes as a mapping from an agents
believes and senses towards an agent action and new believes.
This is then reduced to the scope of a chat bot in the social practice.
After this we will look what extra information the function attitudes need
in an attempt to reduce the amount of possible believes.

** Informal description of Jung + BDI
\cleared
Before diving into the type signature approach, or the formal description we
want to describe it informally.
Firstly we see the Jungian functions as a unit of processing.
This is a clear design choice, there are alternatives.
One could for example choose to make a unit of processing for every possible
combination of jungian functions attitudes which would result in $8!$ different
functions, or specifically just for MBTI which would result in $16$ functions.

\cleared
We also chose to model function attitudes, rather than functions and attitudes.
The reason for taking them as a combination is that there are more precise
descriptions available for function attitudes, rather than functions and
attitudes separated.

\cleared
So a function attitude as a unit of processing is something where information
goes in, the function does its processing and then information comes out.
This is analogous to a mathematical pure function.
Another way of describing such a process is a transformation upon information.

\cleared
From this we used the idea which MBTI uses too, that these small processing
units are in an order,
this order determines the eventual personality.
Then what we set out to do in the rest of the chapter is how to model this
into /type signatures/ and /types/.
/type signatures/ show what information (/types/) goes into a pure function.
In our case this usually contains a believe base for example.
Thus what we explored was what information does the believe base need to contain
for the Jungian functions to do their operations.

\cleared
There are several phases of processing going on.
Firstly we have user message parsing, where we try to figure out what the user
said.
Then, secondly there is action generation, where we use the parsed message to
determine sensible replies.
After that there is action selection, of which the best action is chosen.
This action is finally handled by the surrounding system.

\cleared
The opportunity for personality exists in practically all phases.
In the first phase for example we can do filtering based on the type of
messages received.
For example Thinking based personality may filter the message "how are you" as
an inquiry based on "how is your disease?", or "why are you here?".
Whereas a feeling based personality may retrieve a different meaning,
as in "how are you doing in live generally"?
We chose to not do such kind of personality based filtering because it
requires actual understanding of the message received.
Now there exist techniques such as convolution kernels cite:moschitti2004study
to decide what was said which can be combined with owl cite:world2012owl
to simulate a sense of understanding.
However implementing such techniques is considerably out of scope of this
thesis, and even with the existence of such techniques separately, its still
questionable if you can combine them successfully.

** A type signature approach
<<A type signature approach>>
\newlyCleared
To give a better understanding of the scope of this project we will
try to come up with a type signature of a pure function that models all the
function attitudes.
This is done with a Haskell like syntax,
in which the arrows indicate a function,
left of the arrow is called a domain and the right side a codomain.
The domain is also called the argument of a function.
If we see a pattern like $a \to b \to c$ means $a \to (b \to c)$ or give an $a$
and return a function $b \to c$, this process is called partial application
cite:haskellpartialapplication.
Capital letters indicate sets.

*** Narrowing the model
<<Narrowing the model>>
\cleared
We will go from an as broad as possible system (while using BDI) to a
precise as possible definition, while still being able to satisfy the domain.
This is desirable because it will restrict the amount of things that can happen
inside the function.
Therefore making it less complex and easier to understand.

\cleared
To make this process more easy to understand we'll postpone modeling interplay
between the $f_a$ function attitudes and define a type signature for them working
individually.
To do this we will define some terms, with which we will go from the broadest
definition possible towards one that just fits the project scope.

\cleared
Let $\mathcal{B}$ denote the set of all
possible believes and let $B_t$ with $B_t \subseteq \mathcal{B}$ denote the
believes at time $t$. 
$\Pi$ is the set of all possible sense information,
in which $\pi_t$ with $\pi_t \subseteq \Pi$ denotes the perception information at
time $t$.
$\mathcal{D}$ denotes the set of all possible actions with $\Delta_t$
$\Delta_t \subseteq \mathcal{D}$ denoting the set of actions executed at time
$t$.
With this definition we can define every possible agent configuration[fn::Note
that this is just the deliberation part, there is no memory in a pure function,
but the agent's memories can be stored in the believes.
The believes can be reused in the next call,
its up to the caller to decide how this happens.
This can be done on the thread of control the agent owns for example.
Where it will block until a time $t$ has passed or a new perception $P$ comes in from
the environment.]
as the following pure function type signature:
\[ B_t \to \pi_t \overset{f_a}{\to} (B_{t+1}, \Delta_{t+1}) \]
This says, we first put in the current believe base, then the sensory
information after which we get a new believe base and a set of actions.
In this the intentions are encoded in the function used, and the desires are
part of the believe base.
We marked the $f_a$ arrow, which indicates the deliberation process of the agent,
so $f_a$ can be any of the function attitudes.

\cleared
This definition is however too general for our domain.
First of all the set of sensory information can be reduced to a String,
since this is the information we get from a user.
However a String is still to broad since going from a textual representation
to a deliberation process is difficult.
Therefore we will introduce another mapping function $g$:
\[ \sigma \overset{g}{\to} s \]
Where $\sigma$ is a string and $s$ a symbol where $s \in \mathcal{S}$ in which
$\mathcal{S}$ stands for the set of all encoded symbols[fn::Originally this was
called meaning with an $m$, but we want to avoid confusion with meaning in the
social practice, and therefore renamed it to symbol, as in symbolic
representation]

\cleared
A symbol $s$, where $s = (\{\sigma\}, \sigma)$ has the first value as a set of potential
returning strings to utter,
and the second is the name of the scene the symbol occurs in.
The scene name is used as a name space and a crude way to measure scenario
progression.

\cleared
With this we can define another function $g'$:
\[ s \overset{g'}{\to} \sigma \]
This allows symbol $s$ to be decoded into string $\sigma$.
Note that in this relation there can be multiple $\sigma$ that map to the same
symbol,
but one symbol produces only a defined set of strings $\{\sigma\}$,
that in turn map to itself,
on this a random selection can be made.
In the previous version this mapping was entirely done by AIML.
How this is done in this version will be discussed in the implementation
section [[From strings to meanings]].

\cleared
So the simplification is now as follows,
firstly we note that $\mathcal{S} \subset \Pi$,
since understanding meaning is a form of sensation.
Then we can define $S_t \subseteq \mathcal{S}$ which stands for the
symbols the agent understood at time $t$.
To ensure a reactive and proactive we also have to pass the current time
as argument.
This keeps open the possibility of the agent to do deliberation without having
received a symbol (empty set).
This produces the following type signature:
\[ B_t \to t \to S_t \overset{f_a}{\to} (B_{t+1}, \Delta_{t+1}) \]

*** The dialogue tree
<<Dialogue tree>>
\cleared
We have some believes, time and meaning going in, some deliberation
going on and a new set of believes and actions going out.
The new believes can be used for the next iteration.
However this type signature isn't enough.
The current agent has to be able to do a game tree like deliberation process
to reason about what the other agent will say so it can pick the meaning that
brings it closest towards its goal.
In our case a goal is a particular meaning the agent wants the doctor to utter,
for example if our agent is sick we want the doctor to utter a /GiveMedicine/
meaning,
or if he is in extreme pain he would like to see the /GivePainKiller/ meaning
uttered.
We also need to mark which agent uttered the dialogue tree node,
therefore we introduce $\Lambda$ as the set of all active actors, where $a \in \Lambda$.

\cleared
With an actor $a$ and a symbol $s$ we can start thinking about modeling an
utterance.
However to do this, its important to remember that an utterance always comes with
a perlocutionary value set as discussed in section [[Speech act thoery]].
Therefore we introduce the set of all encoded perlocutionary speech acts as
$\mathcal{P}$ of which a set of speech acts is $P \subseteq \mathcal{P}$.
With this we can define utterance $u$ as a tuple:
\[ u = (P,a,s,t) \]
Where $P$ is the set of perlocutionary values uttered, $a$ is the actor that
uttered, $s$ the symbol that was uttered and $t$ the time at which the utterance
was made.

\cleared
Now we introduce $D$ a dialogue tree tuple:
\[ D = (u, [D])\]
Where $u$ is the utterance,
and $[D]$ is the ordered list of dialogue children.
The initial dialogue is just a symbol with an empty list of children.
To consider a reply, we would use the same dialogue tree,
except with a list of children that is bigger than zero.
The most preferred reply is the first element in the list of children.
How the actor is decided will be discussed in section [[symbol graph]].
An example of an expended dialogue tree can be seen in figure [[fig:dialoguetree]].

#+NAME: fig:dialoguetree
#+BEGIN_SRC plantuml :cache yes :file img/uml/dialoguetree.png :exports results
object D0{
a = "doctor"
s = "Greeting"
[D] = [D1, D2, D3]
}
object D1 {
a = "patient"
s = "Complaint"
[D] = [D5, D4]
}
object D2 {
a = "patient"
s = "QuestionIdentity"
[D] = [D6]
}
object D3{
a = "patient"
s = "Greeting"
[D] = [D1, D2]
}
object D5{
a = "doctor"
s = "StatusInquiry"
[D] = []
}
object D4{
a = "doctor"
s = "DoDiagnostics"
[D] = []
}
object D6{
a = "doctor"
s = "ShareIdentity"
[D] = []
}
D0 --* D1
D0 --* D2
D0 --* D3
D1 --* D4
D1 --* D5
D2 --* D6
D3 --* D1
D3 --* D2
note "This node is currenlty \n implicitly selected \n as response \n(because it came first \n in D0 as child)" as response
response .. D1
#+END_SRC
#+CAPTION: Object diagram of an expended dialogue tree. The leafs is where deliberation stopped.
#+LABEL: fig:dialoguetree
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[1f1f673a8fc69adbde74aa1a7aeb115abfb4b09a]: fig:dialoguetree
[[file:img/uml/dialoguetree.png]]

\cleared
With this in place we can replace both the $S_t$ and $\Delta_{t+1}$ with the $D_t$ and
$D_{t+1}$ respectively, we can also remove $t$, since its now contained in the
utterance.
This is convenient because now we can model function attitudes as processing
units that take a dialogue tree and modify it.
We are left with the following type signature:
\[ B_t \to D_t \overset{f_a}{\to} (B_{t+1}, D_{t+1}) \]
So we receive a dialogue tree from the user, which can just be a root node,
and then after processing we put out a dialogue tree plus the replies which
are the children, whereof the first child is the most preferred.
Also note that this $f_a$ function is an endomorphism, meaning that the input
arguments are of the same type as the output arguments. Note that we annotated
the output arguments with $t+1$ to indicate they could've been changed,
not to indicate a different type.

\cleared
Now we should note that this type signature heavily constrains our agent.
It for example can't handle being punched in the face by the doctor unless
there is a meaning encoded for that. 
It also runs into trouble when the agent is asked to sit on the counter.
Movement should be possible, but movement like one does during sky
diving is not interesting because we have the informal constraint of the
[[social practice]].
However once movement becomes a requirement we can just create a new function
type signature that is less restrictive, but still has the option to use these
functions for meaning full replies.

*** Composing type dynamics
<<Composing types>>
\cleared
The first thing a commendable programmer may think of when trying to combine
behavior is of course functional composition.
However there is an important requirement for this to work.
The input type and output type need to be the same of the two functions we
want to combine.
Our current type signature has this feature almost except for the time
argument, it is not difficult to work around this.
What is problematic however is that using functional composition in this
way would make it impossible for function attitudes to inspect results
of their auxiliary functions.
This is an important feature we want to keep because if for example a
judgement function is first in the order of functions and receives
the user meaning it can't do its job yet, more on his in this section
[[Rational and irrational]].
Therefore we consider another approach.

\cleared
Another architecture that was considered would be to store the functions in a
list and then let an external control unit decide which function processes next.
However this would leave the control of the function being called outside of the
control of the function attitudes,
therefore personality wouldn't play a role in deciding the function being called.
It will also create another problem of deciding when a function is called.
So to solve these problems we looked at another possibility.

\cleared
In this approach we will give $f_a$ another argument which is the next $f_a$.
This looks like the following:
\[ \left (\overset{next}{B_t \to D_t \to (B_{t+1}, D_{t+1})}\right ) \to B_t \to D_t \overset{f_a}{\to} (B_{t+1}, D_{t+1}) \]
Note that the function in the next bracket has the same prototype as the codomain.
In this case the /next/ function can play an advisory role to the codomain.
A unit function can be defined that produces empty sets as results for both
believes and action.
By unit function we mean the initial /next/ function
that does nothing and just returns the believes and dialogue tree.
Since the notation has become quite complex at this point we provided 
an activity diagram of this works in the broader system,
which can be seen in figure [[fig:faprocessing]].

#+NAME: fig:faprocessing
#+BEGIN_SRC plantuml :cache yes :file img/uml/faprocessing.png :exports results
  start
  :Interpret string into symbol (s);
  :Call first fa in personality sequence;
  repeat
  :Current fa logic;
  repeat while (Called next?)
  repeat
  :Fa modify results of next;
  repeat while (Another fa on stack?)
  :Extract string from results (D);
  end
#+END_SRC
#+CAPTION: Activity diagram of function attitude (fa) processing.
#+LABEL: fig:faprocessing
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[f6dff7c3b2e64b005de74f12e19c7b2917da613c]: fig:faprocessing
[[file:img/uml/faprocessing.png]]

\cleared
To illustrate the use of this type signature design more clearly we'll sketch
an example with the first two function attitudes of the INTJ type:
\[N_i > T_e \]
So to encode this as a function we start with the least preferred function
attitude namely the $T_e$,
however to let it play an advisory role in the $N_i$ function we first
need to complete the /next/ argument.
Because its the least preferred function we just use the unit.
Now the partially applied type of $T_e$ satisfies that of $N_i$ and we can use
it as /next/.
This methodology can be used for an entire personality type (ie all 8 functions
in some order).
Also as an analogy we could say that we're dealing with an intrusive linked
list.
The next argument is just the next item in the list.
And unit is just the tail item of that list, which merely exists to provide a
start point to create the data structure upon and an endpoint for iterations.

\cleared
With this methodology function attitudes can decide themselves to consult the
next type.
Then they can inspect the result, and even the changed believe base to decide
if its a good idea to use the result.

\cleared
This architecture can be extended with the scale based jungian models
such as SL-TDI and PDQ by introducing a random choice for using the current or
next function.
However this becomes rather messy because we're modeling pure functions,
therefore we leave this as an exercise to the reader.

***  Rational and irrational
<<Rational and irrational>>
\cleared
Up until now we modeled the type signature to have a dialogue tree as input and
output.
However we have not considered yet how children are generated and how the order
is determined.
If we look at the definition (section [[Jungian types]]) of rational and irrational,
we can make a design decision about what these functions should do to the
children.
Rational functions are about making decisions therefore they
should apply order to the children.
irrational are about producing information therefore they should produce
children based.

\cleared
There are however some edge cases to consider when modeling this idea.
Say the primary function is a rational one.
It receives a dialogue with just the root node.
Currently it cannot apply any order since the children list is empty.
Luckily it can still use its next function, which is irrational
(see section [[Jungian alternating functions]]).

\cleared
Another situation to consider is what to do when there are already children.
Should an irrational function extend this list of children or go to some leaf
node?
Same question for a rational functions should it sort everything or just the
children list one layer above the leaf nodes.
At which level a function should operate is rather fundamental.
We will discuss this level of operation in more detail at section
[[Function ply depth]], since this discussion is quite complicated and not important
for the main idea of what rational and irrational ought to do.

\cleared
With this in mind we can still say these things about the conceptualized
architecture:
/rational/ functions change the order of possible replies,
one layer above the leaf layer,
/irrational/ increase the number of children at the left most leaf layer.
So if we start with an irrational function it produces several related meanings
to the inputted meaning in a tree like structure.
The original meaning uttered by the user is the root node and the produced
response meanings are the children.
These then get inserted into the next rational function which modifies the order
of the children.
After doing this it passes this structure to the next
rational functions (because they alternate [[Jungian alternating functions]]),
until all functions in the personality had their chance.
Finally the unit function just returns the Dialogue and believes without
modifying them.
This returns trough all functions from before that can still modify it.
This could happen if a rational function was the first function for example
and didn't have any choices available to decide upon.
This structure still works with SL-TDI's non alternation.

** Mapping function attitudes to a process 
<<Mapping to process>>
\cleared
Now you may argue at this point we haven't refined our types a lot, since
the believe structure was defined as "Every possible believe",
which is basically analogous to "Anything you can think of" or in a Object
Orientated terminology: Object.
Since the believes serve as input of our function and output of the function
we may as well have said $Object \to Object$.
Of course the believes are not intended to be true output but rather just
part of the mind.
In other words, the believes are intended to be kept in a container
whereas the input $M_t$ and the output $R_{t+1}$ would only be visible for the
"outside world".
But still we want to refine our all possible believe to something which is 
less broad in scope.
To do this we will start analyzing the Jungian functions and see what
"extra" information require to function to perform their duties.
Then we will define the believe tuple more formally.

*** Symbol graph
<<symbol graph>>
\cleared
To make sure the agent stays on topic we will make use of a symbol graph.
This graphs gives connections to the symbols described in section [[A type signature approach]].
The meaning graph $G$ is a set of connections $c \in G$ where
$c = (P, A, s_1, s_2)$, $s_1, s_2 \in \mathcal{S} \wedge s_1 \neq s_2$,
$A \subseteq \Lambda$ is the set of agents that can use the connection,
to prevent cases where the patient asks the doctor about his health problems.
$P$ is the perlocutionary value set of the speech act, as introduced in section
[[Dialogue tree]].
This is encoded in the edges because its not the meaning that causes these
but the way you get to those meanings.
In other words, being polite and then telling bad news causes different
perlocutionary values than just telling bad news.

\cleared
From this we can define a function that gets the allowed connections from
a symbol and an agent:
\[ a \to s \to [c] \]
We can retrieve $a$ and $s$ from the current node we are processing in $D$.
The result is a list of connections we can go to from that symbol.
Since connection $c$ contains multiple agents $A$,
and a dialogue tree as an option can only contain a single agent in the utterance,
we need to flatten the resulting connection list $[c]$.

\cleared
The introduction of the symbol graph is probably the most radical change this
thesis proposes.
It moves chat bots away from the idea that responses are many to one relations
always and opens up many to many relations.
Please note that this is probably not only approach available.
It would have been more robust to use owl cite:world2012owl for example.
But this would open up a new problem on how to construct sentences,
of which the theoretical foundation is incomplete.
Another issue is how to interpret meanings, where you could for example use
cite:moschitti2004study.
But again its just a piece of the puzzle.
We think that making those steps are to big and probably simply will result into
failure.
However the symbol graph provides a good middle ground,
in which its relatively easy to implement but offers enough freedom to encode
personality in as a process.
Note that this approach fits nicely into the information state transitions
idea discussed in section [[Dialogue systems]].

*** Irrational
The irrational functions rely heavily on the symbol graph to create new
children in the dialogue tree.
This is under the assumption that connections in the symbol graph are always
on topic.
Please note that all irrational functions need to have an extra argument
to limit their activities.
Since considering the entire graph is unrealistic, and unnecessary.

\cleared
In the initial design of what the $S$ and $N$ functions should do
as algorithm we considered them in the following way.
$S$ would be analyzing all available options rigorously in a forward chaining
process, whereas $N$ would do backward chaining, starting at the goal and going
trough some way points directly to the starting point.

\cleared
This would translate into $S$ going several plies deep into the
meaning graph before calling the $next$ function and returning the result.
And if we assume that the $next$ function brings us closer to the goal we can
use it as a heuristic to let it determine the direction for $N$.
This of course doesn't allow us to do backward chaining since there is hardly a
guarantee that the $next$ function will bring us to the goal, in fact we may get
stuck in a loop.

\cleared
Alternatives to the implementation proposed include the use of
probabilities to determine appropriate responses. 
However this introduces a new problem of how to obtain the probability
distributions.
Machine learning could be used for this, but this raises the question:
"learn on what"?
Since the answer to that question is non-trivial, we consider such a solution
out of scope.

**** Intuition
# http://personalitycafe.com/cognitive-functions/83205-whats-difference-between-ni-ne.html
\cleared
We can consider $N_i$ to be a depth first approach. Going several plies deep and
at each ply consulting the $next$ function which step to take.
$N_e$ on the other hand just takes the top $x$ of the current dialogue options
and expands those, but then next step it will again consider the entire existing
tree to find the best $x$ of each ply.
This will of course be a much more shallow consideration than $N_i$, but 
much more broad. Which is of course the behavior we are looking for in both
$N_i$ and $N_e$ (see section [[Jungian types]]).

**** Sensing
\cleared
The $S_e$ function just receives all possible connections from the current
meaning for several plies and then applies the /next/ function on it.
The $S_i$ however is more conservative and will only pop $x$ random meanings by
default (the first $x$ connections),
however it will construct its own connections of whatever the user said in
response to the bot from previous conversations when at the same meaning (if it
didn't exists already).
Whenever these connections are available they will substitute the random $x$.
So $S_i$ starts of kind off similar to $S_e$ but builds up over time.

*** Rational
\cleared
In the current design the rational functions apply order to the children of a
current dialogue node.
Then once finished they will call the $next$ function on the most preferred
child. This is to ensure all function attitudes can do some processing.

\cleared
Please do note that although we have a game tree,
we're not dealing with a zero sum game.
Dialogue is cooperative rather than competitive (see section [[Speech act thoery]]).
So doing an algorithm such as mini-max is out of the question.
However we will borrow parts of it.
Namely whenever a rational function finishing ordering the input set it will
call the /next/ function to do deliberation on the most preferred item.

\cleared
We also model the rational functions as local optimizing functions.
Only the current ply and maybe the next ply is considered,
but not the entire tree.
The primary reason for this is time constraints.
However there is no reason why the entire available tree couldn't be used.

**** Feeling
\cleared
Initially we wanted to create two lookup tables for both feeling functions one.
However this would be confusing to configure,
the scenario creator would need to decide which values are "external" and which are
"internal".
Campos however modeled feeling as a prediction of what the other agents will
do.
This describes $F_e$ rather well, $F_i$ not so much however.
So we adapted and adopted that idea for $F_e$ and for $F_i$ we used the lookup
table.

\cleared
Both feeling functions $F$ use the perlocutionary acts to order the children.
$F_i$ uses a predefined value set $h$: 
\[ p \overset{h}{\to} i \].
Where $p \in \mathcal{P}$ is a perlocutionary value.
This valuation is done by a lookup table on all available perlocutionary speech
acts.
$F_e$ tries to figure out what the conversation partners values by
picking the perlocutionary act the other chose most.
This is done by simply keeping track on how many of such speech acts the
partner uttered and picking the that has been uttered most,
if that one is not available we move to the next one.
This is similar to fictitious play.

**** Thinking
\cleared
Normally the $T$ function is about reasoning.
There is little reasoning to do in our scenario except to get to the goal as
soon as possible.
The thinking functions $T$ do this without paying any attention to
perlocutionary speech acts.

\cleared
We could say that while feeling is concerned with perlocutionary speech act goals
thinking on the other is concerned with symbolic goals.
To model the goals of the thinking functions we will introduce the set of goals
in an agents believe base $\Phi$. Where a single goals $\phi \in \Phi$ consists of
$\phi = (a, s)$ a symbol uttered by a particular agent.
Then there also exists the function that can compare goals with each other:
\[\phi_1 \to \phi_2 \to b \]
where $b \in \{ \top, \bot \}$ is a boolean, true or false that determines if
the first goal is more important then the second.
This function is asymmetric.
Finally there is a function that determines if a goal is completed or not:
\[\phi \to b\]

\cleared
Now to begin with $T_e$.
It sees the problem to solve as the conversation itself.
Therefore it will consistently choose speech acts that could help the partner to
progress the scenario.
So it wants to put the partner in a position where he has
almost no other options except to progress the scenario.
If it encounters a child node with a goal $\phi$ in it it will give priority to that.
If there are multiple goals in the options the comparison function can be used
to determine the most important one.
Scenario progression is measured with help of scenes.
If an option changes scene we assume it progresses scenario.
This comes secondary to finding goals.

\cleared
To model $T_i$ however the most obvious solution would be to implement an
axiomatic logic system.
This is however rather heavy on maintenance.
Every agent would need to have their own axiomatic system to determine what to
do for each node in the symbol graph.
The only real solution would be to create this dynamically somehow,
but this is out of scope of this thesis.
Therefore we looked for an alternative.

\cleared
$T_i$ wants to help the conversation partner to analyze the problem according
to the partner's own internal logic framework,
and to do this it wants to give as much options as possible to the partner.
Therefore it will choose the speech acts that produce the most symbols for the
partner.
To do this it will sort the child nodes according to as much unique symbols as
possible.

*** Believes overview
<<Believes overview>>
\cleared
We listed the function attitudes $f_a$ and their required information into
table [[tab:fa-and-data]]. 
Therefore $B = (h, [u], \Phi, G, a, G', h')$.
For reference a symbol table of all introduced symbols is shown
in table [[tab:symbols]] in appendix [[Symbol overview]].

#+CAPTION: Function attitudes and their required data.
#+NAME:   tab:fa-and-data
| Function | required data                                                        |
| $T_e$    | The set of goals $\Phi$, scene information and $G$                      |
| $T_i$    | The set of goals $\Phi$, and $G$                                        |
| $F_e$    | Utterance history [u] and $G$, self believe $a$, learned values $h'$ |
| $F_i$    | Personal values  $h$                                                 |
| $S_e$    | $G$                                                                  |
| $S_i$    | Utterance history $[u]$ and $G$, and learned graph $G'$              |
| $N_e$    | $G$                                                                  |
| $N_i$    | $G$                                                                  |

*** Turn taking
<<Turn taking>>
\cleared
In the naive approach we modeled turn taking with a simple round robin strategy. 
Basically the irrational functions would only consider options that change
actor between plies. 
This makes it however difficult to model agents that hold long monologues,
which happens to for example Susie from the test scenario.
You could do it by making just more symbols that hold all these utterances in
one. However this is very inflexible.
So to solve this problem we make alternation whenever there is a tie between
two options. So irrational would leave out the option that doesn't alternate,
and rational would prefer alternation when possible.

*** Function ply depth
<<Function ply depth>>
\cleared
A big issue that turned up was at which level function ought to operate.
We have a two pass architecture, where functions can inspect the dialogue tree
before passing it to the /next/ function, but they can also inspect the result
of the /next/ function.
The reason for the two pass architecture is explained in section [[Rational and irrational]].
However it didn't treat another issue in dept, which is:
How does a function know at which level it should operate?

\cleared
In a naive approach we tried an implementation where irrational functions
will by default go down the left (most preferred) path to a leaf node and then
generate more meanings,
and the rational functions will sort the one layer above the leaf layer.
This has a problem in that it would make a rational function in the first
position the least relevant function,
since in the first pass it does nothing and when everything
goes back it works at one level above the leaves,
but it should be the *most* relevant.

\cleared
Another approach is to use outside information to determine height.
Basically we would put into the believes the order of functions.
With this information and the dialogue tree we can calculate the
right level to operate upon.
A question then remains is if the rational should sort everything even below
its level or just its level. 
This can be answered however,
rational should sort its level and everything below it,
because we can expect multiple responses if the same actor comes up first,
so in this case we want the dominant rational function to sort those replies too.
Then we want the lower level also to be of the most important rational function.
The 'deeper' less important rational functions only have a guiding role for 
irrational functions after them.

\cleared
We could also let the rational functions sort the entire tree,
and let irrational always extend the most preferred option.
At first glance this idea would make order for rational functions irrelevant.
Perhaps this isn't the case however,
since a lower level rational function would still guide which part of the tree
get extended.

\cleared
So there are two methods of dealing with this issue.
Firstly we can let rational functions just let everything be sorted,
but then the deeper rational functions will become less relevant.
Secondly we can let functions operate at a particular level based upon their
position in the personality.
We chose to do the latter,
because we thought this would make earlier rational functions more influential.
With this particular choice we can also make a decision about whether a function
should operate at a particular height,
or go downward trough the entire tree,
we chose to let it go downward because then the personality will be more
consistent in its choices if it wants to utter lower level replies.
Note however that deeper rationale functions can still have effect by virtue of
deciding which actions are generated indirectly.

\cleared
To calculate an operation height, we need to know the function order,
then the function itself and finally the height of the dialogue tree.
Which results in the following:
\[ [F_a] \to F_a \to i_{D_{\text{height}}} \to i_{\text{operate level}} \]
Where $F_a$ is the Jungian function,
$i_{D_{\text{height}}}$ is an integer which indicates the height of the dialogue tree
and $i_{\text{operate level}}$ is the suggested operation height.
To do this we group the functions in function attitude pairs,
the result is the pair index of the input function function pair,
plus one if the second value of the pair is rationale,
/and/ the input function is rationale,
otherwise its the pair index.


** Consistency with theory
\cleared
In this section we will explore if especially INTJ and ENTJ (MBTI) types would
produce different actions by analyzing when the functions would act.
We will only look at the first two functions because it is enough:
The first two functions of INTJ are:
\[N_i > T_e \]
And of ENTJ they are:
\[ T_e > N_i \]

\cleared
What we would expect is that the $T_e$ and $N_i$ produce different results
because of the order they are in the sequence.
So in case of ENTJ if $T_e$ receives an meaning $M_t$ from the user
it will pass it directly to the next function since it can't make decisions
based on a single meaning. Then once the $N_i$ function returns a reply
(which has the entire meaning tree in it) it can judgments based on these 
meanings producing a final reply.
In case of INTJ the $N_i$ function would generate the meanings based on its
data structure and pass this tree with the children to $T_e$ to assign values
to it.
Then it can either return this result or pass it to the /next/ function and
judge these results again.

\cleared
In any case the main difference is that an INTJ $T_e$ function gets to
value before the other functions get a chance to do anything. In case of an
ENTJ it is always just a final judgement.

\cleared
INTJ and INTP are different in attitudes, but have the same order.
Since attitudes produce a different process by definition
(see section [[Mapping to process]]),
we can conclude that they will also behave differently.


\clearpage
* Architecture
<<Architecture>>
\cleared
To combine the ideas discussed in section [[Jungian BDI]] with the existing program,
some big architectural changes were introduced.
For example the Alice bot was completely removed in favor of a new less tightly
coupled scheme.
The drools have become the center of deliberation (which previously was the AIML).
We will discuss these changes in this chapter.

\newlyCleared
In this chapter we will discuss two architectures,
the first is the architecture which is actually implemented, this deals with a
single agent and the user.
Secondly we will discuss the $N$-agent architecture which is capable of dealing
with more than one agent (and the user), this is called the multilogue
architecture.
The reason for discussing both is that the ideas discussed in section
[[BDI and Jung]] could be applied to an $N$-agent architecture.
However there are some pragmatic problems with this discussed in section
[[Multiple conversation partners]].
Therefore we held of on implementing this and just describe how it could be done
instead.
In section [[Implemented architecture]] we will describe the main architectural
changes between the current implementation and the original architecture
discussed in section [[The serious game]].
Note that we want to keep as much of the existing architecture as possible.

\cleared
There are also several items we won't discuss in this chapter because they
haven't changed, these include the protocol,
and the Wildfly server and the unity client.
** Deployment diagram
<<Implemented architecture>>
\cleared
A deployment diagram of the architecture can bee seen in figure
[[fig:architecture-concept]],
where the dashed arrow means constructs,
the solid arrow means uses and the other lines mean interacts.

#+NAME: fig:architecture-concept
#+BEGIN_SRC plantuml :cache yes :file img/uml/architecture-concept.png :exports results

  folder bot{
    cloud drools {
      component score
      component scenario
      component interpreter
      storage facts
      scenario -- facts
      interpreter -- facts
      score -- facts
      component emotions
      component personality
      emotions -- facts
      personality -- facts
    }
    database meanings [
      patterns
      ====
      symbol graph
    ]
    entity filereader
    filereader ..> meanings
    drools --> meanings
  }
  node server
  node client

  server "1"-- "1..*" bot
  server  -- scene
  server  -(0)- client
#+END_SRC
#+CAPTION: Deployment diagram of implemented architecture
#+LABEL: fig:architecture-concept
#+RESULTS[f680066f7943af2a2abf4c0b6a487ffa49d6b619]: fig:architecture-concept
[[file:img/uml/architecture-concept.png]]

\cleared
The biggest difference from the original architecture is the removal of
distinction between drools and the chat bot.
In the new architecture we make all information in the files available to
the drools in a big database.
This is starkly different than the architecture used in section [[
Server architecture]].
As can be see in section [[user utterance processing]], 
int the old architecture, the reply for a message is already determined before
drools had a chance to do deliberation.
What's even worse is that if the drools want to utter a spontaneous utterance,
then it has to be encoded in a string inside the drools themselves.
This means the strings facing the user are spread over both the AIML files
*and* the drools.
This is confusing for new scenario creators since completely different folders
have to be accessed to change the strings.
# This violates the changeability design principle quite heavily and unnecessarily. \todo{cite}

\cleared
The changes proposed here, result in a much more simple architecture.
Only one place does deliberation rather than two and only one API is used for
generating responses, whereas previously drools could generate replies, /and/
the AIML bot.

\cleared
Note that although we removed the ability for the bot to use AIML, it should be
relatively easy to convert from the old AIML structure to the new format with help
of a script.
A proof of concept of this has been made of this in section [[Conversion script]].
** Data structures

#+BEGIN_QUOTE
Bad programmers worry about the code.
Good programmers worry about data structures and their relationships.

  -- Linus Torvalds cite:linusbadgoodprogrammersquote 
#+END_QUOTE

\cleared
In this subsection we will discuss the main data structures used to implement
the ideas from section [[BDI and Jung]].
We use class diagrams to accomplish this which are based upon UML cite:fowler2004uml.
Before we do this I would like to point out several things to keep in mind.

\cleared
Firstly, we do not show everything precisely such as implemented in the code,
because that would clutter the diagrams.
What we do model is all relevant information in structures and the relationship
between those, following the words of Torvalds.

\cleared
Secondly, its better to think of the classes shown here as data structures,
the fields are set to public in cases where immutability was possible.

\cleared
Thirdly we split up the class diagram into several because of space,
the model has become rather big.
There exists a real separation like this in the code base, the lower level
components are in the =salve_drools= projects, whereas the higher level
components are in the =salve_personality= package.
The reason for this separation is that currently, the bot will simply
not function without the low level components,
but you can make it function without the high level components.
Which in practice is done with the low level replies.

\cleared
Finally note that we use $[\dots]$ for list and $\{\dots\}$ for set in the
class diagrams, to save space.

*** Low level diagram

\cleared
In figure [[fig:droolclass]] the diagram containing the low level data structures
used. These are the basic assumptions, or building blocks the implementation
is constructed from.

#+NAME: fig:droolclass
#+BEGIN_SRC plantuml :cache yes :file img/uml/droolclass.png :exports results
  enum PerlocutionaryValue
  class PerlocutionaryValueSet{
    +perlocuationaryValues:{PerlocationaryValue}
  }
  PerlocutionaryValueSet --* "*" PerlocutionaryValue

  package db{
    class ConnectionDatabase
    class PatternDatabase 
  }
  PatternDatabase --* "*" PatternSymbol
  PatternDatabase --* "*" Scene
  ConnectionDatabase --* "*" Symbol
  ConnectionDatabase --* "*" Connection

  class Actor {
    +name:String
  }
  class Connection {
    +to:Symbol
    +restricted_to:Actor
    +values:PerlocationaryValueSet
  }
  Connection --* Symbol
  Connection --* Actor
  Connection --* PerlocutionaryValueSet
  class Goal{
    +toSay:Inforamtive
    +utility:int
    +isGoal(utterance:Utterance):boolean
  }
  Goal --* Informative
  class Informative{
     +what:Symbol
     +who:Actor
  }
  Informative --* Actor
  Informative --* Symbol
  class PatternSymbol{
     +pattern:Pattern
     +symbol:Symbol
  }
  PatternSymbol --* Symbol
  class PersonalValues{
     -values:EnumMap<PerlocutionaryValue, Integer>
  }
  PersonalValues -* "*" PerlocutionaryValue
  class Scene {
    +name:String
  }
  class Symbol {
    +name:String
    +scene:Scene
    -literals:[String]
  }
  Symbol --* Scene
  class Utterance{
    +informatvie:Informative
    +perlocutionaryValues:PerloctionaryValueSet
    +when:Instant
  }
  Utterance --* PerlocutionaryValueSet
  Utterance --* Informative
  PerlocutionaryValueSet -[hidden]-> PersonalValues
#+END_SRC
#+CAPTION: Class diagram of the low level model
#+LABEL: fig:droolclass
#+RESULTS[1c677a21ef92d9dff7fc9ff5dfca6512d4f6c4d0]: fig:droolclass
[[file:img/uml/droolclass.png]]

\cleared
From figure  [[fig:droolclass]] we can clearly see the importance of the =Symbol=
structure in the application.
Simply by counting the amount of structures that consist of it,
and of course it is a very important structure because it is the building
block that gives understanding to the implementation.
As described in section [[BDI and Jung]] we map strings into user symbols,
and we can map symbols back to strings again.
An overview of the relationship between the theoretic representation
and the implementation for this class diagram can be seen in table
[[tab:jung-class-relation-drool]].

#+NAME: tab:jung-class-relation-drool
#+CAPTION: Overview of section [[BDI and Jung]] symbols and their class representations
| Symbol | Corresponding Class                                                                                                                               |
|--------+---------------------------------------------------------------------------------------------------------------------------------------------------|
| $\sigma$    | =String=                                                                                                                                          |
| $s$    | =Symbol=                                                                                                                                          |
| $g$    | =PatternSymbol=                                                                                                                                   |
| $g'$   | =Symbol=[fn:: The literal strings are used for back conversion, in combination with the MatchedQueryDB described in section [[Before and templates]]] |
| $P$    | =PerlocutionaryValueSet=                                                                                                                          |
| $p$    | =PerlocutionaryValue=                                                                                                                             |
| $a$    | =Actor=                                                                                                                                           |
| $u$    | =Utterance=                                                                                                                                       |
| $c$    | =Connection=                                                                                                                                      |
| $h$    | =PersonalValues=                                                                                                                                  |
| $\phi$    | =Goal=                                                                                                                                            |

\cleared
Something that was thought about is how similar a =Connection= is to an
=Utterance=. Except for the =instant= field, they are the same
(note that the =informative= field of utterance is the same as the =to= and
=restricted_to= fields of connection).
However their semantics are clearly different.
A connection entails a possibility of an utterance, but it does /not/ mean it
will be uttered. Whereas an utterance is a used connection, that possibility
became a realization.
Therefore, we were right to distinct them at type level.

\cleared
These considerations become especially important when structures are
essentially the same, as we can see with the =Scene= and =Actor= classes.
The only thing they contain are a String.
Even the field names are the same!
Are we correct to treat these as distinct classes?
We argue yes because they entail completely different semantics,
the =Scene= class is used to group symbols and patterns,
whereas the =Actor= class is used to identify actors.

\cleared
The next question would be: Should we use an inheritance relation to make our
code more DRY cite:thomas2010orthogonality (don't repeat yourself)?
For by example introducing an abstract class =ANamed= and letting
=Actor= and =Scene= be extended from those.
We argue no, because introduces more complexity than that we would save on code
reduction.
It would also open up to possibility to use the implicit covariant relationship,
resulting in functions that could accept an =ANamed= argument for example.
As soon as client code starts using that, the single inheritance 'slot' Java
provides is occupied forever,
or at least until a major refactor occurs.

*** Believes and DialogueTree
<<Believes and DialogueTree>>
\cleared
In figure [[fig:jungclass]] we can see the higher level structures of =Believes= and
=DialogueTree=. Note that we significantly simplified all lower level components
in this figure to save space.

#+NAME: fig:jungclass
#+BEGIN_SRC plantuml :cache yes :file img/uml/jungclass.png :exports results
  class Believes{
    +programmedConnections:ConnectionDatabase
    +learnedConnections:ConnectionDatabase
    +goals:{Goal}
    +values:PersonalValues
    +learnedValues:PersonalValues
    +actors:{Actor}
    +previousUtterances:[Utterance]
  }
  class DialogueTree{
    +options:[DialogueTree]
    +utterance:Utterance
    +connection_used:Connection
  }
  package drools{
    package drools.db{
      class ConnectionDatabase
    }
    ConnectionDatabase --* "*" Connection
    class Actor {
      +name:String
    }
    Believes -* "2" ConnectionDatabase
    Believes --* "*" Goal
    Believes --* "2" PersonalValues
    Believes --* "1..*" Actor
    Believes --* "*" Utterance
    class Connection {
      +to:Symbol
      +restricted_to:Actor
    }
    Connection --* Actor
    DialogueTree --* "*" DialogueTree
    DialogueTree --* Utterance
    DialogueTree --* Connection
    class Goal{
    }
    Goal --* Utterance
    class PersonalValues{
    }
    class Utterance{
    }
    Utterance --* Actor
  }
  DialogueTree -[hidden]-> drools
#+END_SRC
#+CAPTION: Class diagram of the high level model
#+LABEL: fig:jungclass
#+RESULTS[212259f430fea1f6c765e388f698bb1c14824598]: fig:jungclass
[[file:img/uml/jungclass.png]]

\cleared
From [[fig:jungclass]] we can see the main clients of the low level drool package
is indeed the =Believes= class and after that the =DialogueTree=.
=Believes= provide the Jungian functions with bounded information about the mind
of the chat bot as discussed in section [[BDI and Jung]].
In table [[tab:jung-class-relation-dialogue]] we can see the relationship
between theoretic representation and that of this class diagram, excluding
the ones discussed in previous section.

#+NAME: tab:jung-class-relation-dialogue
#+CAPTION: Overview of section [[BDI and Jung]] symbols and their class representations
| Symbol | Corresponding Class |
| $B$    | Believes            |
| $D$    | DialogueTree        |

\cleared
The =Believes= structure is very peculiar, because it doesn't represent a single
idea or use case. Instead its just a combination of various elements that are
required for the Jungian functions to operate.
But none of the functions use /all/ fields,
so they get in essence just too much information.
In fact, it is extremely similar to how the drools fact base operates.
But the drools have a built in mechanism to make sure individual rules
don't get all information (the when clause) \todo{cite or refer to background}.
So an argument can be made to remove the =Believes= structure and replace it with
the drool fact base.
This hasn't been done, because it would be a very invasive operation,
currently the Jungian functions have the Believe structure in their signature.
This can then be replaced by what they individually need,
rather then what they as a whole need.
With that change the personality functions could be flattened to drool rules,
which would make the architecture even more simple. \todo{Why is this good? or refer to section that discusses this}

\cleared
The =DialogueTree= structure is however a whole other beast.
It provides a well defined structure, and some utility methods that make tree
navigation much easier.
These methods aren't shown in the figure because their type signatures are
rather big. \todo{But we discuss them in the implementation? Refer to that}

*** db package
\cleared
In figure [[fig:dbclass]] the databases are shown.
This is a sub package of the model.
The database is best seen as an immutable hash map. It also provides some extra
java8 features,
such as returning an optional rather than null-able type for the get method.
The concrete implementations of database can add extra behavior once the type
value of the generic parameters is known which is done by connection database
for example.

#+NAME: fig:dbclass
#+BEGIN_SRC plantuml :cache yes :file img/uml/dbclass.png :exports results
  package drools.db{
    abstract class Database<Key,Value>{
      -values:Map<Key,Value>
      +get(key:Key):Optional<Value>
      +getOrThrow(key:Key):Value
      +keys():Stream<Key>
      +values():Stream<Value>
      +entries():Stream<Map.Entry<Key,Value>>
    }
    class ConnectionDatabase<Symbol, {Connection}>{
      +getAllowedConnections(name:Symbol, role:Actor):Stream<Connection>
      +getFromTo(from:Symbol, to:Symbol):Optional<Connection>
      +putInCopy(symbol:Symbol, connections:Connection...):ConnectionDatabase
      +createDual():ConnectionDatabase
    }
    class PatternDatabase<Scene, {PatternSymbol}>
    class SymbolDatabase<String, Symbol>
    ConnectionDatabase --|> Database 
    PatternDatabase --|> Database 
    SymbolDatabase --|> Database 
    ConnectionDatabase -[hidden]-> PatternDatabase
  }
#+END_SRC
#+CAPTION: The database package
#+LABEL: fig:dbclass
#+RESULTS[a2e3cbdbbab42de8a4c6c9d166b2ef419283222c]: fig:dbclass
[[file:img/uml/dbclass.png]]

\cleared
=SymbolDatabase= is the first database constructed during the initialization
phase.
From this the other two databases can be more easily constructed since they 
can lookup symbols in the =SymbolDatabase=, rather than worrying about construction
of new ones.
This class is the realization of $\mathcal{S}$ from section [[BDI and Jung]].

\cleared
=PatternDatabase= can store patterns based upon a =Scene=.
There are actually two constructed of these,
the first one constructs the patterns that are in a scene,
and the second one constructs patterns that are of scenes where the current
scene is connected to.
For example if there exists a connection form a symbol in scene A to a symbol
in scene B, the patterns from the symbol in scene b are stored in the key of
scene A.
This second database allows scene transitions to occur.
However to construct this second database the connection database is required.

\cleared
=ConnectionDatabase= is a database that stores a connection set from a
symbol. 
This class is analogous to the symbol graph $G$ from section [[BDI and Jung]],
it is used to determine what the bot could say, and what it thinks its speech
partner can say.
This database has a special method named =createDual= which is used to create
a connection database where all the connections are flipped.
This is used to create the second pattern database,
it made looking up the required patterns much easier.

*** Jung in Java
\newlyCleared
To implement the theory presented in section [[BDI and Jung]],
several issues had to be overcome.
First of all Java has no native support for doing partial application.
We worked around this Issue by introducing a structure that contained the
arguments of the $f_a$ function described in section [[Mapping to process]].
The structure is called =JungFuncArgs= and can be seen in figure [[fig:jungjavaclass]].
The next issue was doing Functional composition,
and although we can do this in Java with anonymous classes, 
we wanted to make the relation more explicit.
The =NextFunction= and its respective field in =JungFuncArgs= is this explicit
relation.
Adding this field to the =JungFuncArgs= makes the functions a true endomorphism, 
although it deviates from the theory since the result now also has a next function.
This also introduces an infinite creation sequence,
there always needs to be a next function.
To break this the =UnitNextFunction= was introduced.
An argument can be made for using the =null= reference instead,
however this is considered a bad practice cite:nullrefsarebad.
Finally for testing purposes we needed to be able to inject other functions
than the ones defined in the =JungianFunction= enum.
Therefore the =JungFuncAccessor= interface was introduced.
This allows unit test to check if the next function was called for example,
but the architecture also becomes more extendable because of this.

\newlyCleared
Figure [[fig:jungjavaclass]] shows the elements required for java to apply an $f_a$.
To do this we first create a =JungFuncArgs= structure with its =create= method.
Then we insert the Jungian functions we want to apply.
This is a list of elements of the =JungianFunction= enum,
these elements aren't shown in the figure because they're just the abbreviated
names of the Jungian functions,
for example Se for extroverted sensing.
The =insertNextFuncs= returns a new =JungFuncArgs= object with the inserted
next functions,
these next functions are not evaluated.
Also note that =JungFuncArgs= is an immutable object,
so the result of the =insertNextFuncs= needs to be used.
To apply the function we use =applyNext()=,
which returns a new =JungFuncArgs= object with the resulting values.

#+NAME: fig:jungjavaclass
#+BEGIN_SRC plantuml :cache yes :file img/uml/jungjavaclass.png :exports results

interface JungFuncAccessor{
  + getFunction() : Function<JungFuncArgs, JungFuncArgs>
}
interface NextFunction{
  + get():Pair<JungFuncAccessor, NextFunction>
}
NextFunction ..> NextFunction
NextFunction ..> JungFuncAccessor

class UnitNextFunction{
  - result:Pair<JungFuncAccessor, NextFunction>
}
UnitNextFunction --|> NextFunction
class JungFuncArgs{
  + believes:Believes
  + tree:DialogueTree
  + next:NextFunction
  {static} + create(one:Believes,two:DialogueTree):JungFuncArgs
  + applyNext() : JungFuncArgs
  + insertNextFuncs(funcs:[JungFuncAccessor]):JungFuncArgs
}
JungFuncArgs --* NextFunction
JungFuncArgs ..> UnitNextFunction
enum JungianFunction{
  - function : : Function<JungFuncArgs, JungFuncArgs>
  + isRational : boolean
}
JungianFunction ..|> JungFuncAccessor
JungianFunction ..> JungFuncArgs
#+END_SRC
#+CAPTION: Jung in Java
#+LABEL: fig:jungjavaclass
#+RESULTS[019dc12edde2e80f03b0ae309525edacf716f1a2]: fig:jungjavaclass
[[file:img/uml/jungjavaclass.png]]

*** Before and templates
<<Before and templates>>
\cleared
After the personality was implemented, we wanted to bring the bot up too
feature parity with the ALICE bot. 
To do this several new data structures had to be introduced which can be seen
in figure [[fig:templateclass]].

#+NAME: fig:cache notemplateclass
#+BEGIN_SRC plantuml :cache yes :file img/uml/templateclass.png :exports results
  class Symbol {
    +name:String
    +scene:Scene
    -literals:[String]
    -required:{TemplateAttribute}
  }
  class Informative{
     +what:Symbol
     +who:Actor
  }
  Informative --* Symbol
  package template{
    abstract class ATemplate{
      +name:String
    }
    TemplateAttribute --|> ATemplate
    TemplateValue --|> ATemplate
    class InsertQuery{
      informative:Informative
      templateAttribute:Match
    }
    InsertQuery --* Informative
    InsertQuery --* TemplateAttribute

    package db{
       CapturedMatchDB --* "*" TemplateAttribute
       CapturedMatchDB --* "*" TemplateValue
       MatchedQueryDB --* "*" TemplateAttribute
       MatchedQueryDB --* "*" TemplateValue
       QueryDatabase --* "*" TemplateAttribute
       QueryDatabase --* "*" InsertQuery
       QueryDatabase .> MatchedQueryDB
    }
  }
  Symbol --* "*" TemplateAttribute
  class Before{
     before:Optional<Before>
     informative:Informative
  }
  Before --* "0..1" Before
  Before --* Informative
  class Connection {
    +to:Symbol
    +restricted_to:Actor
    +values:PerlocationaryValueSet
    +before:Optional<Before>
  }
  Connection --* Before
  Connection --* QueryDatabase
  class Utterance{
    +informatvie:Informative
    +perlocutionaryValues:PerloctionaryValueSet
    +when:Instant
    +caputeredDB:CapturedMatchDB
  }
  Utterance --* Informative
  Utterance --* CapturedMatchDB

#+END_SRC

#+CAPTION: Before and template class diagram
#+LABEL: fig:templateclass
#+RESULTS[ee21800363fb4f9f8eb99a40012ae803d4facae7]: fig:cache notemplateclass
[[file:img/uml/templateclass.png]]


\cleared
We can see from figure [[fig:templateclass]] that the consumers of these extensions
are the =Symbol= class, the =Utterance= class and the =Connection= class.
What also can be deduced is that the before extensions was probably a lot
easier to realize than the template extension, simply by counting the amount
of classes it introduced and modified.
Whereas the template required the modification of at least three existing data
data structures, the before only required to modify the =Connection=.

\cleared
So the before class is self recursive,
something which we've seen earlier in the =DialogueTree= class for example,
however this is just an optional self recursive relationship.
What it does is lay a restriction on =Connection=, the =Informative= in the optional
=Before= has to be uttered before this connection can be used.
See section [[That tags]] for a more in depth explanation.

\cleared
The template system does something else. It introduces the ability to match
variables from the regex and re-insert these as a template into existing symbols.
This is explained in depth in section [[Star tags]].

*** Support types
<<Support types>>
\cleared
Because we are working with drools,
we often use a technique of wrapping values into other types,
to signify their progress in drools deliberation.
Basically we use types as labels to indicate progress.
These types can either be defined in Java or drools.
If they are defined in Java, both Java code and drools code can use it.
If they are defined in drools, only drools code can use it.
In figure [[fig:supportclassjava]] we can see the supporting types defined in
java and the relations they have with types defined in previous sections.
We can see the types that are defined in the dialogue drools package in figure
[[fig:supportclassdrools]]
and that of the personality specific drools in figure [[fig:supportclassperson]].

#+NAME: fig:supportclassjava
#+BEGIN_SRC plantuml :cache yes :file img/uml/supportclassjava.png :exports results

package model{
class Symbol
  package template.db{
    class CapturedMatchDB
  }
}

package drools{
  class UnparsedUserUtterance{
    +value:String
  }
  class SymbolCapture{
    +symbol:Symbol
    +db:CapturedMatchDB
  }
  SymbolCapture --* Symbol
  SymbolCapture --* CapturedMatchDB
  class ParsedUtterance{
    +captured:[SymbolCapture]
  }
  ParsedUtterance --* "*" SymbolCapture

}

#+END_SRC

#+CAPTION: Supporting types in Java
#+LABEL: fig:supportclassjava
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[55010ae4b3d6cee5b4d1420c002d4a5dd2704576]: fig:supportclassjava
[[file:img/uml/supportclassjava.png]]

\cleared
The classes described in figure [[fig:supportclassjava]] have the primary function
of starting the deliberation process.
With =UnparsedUserUtterance= the initial utterance is inserted, and with
=ParsedUtterance= it is translated to an understood symbol list.
With these symbols the =CaputerMatchDB= is stored, which is later used to create
an =Utterance= from.
This isn't done immediately because the =Believes= structure is
required to create the utterance.
We for example need to know which connection was used to get to this point in
the conversation to figure out the =PerlocationaryValueSet=.

#+NAME: fig:supportclassdrools
#+BEGIN_SRC plantuml :cache yes :file img/uml/supportclassdrools.png :exports results

package drools{
  package model{
    class Symbol
    class Utterance
    package template.db{
      class QueryDatabase
    }
  }
  class UnparsedUserUtterance
}
package dialogue{
  class DefaultReply{
    symbol:Symbol
  }
  DefaultReply --* Symbol
  class PreProcessed{
    utterance:Utterance
  }
  PreProcessed --* Utterance
  class Reply{
    with:Utterance
    insertQueries:QueryDatabase
  }
  Reply --* Utterance
  Reply --* QueryDatabase

  class Parsing
  class FinshedProcess
  class InScene{
    source: UnparsedUserUtterance 
  }
  InScene --* UnparsedUserUtterance 
  class NeigbourScene{
    source:UnparsedUserUtterance 
  }
  NeigbourScene --* UnparsedUserUtterance 
  
  Parsing -[hidden]-> NeigbourScene
  NeigbourScene -[hidden]-> InScene 
  PreProcessed -[hidden]-> DefaultReply

}
#+END_SRC

#+CAPTION: Supporting types in the dialogue drools package
#+LABEL: fig:supportclassdrools
#+RESULTS[11d3c6965221f225c096b4456d706c30e2bbe884]: fig:supportclassdrools
[[file:img/uml/supportclassdrools.png]]

\cleared
By studying figure [[fig:supportclassdrools]] we can start to understand what is
going on inside the drools.
We can for example see that a distinction is made for when a result matches
an in scene pattern or a neighbouring scene pattern.
These structures are of course there to do Scene switching.
We can also see that to create a reply we need to have a =QueryDatabase=.
This is the result of the template match searched in the utterance history.

#+NAME: fig:supportclassperson
#+BEGIN_SRC plantuml :cache yes :file img/uml/supportclassperson.png :exports results
package model{
  class Believes
  class DialogueTree
}

package personality{
  class PersonalityProcess{
    +under_consideration: DialogueTree
    +believes:Believes
    +functionTasks:[]
  }
  PersonalityProcess --* Believes
  PersonalityProcess --* DialogueTree
}

#+END_SRC

#+CAPTION: Supporting type in the personality drools package
#+LABEL: fig:supportclassperson
#+ATTR_LATEX: :width 0.5\textwidth
#+RESULTS[b074494c2edcbfd3dacf2340a12faa839b869329]: fig:supportclassperson
[[file:img/uml/supportclassperson.png]]

\cleared
In figure [[fig:supportclassperson]] we can see the drool defined =PersonalityProcess=.
This structure tracks traversing the Jungian Functions.
We manage this inside drools to give other rules the opportunity to inspect
the deliberation process while its going.

\FloatBarrier
** Initialization
\cleared
Dealing with cyclic immutable data structures is a problem.
If we were to store the connections in the nodes,
and a cycle would occur,
updating the first node would invalidate the second node.
A way of working around this problem is by letting the connections point to an
address of the node, rather than the object itself.
Another way of working around such a problem is having a mutable,
cooking phase, and after that make the object immutable cite:zibin2010ownership.
This is in essence what we do with the =Database= structure.
We construct its data first with a standard java =HashMap=,
and once this is complete we wrap this into the =Database= class.
Which makes a shallow copy and has no api for mutation (see [[fig:dbclass]]).

\cleared
This initialization problem is the reason why we chose the order of
initialization shown in figure [[fig:initjung]].
The cyclic structure we want to create is the symbol graph $G$.
So we start with the nodes in the graph,
which are the symbols by constructing the symbol database.
All symbols are constructed and put into the symbol database with as key a
string containing the scene name and symbol name.
In essence we are using now as an address the scene name and symbol name.

\cleared
Once we have the symbol database we can use it to create connections from it.
As seen in figure [[fig:droolclass]],
connections consist of a symbol object its going too,
and the key value of a connection database is a symbol too (see [[fig:dbclass]]).
So to satisfy these values we just do a lookup in the symbol database.
So we changed the address, rather than it being the scene and symbol name,
its the symbol object in itself.
Since the connections are not stored in the symbols this is possible
without making the symbols mutable.

\cleared
Finally the pattern databases are constructed.
Patterns were after reading the symbols already put into a =HasHmap=,
with as key the symbol and as value the set of patterns.
So the only things that needs to happen for the in scene patterns database is to
group them by scene.
For neighbouring scene patterns however connections are required.
The reason for postponing these to the end of construction is because the
neighbouring scene pattern database requires the knowledge of connections to be
constructed.

#+NAME: fig:initjung
#+BEGIN_SRC plantuml :cache yes :file img/uml/initjung.png :exports results
  |WebSocket|
  start
  :Receve StartGame message;
  |#CCDDDD|Engine|
  :Start kie thread;
  |#AntiqueWhite|File reader|
  :Read symbol files;
  :Construct symbol db;
  :Read connection files;
  :Construct connection db ;
  :Read believe file;
  :Construct patttern dbs;
  |#CCDDDD|Engine|
  :Insert file reader results into drools;
  |WebSocket|
  :put game id in websocket user prefs;
  stop
#+END_SRC
#+CAPTION: Activity diagram of a server game construction
#+LABEL: fig:initjung
#+RESULTS[c422b040ae5246a7ecdb58bed350e5cb68d716bd]: fig:initjung
[[file:img/uml/initjung.png]]

** Operation
\newlyCleared
To understand how the operation of a bot works,
we can look at it from the point when a message is received
and walk trough the steps it takes.
An outline of this process is giving in the figure [[fig:insert_meaning]].
Together with the outline and the figures defined in section [[Support types]],
we can quite precisely explain what is going on.
 
 #+NAME: fig:insert_meaning
 #+BEGIN_SRC plantuml :cache yes :file img/uml/insert_meaning.png :exports results
 |WebSocket|
 start
 :Receve message;
 :Insert into KIE;
 |#CCDDDD|Drool|
 :Pattern match symbol from message;
 if (quick response rules?) then (yes)
 :Do quick reply;
 |WebSocket|
 stop
 endif
 |#CCDDDD|Drool|
 repeat
 :Create initial dialogue tree;
 while (has next function in personality)
 |#AntiqueWhite|Personality|
 :execute jungian function;
 |#CCDDDD|Drool|
 endwhile
 while (has previous function in personality)
 |#AntiqueWhite|Personality|
 :execute jungian function;
 |#CCDDDD|Drool|
 endwhile
 :Get reply from dialogue tree;
 if (Most preffered response is from self?) then (yes)
 |WebSocket|
 :Send reply;
 |#CCDDDD|Drool|
 else
 endif
 repeat while (Reply send?) is (yes)
 |WebSocket|
 stop

 #+END_SRC
 #+CAPTION: Activity diagram of deliberating on a user message
 #+LABEL: fig:insert_meaning
 #+RESULTS[ba2ef7b0333cc8277765f73cc81a4e7ac3846b44]: fig:insert_meaning
 [[file:img/uml/insert_meaning.png]]

\newlyCleared
This operation is starkly different from the one presented in section
[[user utterance processing]],
particularly if you compare the activity diagrams in
figure [[fig:utterance-proccesing]] with figure [[fig:insert_meaning]].
What we can see directly by comparing these is the change in swimming lanes
cite:planumlswimminglanes.
The ALICE swimming lane has been removed completely,
and in its place we've got drools, which has become the figurative center of
the application.
Then the Personality swimming lane was introduced,
this is of course in light of this thesis.

\newlyCleared
Since these activity diagrams are quite detailed in their description of what
is going on,
we made an overview of the key changes in the state diagrams 
presented in figure [[fig:state:aiml]] and figure [[fig:state:yaml]].
In the new architecture, everything happens inside drools.
Only technical things such as dealing with the protocol and setting up the
connection are handled outside drools.
This makes it impossible to bypass it,
and it also opens up more space to do high level deliberations.
Finally since =PatternMatching= is just the execution of another rule,
we're not just limited to just pattern matching schemes in figuring out what
the user said.
Statistical methods could also be used for example cite:jin2009opinionminer,
but this is out of the scope of this thesis.

#+NAME: fig:state:yaml
#+BEGIN_SRC plantuml :cache yes :file img/uml/figstateyaml.png :exports results
  state Drools{
  PatternMatching -> LowLevel
  PatternMatching --> HighLevel
  HighLevel --> Reply
  LowLevel --> Reply
  Reply -> HighLevel
  }
  [*] -> PatternMatching
  Reply -> [*]
#+END_SRC
#+CAPTION: State diagram: Utterance processing with drools
#+ATTR_LATEX: :width 0.5\textwidth
#+LABEL: fig:state:yaml
#+RESULTS[91c67cdcbc4fe5fd0a81ff9cd72c7eddf5ea00be]: fig:state:yaml
[[file:img/uml/figstateyaml.png]]

\newlyCleared
To ensure rules are executed in a particular order we often wrap and unwrap
required data into types, as explained in section [[Support types]].
For example the initial user utterance gets wrapped into an =UnparsedUttarence=
type, before its even inserted into the drools.
This type can be seen in figure [[fig:supportclassjava]].
We could have just inserted a string and not created the type,
but the reason for doing this with the initial string is to make it explicit:
/This string needs to be parsed/.

\newlyCleared
So in drools we can match on this type (see section [[Drools background]]).
Which we do in the next step,
parsing this string with pattern (regex) matching.
This is actually the $\sigma \to s$ operation from section [[Narrowing the model]].
To do this we use the pattern databases from figure [[fig:dbclass]], 
on which we use the active scene as a key (which is stored in the fact base)
and then just match against all from the resulting set,
this results in the =ParsedUtterance= type which can be seen
in figure [[fig:supportclassjava]].
This type then gets inserted into the fact base to continue the process.

\newlyCleared
The =ParsedUtterance= then gets transformed into a =PreProcessed= type.
During this process the duplicates matches are removed.
Each element in the =ParsedUtterance= list gets individually inserted as a
=PreProcessed= type into the fact base.
The reason for this in-between step is because we don't know how to handle
multiple matches.
So we just insert every uniquely matched item.
In contrast to the initial approach where only the first match was used,
this approach is more flexible.
It allows the bot to form opinions about
utterance where it doesn't necessarily wants to reply upon.
For example if it asks the doctor "How are you doing?" the answer of
"I'm good, how can I help you?" or "how can I help you?" should be treated
differently.
It now can also give multiple answers to longer user utterances.
However the disadvantage is that sometimes the bot will give more replies than
desired.

\newlyCleared
As a first priority the low level reply rules can be fired.
What they do when fired is removing the =PreProcessed= type,
so that the high level rules don't get a chance to fire.
This is modelled in figure [[fig:insert_meaning]] as an if else branch,
which is true in practice, but no concrete if else structure is used.
Drools has support for setting priority of execution in rules,
which was used for this.

\newlyCleared
It should be noted that at the point of quick reply personality could also be at
play.
For example people could have alternative ways of pronouncing the response.
Thinking people may for example respond with a confident yes, whereas feeling
people would say it by default in a more doubting tone.

\newlyCleared
The high level processing executes if there is still a  =PreProcessed= type
available, in other words no low level replies were executed.
We create the initial =DialogueTree=, and remove the =Believes=
from the fact base and put these believes into a =PersonalityProcess= which can
be seen in figure [[fig:supportclassperson]].
The reason for removing the believes base is to prevent concurrent modifications.
By removing the Believes structure, rules that use it are no longer executed.
To create a =PersonalityProcess=, a =Believes= structure has to be available.
In this Personality process we also add the =JungianFunction= list,
these are the functions that are extensively described in section
[[Mapping to process]], and its Java adaptation is described in figure
[[fig:jungjavaclass]].
With this list it is determined which function should be executed next upon
the =DialogueTree= and =Believes=.

\newlyCleared
After there are no more functions in the list, we know we are done.
We move to the next step where we get the reply from the DialogueTree.
This is an =Utterance= structure, if this =Utterance= is the same as the
self field in the =Believes= structure, we send the reply by wrapping the
utterance in a =Reply= type.
If we don't send a reply, we insert a =FinishedProcess= type.
If we do send a reply we reinsert the selected =Utterance= as a
=PreProcessed= type.
These types can be found in figure [[fig:supportclassdrools]]. 

** Social practice support
\newlyCleared
Because this entire process is implemented in Drools, and we use types to track
progress. Its relatively easy to add other rules that can modify the process,
without changing the existing ones.
Priority can be used to intercept a rule, as was done with the low level replies.
Adding a more refined implementation of social practice therefore would be
relatively easy.
There exists already some support for the social practice in Drools,
for example the scenes logic, but this is not complete.
Better support can easily be added by adding more rules and tweaking with
priorities.

\newlyCleared
Besides using extra rules to add support for social practice logic,
for the personality part of the thesis specifically there is another possibility.
They can be wrapped in a social practice function,
that analyzes the result of the personality function and then does social
practice operations to the resulting =DialogueTree= or =Believes=.
So based upon the social practice, and the personality function things may
change.

** Multilogue architecture
\newlyCleared
The architecture presented in section [[Implemented architecture]] is for a dialogue
game.
However a social practice does not put limits on the amount of participants,
so what we really want is a multilogue architecture.
Since the presented architecture in section [[Implemented architecture]] is
relatively close to that we shall discuss here how to finish it.
What we therefore will discuss in this section is the required changes to
make it a true multilogue architecture,
and thereby making it easier to implement social practice theory.
Sadly there was no time to do the actual implementation of such an architecture.
A deployment diagram of this architecture can bee seen in figure
[[fig:n-agent-arch]].


#+NAME: fig:n-agent-arch
#+BEGIN_SRC plantuml :cache yes :file img/uml/n-agent-arch.png :exports results

  folder scene{
    cloud sys.drools {
      component score
      component scenario
      storage facts
      scenario -- facts
      score -- facts
    }
  }

  folder bot{
  cloud bot.drools {
    component emotions
    component personality
    component socialPractice
    storage bot.facts
    emotions -- bot.facts
    personality -- bot.facts
    socialPractice -[hidden]-> emotions
    score -- bot.facts
    socialPractice -- bot.facts
  }
  database meanings [
    patterns
    ====
    symbol graph
  ]
  entity filereader
  filereader ..> meanings
  bot.drools --> meanings
  }
  node server
  node client

  server "1"-- "1..*" bot
  server  -- scene
  server  -(0)- client
#+END_SRC
#+CAPTION: Deployment diagram of desired architecture
#+LABEL: fig:n-agent-arch
#+RESULTS[2175bf151e4fe4f5ae54fdba0ca134983678c0d2]: fig:n-agent-arch
[[file:img/uml/n-agent-arch.png]]

*** System vs thoughts
\newlyCleared
What is required of the drools is that we make a separation between the 
multilogue /system/ and agent /thoughts/.
A good step in this direction is the =Believes= structure,
which groups most agent thoughts, at least those used by the high-level system.
Although it should be noted that the =Believes= structure itself also has
problems, this is discussed in section [[Believes and DialogueTree]],
but the gist of its better to replace this structure with a drools fact base
itself.
However what is good about this structure is that it has a self field,
therefore it could be used to identify the agent.
In other parts of the current architecture this is not the case at all.
For example the =PatternDatabase=  are just plainly inserted into the fact base.

\newlyCleared
The naive solution is to just mark every fact with a self field.
Aside from the fact that you now introduce boilerplate code cite:lammel2003scrap,
this has another more serious problem,
it grands the ability for agents to reach each others minds.
Since every believe structure, and thus agent, will live in the same fact base.
This is of course not desirable,
it would defeat the entire purpose of a multilogue system,
at least for the agents.

\newlyCleared
So what we present in figure [[fig:n-agent-arch]] is a different approach.
Basically what we do is separate the system from the thoughts.
The system will be in the =sys.drools= engine, whereas the bot will be in the
=bot.drools=.
These are separate KIE runtimes, but the system has access to the bot.drools
facts so it can do scoring and actually send responses for the bot.
The server can then have multiple bot instances.
In these instances not every fact has to be marked since they have their own
fact base anyway.
The only thing that needs happen is a self fact needs to be inserted,
or the =Believes= structure could be used for that, if that is kept around.

*** Identifying speaker
\newlyCleared
Another big issue is figuring out which agent(s) is being talked to.
There has been some research on this subject,
for example using hand coded selection mechanisms cite:klotz2011engagement,
and statistical mechanisms cite:keizer2013training.

\newlyCleared
Although both these approaches are good options for robots,
we are dealing with an application,
in which we can cheat to get basically nearly 100% correct selection.
What I mean by this is that we can simply modify the user interface,
to let the user select which agent he talks too.
Then the only thing that needs to be done is modifying the protocol so that the
selected agent(s) get the message.
You can of course extend this to select groups of agents,
or make the selection based on some kind of abstraction,
such as the distinction between whisper to an agent or shout to an agent.

\newlyCleared
In the data structures however a more structural change needs to occur,
namely in both the connections and the utterances.
The =Utterance= class need to be extended with to who the utterance was said,
and the =Connection= class needs to get an additional restriction on to whom
this connection can be said too.
These definitions can of course quickly get out of hand,
especially with larger groups,
and therefore it would be wise to define some kind of role mechanism,
for which solutions exist cite:sandhu1996role.

*** Practicalities
\newlyCleared
Then there are some practicalities to consider, that are more at implementation
level.
For example replies should be timed, so that the user won't see suddenly 200
lines of chat messages between two of his conversation partners.
This is relatively complex to do because with multiple bots *and* doing
timed reactions some kind of communication needs to occur between the bots.
This is probably a task for the system,
but it could also be considered a part of the social practice.
Do note that these timed replies should be interruptible by the user.
A different way of dealing with this is just preventing the scenario from
continuing at certain key points until a user reaction occurs.
Deciding which approach is the best is basically a matter of experimentation.

\newlyCleared
Then it should also be noted that the scenarios of the bots should be
specified differently. At least for parts of it, while other parts should be
shareable.
So the YAML files should be specified distinctly per bot, the drools files
distinctly per bot *and* there should be a mechanism to share these.


# empty buffer of figures
\clearpage
* Replacing AIML
<<From strings to meanings>>
\newlyCleared
In this chapter we will discuss AIML in detail,
we will explain why AIML doesn't fit our requirement.
Then we will start analyzing the structure of AIML and see how we can alter it
to make it fit our requirements better.
After that we will introduce a new modeling system,
that is more succinct and flexible then AIML.
Finally we will present a script to convert from AIML to the new format.

** AIML issues
\newlyCleared
Originally, AIML was used for mapping user input to a reply.
However, as explained in section [[Architecture]],
AIML has some problems for our particular use case.
The major two issues are:
+ No way of giving drools space to do deliberation aside from updating the scenario. 
+ No way of accessing the knowledge base from inside drools.
A relatively simple solution to both of these would be to use an XML parser to
load AIML into a data structure and insert it into drools,
however this won't solve the core of our problem:
The way AIML models a conversation makes it hard if not impossible to list
possible actions for an agent at a particular point in a conversation,
therefore no true deliberation is ever possible as long as AIML is used.
As we will see in the coming paragraphs,
trying to adapt AIML to fit the requirements
will transform AIML into something else.

\newlyCleared
To give a good intuition of this issue, we use an example.
Listing [[code:aiml-std-cats]] shows a piece of dialogue modelled in AIML.
This is a pretty standard piece of AIML, no surprises there.
Patterns are used to identify user utterances and attach responses to them.
We created a deployment diagram of the situation seen in figure [[fig:dep:aimlcats]],
which removes the syntax, so that the situation is more obvious.

\newlyCleared
What we can see is that if the user says "Hello" then the bot will reply "Hi".
So what we have here is a mapping function from $\sigma \to \sigma$, where $\sigma$ is a
string (see section [[Narrowing the model]]).
The issue is that once Hello is matched, the answer *must* be Hi.
S-AIML extends this with adding drool tags,
but these are inside the template tags and therefore cannot truly get out of
this relationship.
Unless they were to replace the entire content,
in which case AIML is no longer used as knowledge representation anyway.

\newlyCleared
We're also not modelling the entire conversation.
There is no way for the bot of knowing that his Hi utterance,
could be followed up reasonably with the question "How are you?" for example.
Therefore there is no way for the bot to plan ahead in the conversation,
or have any kind of variations in these plans.
This is of course a problem, because we imagine personality as variations in a
process, or plans (See section [[BDI + Personality]]).

#+CAPTION: Standard AIML categories
#+NAME: code:aiml-std-cats
#+BEGIN_SRC xml
  <aiml>
      <categroy>
          <pattern>
             Hello
          </pattern>
          <template>
             Hi
          </template>
      </categroy>
	  <category>
		  <pattern>
			  How are you
		  </pattern>
		  <template>
			  Not doing too well today.
		  </template>
	  </category>
	  <category>
		  <pattern>
			  How * you
		  </pattern>
		  <template>
			  <srai>How are you</srai>
		  </template>
	  </category>
  </aiml>
#+END_SRC

#+NAME: fig:dep:aimlcats
#+BEGIN_SRC plantuml :cache yes :file img/uml/dep:aimlcats.png :exports results
frame "user says"{
  usecase "How are you" as how
  usecase "How * you" as howstar
  usecase Hello
}

frame "bot replies"{
  storage "Not doing well today." as notwell
  storage Hi
}

how -->> notwell
howstar -->> notwell
Hello -->> Hi
#+END_SRC

#+CAPTION: Deployment diagram of AIML example
#+LABEL: fig:dep:aimlcats
#+RESULTS[0889516e6ef32d64003ace8ae606a81cc01e305d]: fig:dep:aimlcats
[[file:img/uml/dep:aimlcats.png]]

\newlyCleared
There are also some other small problems,
which aren't really that important for this thesis in particular,
but worth mentioning.
Such as with AIML one has to use the AIML based patterns defined by the standard
cite:aimlspec, 
there is no way to use full regular expressions,
or statistical methods.
Another issue that we can't access encoded utterances directly,
so from drools there is no way to do spontaneous utterances unless they're hard
coded strings.
Finally, since drools can be skipped all together (see figure [[fig:state:aiml]]),
the bot could have amnesia about certain utterances,
to prevent this every template tag would need an insert tag,
which is boilerplate code cite:lammel2003scrap.

\newlyCleared
What needs to happen is either to either modify the ALICE bot and AIML to 
work fundamentally different,
or outright replace it with something else.
We chose for the latter,
we did so by first carefully analyzing AIML and deciding which parts we want to
keep,
and which other parts we wanted to remove or change.
The next sections will discuss the thought process to a new representation.

** Analyzing AIML
# Note taht such descriptions are good, show how it was in the old system and
# the thought process towards the new system, so do more of it like this
\newlyCleared
What we want to do is create a mapping function $\sigma \overset{g}{\to} s$
(see section [[Narrowing the model]]).
In our first attempt we will modify AIML to do this.
AIML is primarily a case based reasoner.
It will match on predefined strings or patterns and then "say" the string
that was attached to the pattern.
So we can use AIML to match user input,
but the language has to be modified so that instead of producing a reaction,
it will indicate what the symbol is that was matched.
An example of these changes can be seen if we compare the
listing [[code:aiml-std-cats]] from the previous section with
listing [[code:aiml-symbols]].
The new deployment diagram can be seen in figure [[fig:dep:aimlsyms]].

#+CAPTION: AIML that refers to 'symbols' rather than templates.
#+NAME: code:aiml-symbols
#+BEGIN_SRC xml
  <aiml>
      <categroy>
          <pattern>
             Hello
          </pattern>
		  <symbol>
            Greeting
		  </symbol>
      </categroy>
	  <category>
		  <pattern>
			  How are you
		  </pattern>
		  <symbol>
            StatusInquiry
		  </symbol>
	  </category>
	  <category>
		  <pattern>
			  How * you
		  </pattern>
		  <symbol>
            StatusInquiry
		  </symbol>
	  </category>
  </aiml>
#+END_SRC

#+NAME: fig:dep:aimlsyms
#+BEGIN_SRC plantuml :cache yes :file img/uml/dep:aimlsyms.png :exports results
frame "user sais"{
  usecase "How are you" as how
  usecase "How * you" as howstar
  usecase Hello
}

cloud "symbols"{
  node Greeting
  node StatusInquiry
}

how -->> StatusInquiry
howstar -->> StatusInquiry
Hello -->> Greeting
#+END_SRC

#+CAPTION: Patterns to symbols
#+LABEL: fig:dep:aimlsyms
#+RESULTS[106f5543883a89c0ef55c28146a484e5a0abd7cd]: fig:dep:aimlsyms
[[file:img/uml/dep:aimlsyms.png]]

\newlyCleared
These changes remove the reactive nature of the chat bot,
no longer do patterns indicate what to reply to,
but instead simply what they are.
This example can't be functional of course,
since the symbol graph hasn't been introduced (see section [[symbol graph]]),
so there are no replies.
However we can at least use these to to create the symbol graph from.

\newlyCleared
With this we almost have solved the first problem of not being able to do true
deliberation.
Of course we can't make a reply of this yet since we still have the second
problem to deal with,
how to access information stored in these symbols.
In other words, dealing with the $g'$ function, this is what the next section
deals with.

*** Symbol to string
\newlyCleared
The next step is to consider how we go from symbols back to strings.
What we assume is that the agent already found a symbol to utter,
for example the status inquiry.
This string from a status inquiry is already available in AIML,
they were called template tags.
We just need to separate the literal strings from the catch all patterns
as can be seen in listing [[code:ailm-grouped-literal]].
In this listing we renamed the template tag to literal,
because the name template is very generic.
They function the same:
Provide the string to utter for that particular category,
in other words the $s \overset{g'}{\to} \sigma$ function
(see section [[Narrowing the model]]).

\newlyCleared
In deployment diagram [[fig:dep:aimlliters]] we can see how this works in memory.
Patterns point to symbols, which have the literal utterance available to them.
Since the names of symbols are not the same as the literal content,
we can use terse descriptive names for more verbose content.
Such a property is useful for referring to the symbols from inside the drool
engine.

#+CAPTION: AIML with grouped patterns and string literals
#+NAME: code:ailm-grouped-literal
#+BEGIN_SRC xml
  <aiml>
      <categroy>
          <literal>
             Hello
          </literal>
		  <symbol>
            Greeting
		  </symbol>
      </categroy>
	  <category>
		  <literal>
			  How are you?
		  </literal>
		  <patterns>
			  <pattern>How * you</pattern>
			  <pattern>How are you *</pattern>
		  </patterns>
		  <symbol>
            StatusInquiry
		  </symbol>
	  </category>
  </aiml>
#+END_SRC

#+NAME: fig:dep:aimlliters
#+BEGIN_SRC plantuml :cache yes :file img/uml/dep:aimlliters.png :exports results
frame "user sais"{
  usecase "How are you?" as howq
  usecase "How are you *" as how
  usecase "How * you" as howstar
  usecase Hello
}

cloud "symbols"{
  node Greeting [
    Greeting
    ----
    Hello
  ]
  node StatusInquiry[
    StatusInquiry
    ----
    How are you?
  ]
}


how -->> StatusInquiry
howq -->> StatusInquiry
howstar -->> StatusInquiry
Hello -->> Greeting
  
#+END_SRC

#+CAPTION: Patterns to symbols with literals
#+LABEL: fig:dep:aimlliters
#+RESULTS[8f9d88e8099c1ee4b136d0f0b0d17eb31a02a660]: fig:dep:aimlliters
[[file:img/uml/dep:aimlliters.png]]

\newlyCleared
We can make the syntax from listing [[code:ailm-grouped-literal]] even more terse.
Observe how one category always will have one symbol tag.
If we were to extract the value of this tag and use it as a filename,
we can ensure that each symbol is only declared once.
Then we can also assume that the AIML tags and category tags are implicit.
This results a terse definition as can be seen in listing
[[code:aiml-terse]].
This doesn't include the =Hello= code because that was part of another symbol,
and therefore another file.

#+CAPTION: Terse AIML but illegal XML
#+NAME: code:aiml-terse
#+BEGIN_SRC xml
<literal>
    How are you?
</literal>
<patterns>
    <pattern>How * you</pattern>
    <pattern>How are you *</pattern>
</patterns>
#+END_SRC

\newlyCleared
However the observant reader will know this isn't valid XML
and by extension AIML, since XML requires a single document root tag.
It does specify what we want, and it does so very tersely.
Since we are changing the semantics of AIML drastically we may as well use a
more terse data format in which such a definition is legal.
In the next section we will analyze some possible candidates. 

*** XML vs JSON vs YAML, vs TOML
\newlyCleared
All these languages are standards cite:jsonspec,yamlspec,xmlspec,tomlspec.
However there is a major difference between XML and JSON or YAML, and that is
their intention.
XML is a markup language, whereas both JSON and YAML are data formats
cite:yamlvsxml.
What they all share in common is that they are supposed to be both
human readable and parsable by a computer program.

\newlyCleared
So what we mean by human and program readable is that with relatively little
effort, a human or program can understand what's going on.
Unlike say a binary format,
which first needs to be parsed by a program before a human can understand it
(or with great amount of effort).
Alternatively unlike a human document, such as a book,
a computer program needs to do lots of effort to extract information from that,
whereas a human can just understand it "naturally".

\newlyCleared
Markup languages provide a nice middle ground between human readable and
program readable.
XML does this by inserting tags (metadata, which are usually just annotated
words), that gives meaning for the program,
so that authors can focus on the structure and content of the document
cite:coombs1987markup.

\newlyCleared
In AIML however, no document is constructed.
Its not a story with a lead, middle ground and conclusion,
its more like a key-value pair database or big configuration file.
So since XML was intended to be used for inline document markup,
I will argue that there are better alternatives that focus on key-value based
configuration in particular, such as YAML, JSON or TOML.

\newlyCleared
JSON is by far the best known format of these three remaining contenders.
However JSON has a few significant disadvantages,
for one it doesn't allow comments and it is quite strict.
For example a common acceptable mistake is to have an array with a trailing
comma like: =[1,23,4,]=. This is an error in JSON cite:jsonconfig,
while its relatively easy for a program to notice this is erroneous and
therefore correct it.
The syntax of JSON can be also more terse, which is shown by both YAML and TOML.
Because of these reason we looked at the other two contenders.

\newlyCleared
The reason for choosing YAML over TOML is that YAML is stable,
whereas TOML hasn't reached stabilization yet cite:tomlreadme.
Although the argument TOML has over YAML is that YAML is much more complex,
and can in certain cases be not as human readable cite:yamldisatvantages.
If TOML were to stabilize, its probably better to move to that format instead.
Its unstablility means that the author thinks the representation may change.
Therefore currently the best choice is YAML.
Its relatively easy to move between these standards, if they're stable,
as is shown in section [[Conversion script]].
Therefore a possible future move from YAML to TOML should also be easy.

** Using YAML
\newlyCleared
It was decided conclusively to use YAML instead of AIML for symbol
representation.
How these symbols are represented in YAML can be seen in
listing [[code:yaml-symbol]].
This is only a syntactic change, therefore no deployment diagram is made of
this.

\toReview
Rather than having a literal tag open and close to show what the literal is,
YAML uses a key value structure.
Lists can be indicated by using dashes in front of each item.
Note that we still use the idea of having one symbol per file,
and the symbol name is the filename.
Therefore no =symbol= item is shown in the example.
Quotation marks ="=, are to indicate strings, for certain characters this is 
neccasarry. In other cases YAML does this for you.

\toReview
Note for example that there are multiple literals to choose from.
In the current implementation this is similar to using =random= tags in AIML.
However as can be seen in section [[Low level diagram]],
this list of strings is just available to the implementation.
Therefore social practice could use it for example: if a bot came from "the hood",
he would use "What's up?" instead of "How are you".
This could of course also be influenced by personality.

#+CAPTION: YAML symbol representation
#+NAME: code:yaml-symbol
#+BEGIN_SRC yaml
literals:
  - How are you
  - "What's up?"
patterns:
  - How * you
  - How are you *
#+END_SRC

\newlyCleared
We keep the pattern fields for legacy support.
However its much more easy to just support regular expressions
cite:thompson1968programming.
The reason for this is that they're part of the Java standard library
cite:regexpattern.
What we can do is transform AIML patterns into regular expressions,
and then use the Java standard library to match the patterns.
This will make the patterns more precise,
and give less code to maintain,
an example can be seen in listing [[code:yaml-regexes]].

#+CAPTION: YAML with regular expressions
#+NAME: code:yaml-regexes
#+BEGIN_SRC yaml
literals:
  - How are you
regexes:
  - "How ([a-z])\\w+ you(.*)"
#+END_SRC

\newlyCleared
The example in listing [[code:yaml-regexes]] only matches a single word and allows
for trailing characters.
Note that the example in listing [[code:yaml-symbol]] would've also matched
"How did this became you?", since any character would've matched the star.
Regular expressions can be much more precise in specifying what a wildcard star is,
although they are also a lot more difficult to learn and read.
Therefore both methods will be supported.

\todo[inline]{If we have time we can compare information per character between the new and old method, going from 251 to 131 is quite an improvement}

** Connections
\newlyCleared
Now we've figured out how to represent our basic axioms, the symbols thoroughly,
we can move on to make our model functional again.
So what we have lost in the process are our update rules
(see section [[Dialogue systems]]).
In section [[symbol graph]] we model these as the symbol graph.
However we have not made a syntactic representation of this,
which will be done in this section.

*** Core idea
\toReview
What we do with the symbol graph is re-adding the implicit connection from
AIML between patterns and templates.
Both patterns and templates have now become plain symbols
(see section [[Mapping AIML]]).
If you just have symbols the bot won't know what to do when one of these 
is inserted without extra information.
This is what we represent with connections.
What sensible replies can we give if a symbol is uttered.

\toReview
We will show how this works with help of an example.
In listing [[code:yaml:simple]] we connected the symbols discussed in our original
example from section [[Symbol to string]].
With these connections we can see the situation illustrated as deployment
diagram [[fig:dep:connections]],
note that we removed the patterns because it became to cluttered.
From this we can see that a =greeting= can be replied to with a =greeting= or
with a =status_inquery=.
As we can see there is a choice now once a =greeting= is uttered,
and choice opens up room for personality as a process.

#+CAPTION: Connections grouped into a file
#+NAME: code:yaml:simple
#+BEGIN_SRC yaml
from:
 - greeting
to:
 - symbol: status_inquery
 - symbol: greeting
#+END_SRC

#+NAME: fig:dep:connections
#+BEGIN_SRC plantuml :cache yes :file img/uml/dep:connections.png :exports results
cloud "symbols"{
  node Greeting [
    Greeting
    ----
    Hello
  ]
  node StatusInquiry[
    StatusInquiry
    ----
    How are you?
  ]
}

Greeting -> Greeting
Greeting --> StatusInquiry

#+END_SRC

#+CAPTION: Symbol graph deployment diagram
#+LABEL: fig:dep:connections
#+ATTR_LATEX: :width 0.3\textwidth
#+RESULTS[a863aaaf9c34d5f26c8abaef929dfa2db002ce5e]: fig:dep:connections
[[file:img/uml/dep:connections.png]]

*** Single file
\newlyCleared
Originally we just wanted to stick to the (implicit) AIML approach of connections,
and add them within the symbol files as can be seen in
listing [[code:yaml-connections-intrusive]].

#+CAPTION: Intrusive connections
#+NAME: code:yaml-connections-intrusive
#+BEGIN_SRC yaml
literal: Why are you here
to:
  - need_medicine
  - broken_arms
  - feel_sick
#+END_SRC

\toReview
However we decided against such an approach.
There were two reasons for this,
the first one is that we found out that connections are much more complex
than simple one directional links.
They for example also need to contain perlocutionary values and be marked for 
which agent can use the connection (default being all agents).
The second reason was more incidental, it turns out that if you group all
connections into a single file you can get better overview of which connections
are made.
What we do now is a grouping of connections into their own special file.
Take as an example listing [[code:yaml:complex]] which represents a
connections file of a scene.

\toReview
In figure [[fig:dep:filedconns]] we can see a deployment diagram of the presented
symbol graph.
This is not a complete conversation of course just an expert of a larger model.
Note that its not much harder to read that than the code from listing
[[code:yaml:complex]].
What we can see is that already the connections are quite complex,
as this file grows in size the dialogue becomes harder to manage.
While editing these, tool in text editors such as searching become quite
vital.
In any case it should be less of an issue than in AIML since this syntax is more
terse.

#+CAPTION: Connections grouped into a file
 #+NAME: code:yaml:complex
 #+BEGIN_SRC yaml
from:
 - ask_reason_here
to:
 - restricted_to: patient
   symbol: need_medicine
 - restricted_to: patient
   symbol: broken_arms
 - restricted_to: patient
   symbol: feel_sick
---
from:
 - need_medicine
 - greeting
to:
 - restricted_to: doctor
   symbol: why_need
 - symbol: status_inquery
---
from:
 - greeting
to:
 - symbol: greeting
 - symbol: ask_reason_here
   restricted_to: doctor
 #+END_SRC

#+NAME: fig:dep:filedconns
#+BEGIN_SRC plantuml :cache yes :file img/uml/dep:filedconns.png :exports results
cloud "symbols"{
  node ask_reason_here
  node broken_arms
  node feel_sick

  node greeting
  node status_inquery
  node why_need
  node need_medicine

  ask_reason_here --> need_medicine : a = patient
  ask_reason_here --> broken_arms : a = patient
  ask_reason_here -> feel_sick : a = patient

  need_medicine --> status_inquery
  need_medicine --> why_need : a = doctor
  greeting --> status_inquery
  greeting --> greeting
  greeting --> why_need : a = doctor
  greeting --> ask_reason_here : a = doctor
}
#+END_SRC

#+CAPTION: Symbol graph of connections grouped in file
#+LABEL: fig:dep:filedconns
#+ATTR_LATEX: :width 0.7\textwidth
#+RESULTS[95cead6c9a6fb358accf6686cac4a2b62f2d9111]: fig:dep:filedconns
[[file:img/uml/dep:filedconns.png]]

*** Scenes
\newlyCleared
In the S-AIML extension, scenes were used to enable and disable certain patterns.
Unlike the topic mechanism of AIML which just gives preference,
something from another scene wouldn't be used at all.
This is makes it easier to write dialogues,
because we don't have to worry about patterns from other scenes,
so we can use more generalized patterns in our particular scene.

\toReview
Although scenes aren't necessary to implement the theory presented in
section [[BDI and Jung]],
it is necessary for eventual social practice support.
It also makes this representation much more modular.
The part were scenes are actively used is in section [[db package]],
patterns are grouped based upon scene in the =PatternDatabase=.

\newlyCleared
The way we represent scenes is rather simple.
We use directories as scenes, all the symbols within a directory are in that
scene.
Connections are implicitly assumed to be between symbols in the same scene
as where the connection file is in,
unless stated otherwise, which can be seen for example in listing
[[code:yaml-scene-example]].

#+CAPTION: Scene example in connections
#+NAME: code:yaml-scene-example
#+BEGIN_SRC yaml
from:
 - status
to:
 - symbol: ask_reason_here
   scene: information_gathering
   restricted_to: doctor
   values:
     - Impatient
 - symbol: good
   restricted_to: doctor
   values:
     - Polite
     - Happy
#+END_SRC

\newlyCleared
In listing [[code:yaml-scene-example]] we can see two connections being modelled,
from the =status= symbol to =ask_reason_here= symbol that transitions to a new
scene, and from the =status= symbol to the =good= symbol that stays in the same
scene.

\newlyCleared
We break away from the idea of S-AIML that scenes are linear.
We believe that scenes are a weakly connected cyclic graphs.
Note that by cyclic, we mean there can be cycles, but there don't have to be.
So we can go back to previous visited scenes for example.
Its weakly connected because it wouldn't make much sense to model scenes
that can't get to other scenes trough connections.
Although there is nothing preventing one from doing so,
the common sense reasoning is:
Why would you model a scene that is inaccessible from the rest of your model?

*** That tags
<<That tags>>
\newlyCleared
The that tags in AIML have a rather unfortunate name.
They require the bot to have said something before the current
pattern can be used.
Therefore in our YAML semantics, they are an additional restriction on connections.
They appear in listing [[code:aiml-that-tag]] as an example.

\toReview
Although supporting this feature isn't necessary to implement the theory
presented in section [[BDI and Jung]],
they do allow much more fine grained control over the scenario.
They are described more extensively in section [[Before and templates]].

#+CAPTION: That tags example.
#+NAME: code:aiml-that-tag
#+BEGIN_SRC xml
  <category>
      <that>Why is doctor Aarts not here I am one of his patients.</that>
      <pattern>
          surprised you're doctor
      </pattern>
      <template>
          <insert packageName="scenarios.large.global" typeName="SentenceSpoken" />
          <insert packageName="scenarios.large.prehistory" typeName="BadAndLateExplanation" />
          I did expect him to be here, yes.
      </template>
  </category>
#+END_SRC

\newlyCleared
That tags act as an extra filter upon the category.
Before this category becomes active, the bot first has to have uttered the
pattern in the that tags.
In the new representation we can model such a thing too.
To model that tags we add an extra optional field to the =RawConnections= called
before, with two required fields, `who' and `said', who indicates the actor
and said indicates what was said.
An example can be seen in listing [[code:yaml-before-field]].

#+CAPTION: That tags as before fields in YAML
#+NAME: code:yaml-before-field
#+BEGIN_SRC yaml
  before:
     who: patient
     said: "why_is_docter"
  from:
   - "surprised_your_doctor"
  to:
   - symbol: "expect_him_be_here"
     restricted_to: patient   
#+END_SRC

\newlyCleared
Adding the who field was necessary since we no longer model just the
utterances of the bot,
we needed to expend it by adding the actor who uttered the utterance.
We also needed to think about *when* it was uttered, because alternation
isn't a guarantee in conversation (discussed in section [[Scheduling dialogue]]).
What is done now, is to filter out the utterances from the person who is not
the who in the before tag, and then take the latest utterance from them.

\newlyCleared
To surpass the AIML that tags,
we can extend this mechanism by making the =RawBefore= type self
recursive with an optional field before of its own type.
This is best illustrated with an example which can be seen in listing
[[code:yaml-before-recurion]].

#+CAPTION: Before recursion
#+NAME: code:yaml-before-recurion
#+BEGIN_SRC yaml
  before:
     who: patient
     said: "why_is_docter"
     before:
        who: doctor
        said: "im_the_doctor"
  from:
   - "surprised_your_doctor"
  to:
   - symbol: "expect_him_be_here"
     restricted_to: patient   
#+END_SRC

\newlyCleared
The default value of the before field will be None. Which just means no
additional restrictions.
In this example making such an explicit definition won't be very constructive.
However since we need an identity (no-op) before value anyway for the default
restriction. Making a recursive definition isn't that big of an extension.

\newlyCleared
The AIML tag specification never defined when a that tag match would be
active cite:aimlspec_that. However it can be derived implicitly from the
reference cite:aimleference_that that it should always be on the previous
utterance.
We could add options for when an utterance was made, for example just now or
any previous utterance. However in the interest of time we won't do this.

\FloatBarrier

** Templates
<<Star tags>>
\toReview
In AIML, star tags are template focused.
They capture the content of a wildcard
at a particular index and allow them to occur in the bots reply.
An example can be seen in listing [[code:aiml-star-tag]].
This is a simple trick to make the bot look quite clever,
and since in AIML patterns and replies are hand in hand, doing this is easy.
Our system has no such luxury.

\toReview
To implement these in our new scheme we first need to analyze what star tags are.
Then we need to figure out how we can implement this in our matching system,
and finally we need to add a template method to our YAML representation.
The data structures involved are discussed in section [[Before and templates]].
What is discussed in this section is the behavior and syntax.

#+CAPTION: Star tag usage example.
#+NAME: code:aiml-star-tag
#+BEGIN_SRC xml
<category>
    <pattern>
        name is *
    </pattern>
    <template>
        Okay, <star index="1" />. Can we get started?
    </template>
</category>
#+END_SRC

*** AIML stars
\newlyCleared
The AIML standard specifies cite:aimlspec stars as a one based index scheme.
Wildcards are defined as any string in $L(N)$ where $L(N)$ is all normal words.
This would imply that it would not include spaces or other special symbols.
Since this definition is rather vague we did some experimentation on the example
from listing [[code:aiml-star-tag]].
We tried to introduce ourselves to the bot over and over again with
different names as can be seen in table [[tab:alice-normal-words]].

#+CAPTION: Attempts at what would pass for 'normal' words according to ALICE.
#+NAME: tab:alice-normal-words
| Inserted              | What the bot accepted |
|-----------------------+-----------------------|
| jap34! gee!@          | jap34                 |
| jap gee23             | jap gee23             |
| jap_23_flap ddd dfadf | jap_23_flap ddd dfadf |
| blah *. blah          | blah *                |
| blah * ahah           | blah * ahah           |

\newlyCleared
So quite arbitrarily some characters are accepted while others aren't,
ALICE happily accepts an underscore but an exclamation mark is to much.
There are several ways to improve this system.
Such as trying to add context to what the star should be.
In our example case we wanted to match on names,
so we know that numbers ought not to be allowed,
or at least that it would be highly unusual.
Social practice and norms could help with this.

\newlyCleared
We already improved on the star matching system by using regular expressions
cite:thompson1968programming,
which would allow scenario writers to be much more precise in what they want
to match.
However we want to also be able to store what is matched and access it later.
The java regex API already provides a method of extracting information from
wildcard trough something called groups cite:regexgroups.
An example of an regular expression that extracts data can be seen in listing
[[code:regex:extract]].
So the problem is no longer one of extraction,
but just about organizing that what has been matched,
and putting it in a template.

#+CAPTION: Extracting data with a regular expression.
#+NAME: code:regex:extract
#+BEGIN_SRC yaml
literal:
    - "My name is paul" # what the bot would say if symbol used
regexes:
    - "My name is (?<name>.*)" # the matching mechanism, store wildcard into name field
#+END_SRC


*** Templates in symbols
\newlyCleared
To insert data into a symbol we need a templating mechanism.
So the first thing we did was finding template libraries in Java.
Three options came up:
Velocity cite:velocity, FreeMarker cite:freemarker
and StringTemplate cite:stringtemplate.
Because StringTemplate enforces strict model view separation,
and is therefore much more maintainable and easier to understand than FreeMarker
template engines cite:parr2004enforcing, we chose to use StringTemplate.

\newlyCleared
Using that engine we can define a naive way of writing a symbol as can be
seen in listing [[code:naive-template-symbol]].

#+CAPTION: Naive approach
#+NAME: code:naive-template-symbol
#+BEGIN_SRC yaml
literal: "Hello, my name is <actor.name>"
#+END_SRC

\toReview
In listing there [[code:naive-template-symbol]] is a problem however,
is it always the case that the current actor should be used if we use a query
like "<actor.name>"?
No because we can say something like: "Hey <actor.name>, can I borrow your pen?".
Therefore it is perhaps unwise to try and select such things at the symbol level.
Because a lot of context information is not available yet.
The best we can do is give them a name and leave it at that,
as can be seen in listing [[code:template-symbol-context]].
This won't add any /real/ restrictions on the inserted words.
Its just a hole that can be filled up by an arbitrary string.

#+CAPTION: Context unaware approach
#+NAME: code:template-symbol-context
#+BEGIN_SRC yaml
literal: "Hello, my name is <name>"
--- # another file
literal: "Can I borrow a <tool>"
#+END_SRC

*** Tying matches to templates
\toReview
Now we know how to extract data from a regular expression,
and we know how to insert data into a symbol.
However, we need to observe the key difference between AIML and the YAML
implementation.
Pattern and template tags are expended into their own symbols, as discussed
in section [[Mapping AIML]]. 
Therefore we need to device a system that can match in one symbol and
insert the matched data in another.

\toReview
As said before the implicit relationship between patterns and template tags in
AIML is made explicit in this implementation trough connections.
Its only natural to demand to solve this problem with help of connections.

\newlyCleared
So then the question becomes how do we fill in these templates?
The issue we had with trying to fill these in the symbols was the lack of
context.
Context is mainly provided by connections, if we know who is saying
"Hello, my name is <name>", we know what to fill in for name.
In this system context is provided by connections.
An example of how to do this is given in listing [[code:template-connection-fill]],
where the name is filled by using a previous utterance.
We use the match label to identify which matched item needs to be extracted.

#+CAPTION: Connection syntax for filling templates
#+NAME: code:template-connection-fill
#+BEGIN_SRC yaml
from:
- my_name_is_x
to:
- symbol: hello_x
  restricted_to: patient
  utterances:
    name: # the template name
      actor: doctor
      symbol: my_name_is_x
      scene: introduction
      match: name # we can match on named groups
#+END_SRC

\toReview
There are several important things to note about this implementation.
First of all its a lot more flexible than AIML stars,
since information can be retrieved from any previously uttered utterance,
if a connection has a query that isn't satisfied, it is not available.
Another advantage over AIML is that regular expressions allow much more precise
input sanitation than wildcards.
This could enforce input that is only numeric for example.
Which in turn can be used within drools as a query.
Finally we preform checks to make sure that symbols with template names
only have connections leading up to them that satisfy the template names.

\toReview
A feature that is missing is retrieving drool facts from the knowledge base
and inserting them into the template.
However one can workaround this limitation by writing drools for this,
similarly to low level replies.
A =MatchedQueryDB= can be constructed manually to fill with drool facts.

** Automatic AIML to YAML
\newlyCleared
AIML is a standard cite:aimlspec.
Note that the spec says: "AIML shall be compatible with XML.",
and XML is also a standard cite:xmlspec.
YAML happens to also be a standard format cite:yamlspec.
although its not a markup language, unlike XML and AIML,
but rather a data format cite:yamlvsxml.
The advantage of being "just a data format" is
that the syntax can become a lot more terse, while maintaining readability.
With all these standards, its relatively easy to convert between them,
because libraries exist for parsing them.

*** Legacy AIML
\newlyCleared
An introduction of a new format is nice, but when this is done,
all the work in the old format could become obsolete.
This is obviously not desirable.
There are several ways of circumventing this.
First of all, one could add support of the legacy format to the code base.
The second method is creating a script that will help along the way with
conversion.

\newlyCleared
We chose the second method because the first method will be much harder,
as it will re-introduce the problems we had with AIML in the first place.
The second method provides the user an opportunity to make their AIML script
comply to the new method,
whilst also reducing the effort it takes.

\newlyCleared
To make the conversion we need to point out some structural observations about
differences between AIML and YAML.
Firstly AIML works strictly from the perspective of the bot.
There is no deliberation about what the user is thinking.
Therefore we can't model what we expect the doctor to say after a patient
uttered something in the test scenario because this information isn't encoded.
You may argue that the mechanism which could be used for this are the /that/ tags.
But they are just an additional restriction on the pattern matching:
If user uttered pattern $A$ *and* he said that pattern $B$ before,
we can say template $C$.
Alternatively you count the injection of types (in S-AIML),
but this isn't a formal encoding in AIML itself,
but rather a way of informing drools what's going on.

*** Mapping AIML
<<Mapping AIML>>
\newlyCleared
What we can do is extract the patterns, and their respective literals into
symbols. For example we have the following category in listing [[code:aiml-mapping]].
In this example there are in terms of YAML two symbols and a connection.
The first symbol is pattern tag,
the second symbol is the template tag excluding the insertions,
and the connection is from the pattern to the template which is restricted to
the patient.
So from this example we can define the mapping result in listing [[code:yaml-mapped]],
with its respective file names in comments above.

#+CAPTION: AIML mapping example
#+NAME: code:aiml-mapping
#+BEGIN_SRC xml
  <category>
      <pattern>
          How long * pain
      </pattern>
      <template>
          <insert packageName="scenarios.large.global" typeName="SentenceSpoken" />
          <insert packageName="scenarios.large.timelapse" typeName="DurationPain" />
          For a while now
      </template>
  </category>
#+END_SRC

#+CAPTION: Listing [[code:aiml-mapping]] expressed in YAML, with the filenames in comments.
#+NAME: code:yaml-mapped
#+BEGIN_SRC yaml
  # for_a_while_now.yml
  literal: "For a while now"
  ---
  # how_long_*_pain.yml
  literal: "How long * pain"
  ---
  # _connections.yml
  from:
   - "for_a_while_now"
  to:
   - symbol: "how_long_*_pain"
     restricted_to: patient   
#+END_SRC

\toReview
A lot of category elements simply mean to add a pattern to a symbol,
for example listing [[code:aiml-srai-mapping]].
What we can do with the SRAI tags, if they exist, is simply checking if the
symbol exists and then add the pattern to that symbol.
If the symbol does not exists yet, we create it anyway,
since the content of a SRAI tag is the pattern itself,
we just add both the pattern and content to the pattern list.

#+CAPTION: SRAI tag that adds a pattern to a symbol
#+NAME: code:aiml-srai-mapping
#+BEGIN_SRC xml
  <category>
      <pattern>
          How long * pain *
      </pattern>
      <template>
          <srai>How long * pain</srai>
      </template>
  </category>

#+END_SRC

*** Type insertion
<<Caviats>>
\newlyCleared
After the conversion is finished, the bot will mostly work, with the added bonus
that the dialogue will be more readable.
However there are some caveats, especially in the previously introduced variant
called of AIML called S-AIML.

\newlyCleared
In S-AIML types are injected to track progress of the scenario.
In contrast to the current scheme where the entire user utterance gets
inserted and its up to drools to make a symbolic understanding from it.
To work around the issue of inserting types we actually have to generate
drools in case of a particular symbol inserted.
For this we can just use the low level reply mechanism, but rather than
replying we insert the specified type.
An example of this can be seen in listing [[code:drool:generated]].

#+CAPTION: Generated drools from listing [[code:aiml-mapping]] insert tags
#+NAME: code:drool:generated
#+BEGIN_SRC java
rule "insert types when symbol how_long_pain was uttered"
when
	$pre:PreProcessed($symbol:utterance.what, $symbol.name == "timelapse/how_long_pain")
then
	log.info(drools.getRule().getName());
	
	scenarios.large.global.SentenceSpoken obj1 = new scenarios.large.global.SentenceSpoken();
	insert(obj1);
	
	scenarios.large.timelapse.DurationPain obj2 = new scenarios.large.timelapse.DurationPain();
	insert(obj2);
	
end
#+END_SRC

\toReview
Something which complicates this is that attributes can be set trough JSON
within the insert tags.
This can be handled inside the drools rules because the inserted types
always have setters.
So there could be java code generated for that.
Although we haven't done this in the actual implementation since this feature
didn't seemed to be used a lot.

*** Proof of concept
<<Conversion script>>
\newlyCleared
To show that it is indeed easy to write a conversion script,
with above restrictions kept in mind we made a proof of concept.
This conversion script is located in the conversion folder from the root project
of the git project.
It is expected to be executed from command line and provides several command
line arguments that are documented in the script itself.

\newlyCleared
The usage of the script can be shown by passing the help parameter to it.
As can be seen in listing [[code:sh-conversion-script-help]].
There are some features missing from this script however.
The help message will display which.

#+CAPTION: Print conversion script usage
#+NAME: code:sh-conversion-script-help
#+BEGIN_SRC sh
  python main.py --help
#+END_SRC

\clearpage
* Implementation
\todo[inline]{The level of detail is around the one we did with the demonstration: Go trough one connection and show how the things are used, such as personality before and template.}
\todo[inline]{Remember the implementation is in support of thesis, not the other way around, so programming stuff is irrelevant}
\todo[inline]{I think in here we can also discuss why we did or didn't use logic?}

\toReview
In this chapter the implementation of the bot is discussed.
Herein we will discuss some of the bigger challenges of implementing the bot.
To do this we will setup a small test scenario in YAML.
With this we will walk trough the steps that are interesting or were
particularly challenging, in both loading and execution.
Finally we will discuss the tests that show we indeed succeeded.

\toReview
When one starts working on an existing software project the first
obstacle faced is building/executing the project.
This is however not discussed in this chapter,
but done in detail in the appendix [[building]].

** Demo
\todo[inline]{Delete this subsection}
\todo[inline]{This is just here to remind myself waht I had shown in the demo (to remember the level of detail)}
1. Start server
2. zet persoonlijkheid die in believes.yml op INTJ
3. Build
4. Open test gedeelte van thesis
5. Open Unity client en ga INTJ test af
6. Stel believes.yml in op ENFP
7. Rebuild
8. Ga ENFP test af met de python client.
9. zelfde voor ISTP?
*** Convert
1. Verwijder salve/anamnesi/large & small
2. Voer convert script uit
3. Open introduction.aiml & introduction converted folder
   1. symbols: patronen of templates
   2. verschil in verbosity: connections
   3. Zoek 'I am an intern in gegenereerde' drools
*** second
4. Start mysqld =sudo systemctl start mysqld=
5. Start wildfly
6. Open believes.yml, introduction/connections.yaml, en ranger in introduction
*** Templates
+ Vertel over template matching met regexes, en insertion
+ rebuild
+ open python client
+ zeg "My name is jappie"
+ laat zien resultaat verwacht naar yaml
+ zeg "How are you?"
+ vertel over queries in yaml
*** Before clauses
+ nu over before clauses
+ zeg "Hello"
  + laat zien dat nu de before clause gebruikt is
  + vertel ook over labels in templates
*** scene transitions
+ Transition scene: "How can I help you?"
+ Zeg nog eens "Hello"
** Setting up the scenario
\todo[inline]{I don't know if we should start with yaml here, perhaps we should just discuss how loading works and move on let let all yaml discusion be contained in the replacing AIML chapter, maybe the only thing to do here is discussing believes because I didn't treat that there}
\toReview
To indicate how to use the bot, we will setup a small scenario.
The first thing that needs to happen is setting up the =believes.yml=
which can be seen in listing [[code:sc-believes.yml]].
Actually loading the believes inside a YAML file presents us with a first
design conflict.
Should believes be loaded from YAML or inside the drools?
There is a constant pull between these two possibilities.
Drools is much more flexible, however YAML is usually less verbose.
Clearly we chose to use YAML, but was this the right choice?
The issue is that we now indicate that this structure is a standard part of the
bot, but its only part of the personality component.
The idea of doing it this way was to provide some kind of scenario descriptor
file, drools however may have been better suited for that.

#+CAPTION: Believes YAML file
#+NAME: code:sc-believes.yml
#+BEGIN_SRC yaml
goals: []

values:
  enlightening: 12

self: patient

actors:
  - patient
  - doctor

# ENFP
personality: [Ne, Fi, Te, Si]
#+END_SRC

\drafting
Next we require several symbol files that can be seen in listing [[code:sc-symbols.yml]].
Unlike the believes file,
usage of YAML for symbols was a good idea.

#+CAPTION: Symbols YAML file
#+NAME: code:sc-symbols.yml
#+BEGIN_SRC yaml
--- # file; introduction/deep_conversation.yml
literals:
  - I love this conversation <pall>
--- # file; introduction/good.yml
literals:
  - Good
regexes:
  - "good"
--- # file; introduction/greeting.yml
literals:
  - Hello
  - Hi
regexes:
  - "hello (?<name>.*)"
--- # file; introduction/made_a_friend.yml
literals:
  - I just met <friend> today!
  - I just met <friend> he\'s the best!
--- # file; introduction/my_name_is.yml
literals:
  - My name is agnese # just insert the bot name
regexes:
  - "[mM]y name is (?<name>.*)" # capture user name
--- # file; introduction/status.yml
literals:
  - How are you today?
regexes:
  - "[hH]ow are you"
--- # file; introduction/wow_name.yml
literals:
  - is <name> spanish?
  - Wow I've never heard of <name>!
  - Can you eat <name>?
#+END_SRC

\drafting
Finally we need to specify the connections between the symbols.
This basically gives the bot a raw context to work in,
which can be seen in listing [[code:sc-connections.yml]].
\todo{Obviously that listing is way to big}

#+CAPTION: introduction connections YAML file
#+NAME: code:sc-connections.yml
#+BEGIN_SRC yaml
from:
 - greeting
to:
 - symbol: greeting # should this be commented out because of the shortcut?
   values: # no it shouldn't, this forces Fi to d
    - Polite
 - symbol: status
   restricted_to: patient
   values:
    - Polite
    - Enthusiasm
 - symbol: ask_reason_here
   scene: information_gathering
   restricted_to: doctor
 - symbol: my_name_is
---
from:
 - status
to:
 - symbol: ask_reason_here
   scene: information_gathering
   restricted_to: doctor
   values:
     - Impatient
 - symbol: good
   restricted_to: doctor
   values:
     - Polite
     - Happy
 - symbol: made_a_friend
   restricted_to: patient
   utterances:
     friend:
       symbol: my_name_is
       actor: doctor
       match: name
   values:
     - happy
     - enlightening
 - symbol: deep_conversation
   restricted_to: patient
   utterances:
     pall:
       symbol: my_name_is
       actor: doctor
       match: name
   values:
     - happy
     - enlightening
     - polite
   before:
     who: doctor
     said: greeting
---
from:
 - good
to:
 - symbol: ask_reason_here
   scene: information_gathering
   restricted_to: doctor
   values:
     - Concerned
---
from:
 - my_name_is
to:
 - symbol: wow_name
   restricted_to: patient
   values:
     - enlightening
   utterances:
     name:
       symbol: my_name_is
       actor: doctor
       match: name
 # add utterances
---
from:
 - wow_name
to:
 - symbol: status
---
from:
 - made_a_friend
to:
 - symbol: ask_reason_here
   scene: information_gathering
#+END_SRC

\FloatBarrier
** Loading
\drafting
Whereas the original ALICE bot was both an XML parser *and* a chat bot.
We used simply a library for loading.

** Initialization
\toReview
With the basic user faced structure explained we can start explaining how
we load this into memory.
First of all note that we could just use the existing code for loading drools
and setting up the websocket, so we won't treat those subjects here.
Secondly note that we just use a library to deal with YAML,
we will not be writing a parser similarly to what the ALICE bot did for AIML.
So we will briefly discuss how YAML is loaded trough an example.
Then we'll describe how we setup the eventual used data structure for
that makes reasoning easy to do.

*** Loading YAML
\todo[inline]{Discuss how yaml is loaded into a raw format, and how raw format gets converted to final format}

*** Symbols
\toReview
We begin by parsing all symbol files. The reason for this is that the symbols
don't have any dependencies of themselves. 
From these files we create a symbol database.
This is a temporary structure that uses a concatination of scene and the
filename to point to the created symbol.
A symbol no longer contains patterns.

**** Patterns
\toReview
From the patterns we create another structure called the pattern database.
This structure has as key a scene and as value a list of pattern symbol pairs.
The patterns are regexes, the are generated from the various enteries in
the yaml files from the symbols. Not only the regex field is used, but also
the literal field, since a literal is just a very precise regex.

\toReview
With this structure it becomes really easy to figure out a user utterance.
We just take the active scene, get back a list of pattern symbol, go trough
each pattern to see if its a match with the user utterance
(potentially asyncrhonusly), and insert all matched symbols.

\toReview
If we don't have a match for the active scene we have some choices.
Initially we behaved like the AIML topic tags,
only if there was no match in the current active scene we'd search the rest.
But this isn't how S-AIML scenes behaved, S-AIML disable all other patterns
and only use the onces from the active scene.
It expected types to be inserted to deal with scene changing trough drools.
This is very involved because it requires the user to write drools for each
scene change.

\toReview
We can therefore do better,
if a pattern isn't matched on the current active scene,
we can use the scene attribute described in the connection yaml file 
to try and match patterns on neighbouring scenes.
If they don't match we don't have a scene transition and default behavior
can ensue.

*** Connection database
\toReview
Next are the connections,
these are explicitly done after symbol loading,
because connections consist of symbols. 
From this we want to make a database that has symbols as keys, and a set of
connections as value.
The connection in themselves are just symbols, but with addition to the symbol
some meta data such as perlocutionary values and the actor to which this
connection is restricted.

\toReview
In the Initial design the keys were strings, however,
using symbols directly as keys ensures trough type checking that the right
lookups are done.
It is also faster, in a micro optimizing way.
The hashcodes can be cached and the equal check can often be done by
identity,
because practically all symbols will be used from the initial symbol database.

**** Scenes
\toReview
Once the connection database is constructed we can start working on a scene
structure.
This is to support scene transitions from the active scenes,
to neighbouring scenes.
The initial idea was to make a simple scene graph that would allow scenes to
look into neighbouring scenes if they couldn't match an utterance string with
their own patterns.
However we can do a better pre-processed variant.
What we really want is another pattern database,
but this does for the scene key not contain the patterns of the current scene,
instead it contains the patterns of symbols it can go to from neighbouring
scenes.

\toReview
If a match is found in this database we can start thinking about making a
scene transition.
We can transition as soon as this happens,
however this has problems because multiple mathces can be found
(from different scenes).
Therefore we just let the bot decide what to do with the match and only
transition if a reply is made from within a new scene.

** Processing
*** Drools

**** Scheduling in Dialogue
<<Scheduling dialogue>>
\toReview
The naive approach of looking at a dialogue is a round robin scheduling process.
Where someone utters a single sentence,
and then a single reply is made by the conversaton partner.
Even in our simple case study (section [[Personality influence case study]])
we discovered that a dialogue does not conform to a round robin based scheduling
process.
Sometimes the actors would conform,
but at other times one of the actors would say multiple utterances.

\toReview
There are several not so elegant ways to implement this without performing
to much chagnes to the code base.
First, you could just modify the case study to not do this and let be a
'coincedental' round robin process.
Obiously this would 'work',
but modifying once's predetermined tests is something which ought to be avoided
unless there is a good reason to do so.
Second of all you could just create a symbol with a huge,
multisentence literal reply.
This isn't really how symbols are meant to be used, but you could do that.

\toReview
But then our minds started to wonder,
how difficult would it be to emulate this?
To just make the bot properly utter multiple symbols.
What if we just re-insert every reply by the bot into the drool facts,
and let the personality decide how to reply to itself.
To prevent an infinite loop we would preffer alteration by default in the
irrational functions.

\toReview
So after this change we could model ENFP correctly, 
but we found another use in this new implementation.
Since all rational functions now shared a behavrior:
Preffer alteration of actors between levels default,
we could make some more general unit tests.

*** Personality

** Actors
\todo[inline]{Find a place for this section which shouldn't be a section}
\drafting
To make sure certain strange situations don't occur, such as the patient asking
the doctor if the doctor is sick, we added actor based restrictions on
connections.
Currently however this implementation is rather limited, it only allows for an
"any" actor, which basically means any actor can say this, or a specific actor.
This could be extended with some kind of role system,
where more fine grained groups of restrictions can be specified.
For example both the patient and family member should be able to ask the doctor
what's wrong with the patient, however the doctor not.

** Testing
\toReview
To verify our implementation's correctness we use several testing methodologies.
First at the lowest level we use the so called unit tests to verify individual
Jungian functions work as they were described in the thesis.
We test these individually by creating specific believes and a dialogue tree for
input, then we check the output against an expected believe base and dialogue
tree.

\toReview
Integration tests are done by combining parts of the application with each
other and seeing if the input and output is acceptable.
For example we would create a full personality and then see if it replies in the
way we want. By firing up the drools engine.

\toReview
On the highest level we have the so called validation tests.
With these we check if the program we created complies to what we described in
the theory.
To do this a scenario is implemented and the tests are done upon it.

*** Unit tests
\toReview
Unit tests (code that tests code each build)
provide extra guarantees upon behavior where type can't do this.
In essence unit tests are an extension of the type checker.

\toReview
Static typing provides better correctness guarantees than just unit tests cite:unitvsstatic.
It follows that if you have a stronger type system you need fewer unit tests,
Java however has a rather basic type system cite:javavsscala,javavshaskell.
Therefore we implemented over 70 unit tests in the code.
These are executed each build.
A framework called JUnit cite:junit is used to integrate with maven and execute
the tests on compile time.
It also has a handy assertion API.

\toReview
The unit tests don't cover every aspect of the application but are
mainly focused upon the Jungian Functions and their data structures.
For example the Te tests can be seen in listing [[code:java-unit-te]].

#+CAPTION: Te test example
#+NAME: code:java-unit-te
#+BEGIN_SRC java
  public class TeTest extends AJungFuncTest {
      @Override
      public JungianFunction getTestTarget() {
          return JungianFunction.Te;
      }
      @Test
      public void no_goals_look_for_ones_that_change_scene(){
          Believes inputBelieves = believes.setGoals(Collections.emptySet());
          builder.addOption(MockBelievesFactory.hellos);
          Utterance expected = builder.addOption(MockBelievesFactory.needmedicine);
          builder.addOption(MockBelievesFactory.whyhere);
          DialogueTree inputTree = builder.getCurrent();

          JungFuncArgs result = apply(inputBelieves, inputTree);

          believes = inputBelieves;
          believesShouldRemainTheSame(result.believes);

          Assert.assertEquals("the scene changing dialogue is preffered",
              Optional.of(expected),
              result.tree.getPrefferedUtterance()
          );
      }
  }

#+END_SRC

\toReview
So in getTestTarget we define which function is under test,
which is handled by the parent class.
Then as can be seen by its annotation, the method
`no_goals_look_for_ones_that_change_scene` defines a test.

\toReview
Tests generally follow a similar pattern, first an expectation is build,
then the input is created, the function to test is called, trough the `apply`
method in this case, and finally the expectation is asserted.
If the expectation isn't upheld an error will be shown at compile time.

\toReview
Testing is one of the few places we use inheritance.
The reason for this is that testing often involves a lot of boilerplate,
and inheritance provides a really cheap way of getting rid of that.

\toReview
We also provide a builder for making the DialogueTree.
This is a mutable wrapper around the dialogue tree, again to reduce boilerplate.
This boilerplate isn't so much a problem in the Jungianfunctions themselves
because they often deal in terms of collections, or just want to add one.
But with tests you want to be specific.

\toReview
$T_e$ only has one test that is specifically aimed at it, but there are also
several shared tests unleased upon it.
For example we know that rationale functions should preffer alteration if all
things are equal.
So we wrote a test for this and just applied the same test on all rationale
functions.

*** Validation test
\toReview
To do validation tests we will try to model the scenario presented as an example
in section [[Personality influence case study]].
To do this we go trough each utterance in the dialogue and see if they have
unique meanings. These we then translate in their respective symbol files.
If we for example look at the conversation between sander and the doctor seen
in table [[tab:sander-conv-doct]], we for example have two greetings. "Hi" and "Hello".
So we put this in a symbol named greeting under the first scene "introduction".
Therefore greeting is a symbol $s^{\text{greeting}}$ of
\[s^{\text{greeting}}=(\{\text{"Hi"}, \text{"Hello"}\}, \text{"introduction"})\]
We continue doing this process for all the utterances in this dialogue and the
next dialogues until all utterances have at least their own unique symbol, 
or share one with similar utterances in meaning.

\toReview
Next up is deciding which of the symbols should be connected with each other
trough connections.
To decide this we again take the case study dialogue found in 
example dialogue.

\toReview
After this we run the test against the scenario. This can be seen in section:
[[Test Results]]. There were some issues with the scenario itself,
however most issues we found were with the functions and their interactions.
The biggest issues we found were:

1. No low level replies.
2. No way of making the bot utter multiple symbols.
3. The height of which functions ought to operate wasn't well thought out.
4. $T_i$ didn't have good default behavior

\clearpage
* In conclusion
\drafting
We need to explicitly say here that Mapping function to attitudes to a
process (3.4) is valid for the test use cases shown in [[Test Results]].
Although the validity is in no way proven
(we just have /a/ instance that is correct, which is different from
saying that all instances are correct)

\drafting
I think another major conclusion is that we created a viable language processing
bot.
That just deals with language, but does not specify anything about responses.
A comment in the beginning of my thesis was that AIML was used to
'just deal with language', but this wasn't true,
AIML defined the entire flow of the application.
Now there basically is no more 'fixed' way of operating because drools decide
that.
It was claimed that drools were the center of the application,
but they weren't, this thesis showed a method of making it the center of the
application.

\todo[inline]{Discussion, comparison}
** Future work
*** Give the bot some semantic understanding
\drafting 
A possible alterantive is using cite:moschitti2004study, to parse the semantics
of a sentence. Then a graph can be used to determine how to predicates
corrolate logically with the arguments being just fill in.

\drafting
Something such as cite:mccord1990slot could also be used to get a more deeper 
"understanding" of the user message. However introducing something like that
would require a much more advanced reasoning process. No longer are we
dealing with sentences but instead we use words.
Symbols then would need to indicate how many arguments they need to be completed.

**** Variables in literals
\todo[inline]{This is partly implemented already but we can't retrieve information from drools, perhaps that should be implemented, although drools can get symbols and insert stuff themselves}
\toReview
A first step would be to add variables to the symbols. Such as a name of an
actor. I guess these things could be extracted from the social practice
which is still defined kindoff implicitly.
We could use a framework like this: http://www.stringtemplate.org/ to substitute
variables with their proper names. (ANTLR seems to strict however).

\toReview
If this is done in the literals however, care should be taken, since these
are also expended into regexes,
therefore all possible inputs of the literals should be available at the time
when the patterndatabase is build.

\toReview
There are 3 ways to create these variables, first of all just collect them
when parsing the symbols and connections,
secondly we insert them from an external source (ie from drools).
Thirdly we use a user defined structure.
For the actors we can collect, but for things such as the healthproblem we need
a user defined structure since drools is kindoff later in the init cycle.

*** More advanced learning
\drafting
Could consider extending the symbol graph dynamically.
For example create a new symbol every time you don't know something,
then ask about it and if the user replies with something you do know connect
them.
Currently there is limited support for "learning". but this is based on knowing
existing symbols, the extension would make symbols dynamically.
This could be done by more advanced language parsing techniques in combination
with an existing knowledge base such as OWL.

*** Multiple conversation partners
<<Multiple conversation partners>>
\drafting
This can be supported by the current architecture technically I think.
Issues that are not addressed for this however are for example timing of replies
and making sure that the bots won't chit chat with each other forever ignoring
the user.
This probably requires that the actor class to be more specific in this case.
Connections could for example be restricted to coalitions of actors rather than just
single actors.
In other words, the yml files shouldn't restrict to any or singular actor,
but rather to groups of actors.

\drafting
Another major issue would be deciding which agent is being talked to by the
user. This could maybe be solved by giving very fine grained restrictions,
but this would become quickly hard to manage with more than 3 agents.
Perhaps a heuristic can be used where the user would have to address agents
by name or have separate buttons to talk to specific agents.

*** Multiple symbols matched
\drafting
better support for if multiple symbols are matched.
Currently just the first one is used. So we truncate the rest.
However if multiple symbols are uttered we could do more advanced heuristics,
such as trying to figure out which one was really meant by using information
theory to select the most precise one.
However this precision also should be encoded or derived somehow
(for example, more words means more information).

*** Social practice support
\drafting
Better social practice support. This is mainly due to a lack of propper
description of the social practice, but it could eventually make the bot very 
salable in use cases.

*** Use GPU for pattern matching

\drafting
It is also entirely possible to make the bot a lot more faster in response time
by using the GPU for regex matching.

*** Graphical scenario editor
*** Alternative matching methods
\drafting
The bot can be easily modified to use alternate matching mechanisms such
as fuzzy matching or probabilty based schemes. \todo{cite such systems}
Because matching already happens in drools,
The modification required to do this correctly is to put a set of symbols per scene,
rather than a set of patternsymbol per scene.

# start appendix, dump al floats and leave some room
\clearpage
\appendix

* References
<<bibliography link>>

bibliographystyle:unsrt
bibliography:refs.bib


\newpage

* List of figures
\listoffigures
\newpage
* List of tables
\listoftables
\newpage
* Symbol overview
<<Symbol overview>>
#+NAME: tab:symbols
#+CAPTION: Symbol table
| Symbol        | Constraints                                                                                | Description                                   |                                          |
|---------------+--------------------------------------------------------------------------------------------+-----------------------------------------------+------------------------------------------|
| $f_a$         |                                                                                            | Function attitudes                            |                                          |
| $\mathcal{B}$ |                                                                                            | Set of all possible believes                  |                                          |
| $t$           |                                                                                            | time                                          |                                          |
| $B_t$         | $B_t \subseteq \mathcal{B}$                                                                | Believe $B$ at time $t$                       |                                          |
| $\Pi$           |                                                                                            | Set of all possible sense information         | [fn:not-used:Not used in implementation] |
| $\pi_t$         | $\pi_t \subseteq \Pi$                                                                          | Perception information $\pi$ at time $t$        | [fn:not-used]                            |
| $\mathcal{D}$ |                                                                                            | Set of all possible actions                   | [fn:not-used]                            |
| $\Delta_t$         | $\Delta_t \subseteq \mathcal{D}$                                                                | Set of actions $\Delta$ executed at time $t$       | [fn:not-used]                            |
| $\sigma$           |                                                                                            | A string                                      |                                          |
| $\mathcal{S}$ |                                                                                            | All encoded symbols                           |                                          |
| $s$           | $s \in \mathcal{S}, s=(\{\sigma\},\sigma)$                                                             | A symbol $s$                                  |                                          |
| $g$           | $\sigma \overset{g}{\to} s$                                                                       | Mapping function from $\sigma$ to $s$              |                                          |
| $g'$          | $s \overset{g'}{\to} \sigma$                                                                      | Mapping function from $s$ to $\sigma$              |                                          |
| $\mathcal{P}$ |                                                                                            | Set of all encoded perlocutionary speech acts |                                          |
| $P$           | $P \subseteq \mathcal{P}$                                                                  | Set of perlocutionary speech acts             |                                          |
| $p$           | $p \in \mathcal{P}$                                                                          | A perlocutionary speech act value            |                                          |
| $\Lambda$           |                                                                                            | Set of all active actors                      |                                          |
| $a$           | $a \in \Lambda$                                                                                    | an actor                                      |                                          |
| $u$           | $u=(P,a,s,t)$                                                                              | Utterance made by $a$ at time $t$             |                                          |
| $D$           | $D=(u,[D])$                                                                                | Dialogue tree                                 |                                          |
| $G$           |                                                                                            | A set of connections                          |                                          |
| $c$           | $\begin{matrix} c=(P,A,s_1,s_2), c \in G \\ s_1, s_2 \in \mathcal{S} \wedge s_1 \neq s_2 \end{matrix}$ | Connection, from one symbol to another        |                                          |
| $i$           |                                                                                            | An integer                                    |                                          |
| $h$           | $p \overset{h}{\to} i$                                                                     | Mapping function from $p$ to $i$              |                                          |
| $\Phi$           |                                                                                            | Set of goals in an agents believe base        |                                          |
| $\phi$           | $\phi \in \Phi, \phi = (a,s)$                                                                         | A single goal, consisting of actor and symbol |                                          |
\newpage
* Building
<<building>>
\cleared
To build this project two hurdles need to be overcome, because the
server uses a starkly different tool chain than the client.
In this appendix we will record how the application can be build.
It may seem trivial but the Java EE world is incredibly complex.
We assume a unix-like operating system with a package manager.

** Client
\cleared
The client is relatively easy too setup since its build with a
monolithic environment.
Therefore you need to have the unity editor.
The only issues with the client were an incomplete merge and a dangling
import that produced build errors.
Also note that there exists a Linux editor,
its just not officially supported (yet) but the latest version can be found [[https://forum.unity3d.com/threads/unity-on-linux-release-notes-and-known-issues.350256/][here.]]
Scroll all the way down for the latest release.

\toReview
Note that the unity client currenlty doesn't support multiple replies from an
agent, because the reply is just inserted in a label, rather than showing a chat
history.
** Server
\cleared
The server runs on Java, therefore the first step is to install Java.
In our case java 8 was used. If your system uses portage you can use the
following command:

#+BEGIN_SRC sh
   # emerge dev-java/oracle-jdk-bin
#+END_SRC

*** Maven
\cleared
Then maven needs to be installed since gradle didn't work ([[Gradle attempt]]):

#+BEGIN_SRC sh
   # emerge dev-java/maven-bin
#+END_SRC

\cleared
Maven is the package manager for java software, it downloads and installs
dependencies (and dependency dependencies) automatically based on xml
configuration.
Do note that to use maven you need to setup a \url{\string~/.m2/settings.xml}
file. I based mine on [[https://maven.apache.org/settings.html][this]] with help of [[https://maven.apache.org/ref/3.3.9/maven-settings/settings.html][this.]]
The active profile should have the name local so that the local profile is used
in the maven project (in this case /local/).
Otherwise the wildfly plugin won't deploy the application.
To test if maven works go to the \url{communicate2/communicate/communicate_server}
folder and execute:

#+BEGIN_SRC sh
 $ mvn compile
#+END_SRC

\cleared
If no errors occur it means the settings are configure right.
However we are not done yet since the resulting binary is not executable.
It is something called a servlet which is an API for server like applications.
To use this binary, we need an application server.
Our maven repository and code base has been configured towards /wildfly/,
so we will use that.

**** Gradle attempt
<<Gradle attempt>>
\cleared
it was attempted to replace maven with gradle, since its a lot less verbose
than maven and easier to setup however doesn't have the picketlink extension
which wildfly requires.
Therefore gradle was abandoned and the maven tool was used instead.

*** Get wildfly
\cleared
Download wildfly from [[http://wildfly.org/downloads/][here]], choose the full web distribution
(if you choose the servlet one you'll run into trouble since it doesn't have the
datasource subsystem, it took about two days to figure that out).
Extract this download somewhere which we will call hence forth $WILDFLY.

*** Setup datasource
\cleared
Now its time to configure the persistent datasource.
The code base can handle sessions,
but to deal with user registration and logins and such we need a database.
There are two methods, mariadb and the in ram storage.
Mariadb is what the online application uses and its probably better to
stick to that for active devlopment, but if you just want to have
a quick look at the server you should use look at section [[inmemorydb]].

*** Mariab setup
<<Mariadb setup>>
\cleared
So first install mariadb (or mysql, they are the same, except mariadb has better
defaults):
#+BEGIN_SRC sh
  # emerge dev-db/mariadb
#+END_SRC
\cleared
Then we need to setup the user and database:
#+BEGIN_SRC sh
    $ mysql -u root
    > create database salve;
    > GRANT ALL PRIVILEGES ON salve.* To 'salve'@'localhost'
    IDENTIFIED BY 'salve';
#+END_SRC

*** Mariadb driver
\cleared
Now we need to make the application server aware of the database.
To do this we first need to install a driver from here [[http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.33/mysql-connector-java-5.1.33.jar][here]],
then copy this jar into
\url{$WILDFLY/modules/system/layers/base/com/mysql/driver/main}
you probably need to make everything after base.
Also create another file called \url{module.xml} with the following content:
#+BEGIN_SRC xml
<module xmlns="urn:jboss:module:1.3" name="com.mysql.driver">
 <resources>
  <resource-root path="mysql-connector-java-5.1.33.jar" />
 </resources>
 <dependencies>
  <module name="javax.api"/>
  <module name="javax.transaction.api"/>
 </dependencies>
</module>
#+END_SRC

*** Wildfly datasource
\cleared
Now the /driver/ is installed we need to configure it as a datasource.
To do this we move to \url{$WILDFLY/bin}.
Then execute the following commands:
#+BEGIN_SRC sh
   $ chmod +x add-user.sh jboss-cli.sh standalone.sh
   $ ./standalone.sh &
   $ ./jboss-cli.sh --connect controller=localhost
   --command="/subsystem=datasources/jdbc-driver=mysql:add(driver-name="\
   "mysql,driver-module-name=com.mysql.driver,driver-class-name="\
   "com.mysql.jdbc.Driver)"
   $ ./add-user.sh
   $ xdg-open localhost:9990
#+END_SRC

\cleared
That last command should open the browser. Click then
Configuration \to subsystems \to datasrouces \to non xa \to add  \to mysql \to next.
The name should be GameDS and the JNDI name should be java:/GameDS,
now click: next \to detect driver \to mysql.
The url should be \url{jdbc:mysql://localhost:3306/salve}, the username and pass
should both be salve, now click next \to finish.

*** Deploying
\cleared
first go to the \url{communicate2/communicate/communicate_server} folder.
Then to deploy the application the following command is used:

#+BEGIN_SRC sh
 $ mvn wildfly:deploy
#+END_SRC

\cleared
If your build gets stuck because it tries to find communicate jars from the 
internet it can help to go to the root folder and execute:

#+BEGIN_SRC sh
 $ mvn compile
#+END_SRC

*** Alternative: in memory db
\cleared
<<inmemorydb>>
Now there is a choice to be made, you can either choose to use maria db
or try and point the appliation to the in ram storage of wildfly.
To do this go to:
\url{communicate2/communicate/communicate_server/src/main/resources/META-INF}
and then replace everything with:
#+BEGIN_SRC xml
  <?xml version="1.0" encoding="UTF-8"?>
  <persistence version="2.1"
  xmlns="http://xmlns.jcp.org/xml/ns/persistence"
  xmlns:xsi="http://www.w3.org/2001/xmlschema-instance"
  xsi:schemalocation=
  "http://xmlns.jcp.org/xml/ns/persistence 
http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd"
  >
      <persistence-unit name="salve_persistence_unit"
          transaction-type="JTA">
          <jta-data-source>java:jboss/myDs</jta-data-source>
          <properties>
              <property name="hibernate.dialect"
                        value="org.hibernate.dialect.H2Dialect" />
              <property name="hibernate.max_fetch_depth" value="3" />
              <property name="hibernate.hbm2ddl.auto" value="update" />
              <property name="hibernate.show_sql" value="true" />
          </properties>
      </persistence-unit>
  </persistence>
#+END_SRC

** Ubuntu issues
At some point my laptop crashed and I had to fall back to an ubuntu based
distribution.
Installing mysql came with the gotcha, the default root on mysql is only
accessible from:
#+BEGIN_SRC sh
sudo mysql -u root
#+END_SRC
I thought I could do this as the normal user but it appears this not the case.
Also an online forum said that you had to run
#+BEGIN_SRC sh
sudo mysql_install_db
#+END_SRC
However I think apt handles that for you.

**** utf8 problem
\cleared
I got an error: \\ 
#+BEGIN_SRC sh
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException:
  Specified key was too long; max key length is 767 bytes
#+END_SRC
This is because it uses an utf8 encoding (see [[http://stackoverflow.com/questions/10748155/specified-key-was-too-long-max-key-length-is-767-bytes][this website]]).
To solve this change the tables to use a smaller utf8 instead.
In `/etc/mysql/mariadb.conf.d/50-server.cnf` change the variables to

#+BEGIN_SRC sh
character-set-server  = latin1                                                            
collation-server      = latin1_swedish_ci
#+END_SRC

\cleared
We also need to modify `/etc/mysql/mariadb.conf.d/50-client.cnf`
with:
#+BEGIN_SRC sh
default-character-set = latin1
#+END_SRC

\cleared
After which we do a restart of the mysqld:

#+BEGIN_SRC sh
sudo systemctl restart mysql
#+END_SRC
\cleared
Note: make sure to stop your running wildfly instance, otherwise wildfly will keep it alive

\cleared
Now drop the entire salve database as root, the tables were created with the
wrong charset so we need to just remove them all.
#+BEGIN_SRC sh
mysql -u root -ppassword -e "DROP DATABASE salve;:
#+END_SRC

\cleared
Now recreate the database as was done in section [[Mariadb setup]] (alternativly
logging in as root and pressing arrow up a couple of times should get you the
right commands).

** Notes
\cleared
If you're located in the communicate_server folder, The rebuild everything
command is:
#+BEGIN_SRC sh
rm -R ~/.m2/repository/cnruithof; (cd ../ && mvn clean && mvn install) && mvn wildfly:deploy
#+END_SRC
There is also a shell script "rebuild.sh".
This will re-install the entire project thereby also rebuilding all dependencies.
mvn clean in there for good measure.

\cleared
There is a python client script for quick debugging, therefore its unnecessary
to keep unity running (or use at all).

\newpage
* Test Results
<<Test Results>>
\toReview
All these test follow the scenario which is presented as case study in section
section [[Personality influence case study]].
Each time all tests are executed to prevent regressions, even if they did manage
to pass a test cycle before.

** Initial test
| Commit | 65e704a0f9ec6f5d7052e0de285a79baf420db7d |
| Date   | 2017-03-28 |

\toReview
We believe most of the higher level reasoning is done at this point.
Therefore we attempted this acceptance test to see how well the system would
hold up.

*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |      1 |
| Doctor   | How can I help you?                               |      2 |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\toReview
1. Actually said "How are you?", This is unexpected,
   however since replying with hello is useless to INTJ (it'll just loop back),
   such a reply may actually be better for progress high level process.
   However, this doesn't mean this is right, the intention was to make the hello
   reply be done on a lower level (ie first item said and understanding matches
   hello short-circiuts into replying hello)
2. We use the other scripted response (perhaps it thinks its ENFP),
   this didn't match however,
   turns out this symbol didn't have any regexes,
   after adding the regexes it still didn't match,
   further investigation is required
   into the regexes why they don't match,
   I'm suspecting its either a construction problem (not all are added),
   Or some standard java regex problem.

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            | 1      |
| /Susie/ | /How are you today doctor?/                                        | 1      |
| Doctor  | I'm good, how can I help you?                                      | 2      |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              | 3      |
| /Susie/ | /I got this pain in my back./                                      |        |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             | 4      |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |

\toReview
1. Skipped saying hello (again we miss the shortcircuit rule, same as INTJ)
2. Didn't match with I'm good, probably samme issue as INTJ.
3. Only says the first sentence. This is because we don't keep on popping
   sentences from the dialogue tree if the patient actor still is preferred.
4. We skipped the intermidate sentences (because they didn't pop),
   What we would expect is to get some confusion back after doing this.
   This didn't happen so rules to give confusion when skipping parts of the
   graph should be implemented.

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |      1 |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |      2 |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |      3 |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |        |
| Doctor  | Yes but that will only work temporary.                            |        |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |

\toReview
1. Again no hello
2. Replied with, I'm afraid I need some medicine, I think this is because Ti
   is the first function, and I think the two pass effect isn't implemented
   correctly yet. It just goes deeper now rather than finding the right level
   to modify. Since telling about back pain is a goal and we have a unit test that
   ti prefers goals its almost surely this broken two pass behavior.
3. It says when lifting a heavy object, but I'm pretty sure it just always picks
   the first option because two pass logic is broken.
   So I'll end this test prematurely.

** Second test

| Commit | 1de05450c187c51df780a975cc4f0cec7c69dba1 |
| Date   |                               2017-04-05 |

\toReview
After solving the issues from the initial test, we redid them.

*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |        |
| Doctor   | How can I help you?                               |        |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\cleared
Conversation went according to script.

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            |        |
| /Susie/ | /How are you today doctor?/                                        |      1 |
| Doctor  | I'm good, how can I help you?                                      |      2 |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |        |
| /Susie/ | /I got this pain in my back./                                      |      3 |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |        |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |


\toReview
1. Wasn't uttered, probably because we handle hello as a low level reply.
   Perhaps we should let replies also be passed to themselves so higher level
   functions have a chance to interact?
   (note that alteration is the default, so unless a goal is directly below it
    nothing will be said)
2. We just said 'how can I help you' instead.
3. Goes into "Perhaps I put to much water in the watering can".
   Probably because ENFP is an Fi rather than Fe, Fi is a learning function.
   We should analyze what has been learned at this point.
   It appears also that in either case no values are attached.
   After this point the bot follows the ISTP script.
   This is wrong, Fe is the learning function, Fi uses perlocutionary values.
   So this was easily fixed by modifying the perlocutionary value utility.

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |        |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |        |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |      1 |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |        |
| Doctor  | Yes but that will only work temporary.                            |        |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |


\toReview
1. Says 'when lifting a heavy object'.
   This derails the entire script so the test was stopped.
   The reason for this became apparent after a full tree dump after each function.
   First time the Ti function has nothing to sort, so it does nothing.
   Se generates all available options in the order they came,
   Ni just goes down whatever Se preferred.
   Fe sorts everything twice, but most have no perlocutionary value.
   Then once we come back to Ti, the most obvious choice is of course the first
   option provided by Se, since it was expended by Ni, twice.

\toReview
This is obviously not what we want, since Se is deciding which action is taken
here.
Se could try and get a sane ordering function. However it only has next
available and trying to use previous would lead to a stack overflow.
Ti probably should get a better ordering mechanism.
For example rather than using the DialogueTree for direct options we just
list all available options.
We ended up doing this but note that this breaks the design idea of the
architecture. 

\toReview
To fix this properly we need to reconsider the design at a deeper level,
for example give ti the opportunity somehow in with direction Ne will go down.
A potential better way of solving this would to allow irrational to either
produce on the level of previous irrational,
or if the produced action already exists, go one lower.
But since we're starting to run into time constraints we just leave it at this
'solution'.

** Third test

| Commit | 893f54f6942a65e3c22126949091d096c3691445 |
| Date   |                               2017-04-10 |

\toReview
After solving the issues from the second test we did another run of all tests.
Even though this time we tested quite closely against the issues from the
previous test, going trough the entire battery is necessary to prevent
regressions.


*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |        |
| Doctor   | How can I help you?                               |        |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\cleared
Conversation went according to script.

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            |        |
| /Susie/ | /How are you today doctor?/                                        |        |
| Doctor  | I'm good, how can I help you?                                      |        |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |        |
| /Susie/ | /I got this pain in my back./                                      |        |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |        |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |

\cleared
Conversation went according to script.

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |      1 |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |        |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |        |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |      2 |
| Doctor  | Yes but that will only work temporary.                            |        |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |        |
| /Chris/ | /Yes, I will go then./                                            |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |

\toReview
1. Said hello twice?!
   This was caused by the reinserting part of the shortcut, it used anyactor
   rather than self. Fixing this caused a regression in ENFP which wouldn't
   ask about the doctor's day anymore.
   This was solved by adding an extra value to that connection
   (making it more appealing for Fi).
2. Said "of course" rather than give me some pain killers
   After inspection of the scenario it appears that there is no reason to say
   "can't you give me painkillers" because there weren't any connection
   leading out of it.
   I also made give painkillers a low priority goal, to force ISTP in that
   direction.

** Fourth test

| Commit | 8ea894d0da28addd8067c341e842ca2d91296586 |
| Date   |                               2017-04-10 |

\toReview
Its the same day and we try another round to try and pass this.
Although we modified ISTP slightly, because it had to parse a large amount and
produce a single reply for no obvious reason. Unlike ENFP which for example is
expected to produce multiple replies because its talkative.

*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |        |
| Doctor   | How can I help you?                               |        |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\cleared
Conversation went according to script.

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            |        |
| /Susie/ | /How are you today doctor?/                                        |        |
| Doctor  | I'm good, how can I help you?                                      |        |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |        |
| /Susie/ | /I got this pain in my back./                                      |        |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |        |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |

\cleared
Conversation went according to script. 

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |        |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |        |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |        |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |        |
| Doctor  | Yes but that will only work temporary.                            |        |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |        |
| /Chris/ | /Yes, I will go then./                                            |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |

\toReview
Conversation went according to script. Note however that we split up the
utterances of the doctor compared to the scenario.
This is because there were to many different symbols in the input
(scan and give painkillers), this made the bot reply to both of them.

** Fifth test

| Commit | ae74151591d0c5a20566d8d74283d4c73e9450d2 |
| Date   |                               2017-04-30 |

\toReview
This test was done after completing the major features that were still missing
in comparison with AIML.
We wanted to make sure no regressions had occured meanwhile.

*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |        |
| Doctor   | How can I help you?                               |        |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\cleared
Conversation went according to script

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            |        |
| /Susie/ | /How are you today doctor?/                                        |        |
| Doctor  | I'm good, how can I help you?                                      |        |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |        |
| /Susie/ | /I got this pain in my back./                                      |        |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |        |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |

\cleared
Conversation went according to script

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |        |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |        |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |        |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |        |
| Doctor  | Yes but that will only work temporary.                            |     1  |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |     1  |
| /Chris/ | /Yes, I will go then./                                            |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |

\toReview
1. It didn't match these sentences, apprantly because of the new scene system.
   There was no connection for this transition.

** Sixth test

| Commit | e15409ffc37b837a47a9ceb3c183d67f18c3eb17 |
| Date   |                               2017-04-30 |

\toReview
Because of the ISTP issues in last test we wanted to try and pass this one.

*** INTJ
| Who      | Scripted Utterance                                | Issues |
|----------+---------------------------------------------------+--------|
| Doctor   | Hi                                                |        |
| /Sander/ | /Hello/                                           |        |
| Doctor   | How can I help you?                               |        |
| /Sander/ | /I have a back pain./                             |        |
| Doctor   | When did this first occur?                        |        |
| /Sander/ | /When I lifted a heavy object./                   |        |
| Doctor   | Oh, yes then you need some pain killers for this. |        |
| /Sander/ | /Thank you doctor/                                |        |

\cleared
Conversation went according to script. 

*** ENFP
| Who     | Utterance                                                          | Issues |
|---------+--------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                 |        |
| /Susie/ | /Hello/                                                            |        |
| /Susie/ | /How are you today doctor?/                                        |        |
| Doctor  | I'm good, how can I help you?                                      |        |
| /Susie/ | /I'm afraid I need some medicine/                                  |        |
| Doctor  | Medicine? Why do you need that?                                    |        |
| /Susie/ | /Well, I was watering the plants and all the sudden,/              |        |
| /Susie/ | /I got this pain in my back./                                      |        |
| /Susie/ | /Do you think I'm allergic to plants?/                             |        |
| Doctor  | Haha, no, I think we need to make a scan of your back.             |        |
| Doctor  | Because a watering can is a little to light to get back-pain from. |        |
| /Susie/ | /Of course doctor./                                                |        |
| Doctor  | Can you go to the hospital next Friday at 13:00?                   |        |
| /Susie/ | /Yes, I will go then./                                             |        |

\cleared
Conversation went according to script. 

*** ISTP
| Who     | Utterance                                                         | Issues |
|---------+-------------------------------------------------------------------+--------|
| Doctor  | Hi                                                                |        |
| /Chris/ | /Hello/                                                           |        |
| Doctor  | How can I help?                                                   |        |
| /Chris/ | /I have back pain doctor./                                        |        |
| Doctor  | When did this first occur?                                        |        |
| /Chris/ | /Well I was watering the plants,/                                 |        |
| /Chris/ | /Perhaps I put to much water in the watering can/                 |        |
| Doctor  | Yes, that could be the case.                                      |        |
| Doctor  | However I would like to make a scan of your back just to be sure. |        |
| /Chris/ | /Can't you just give some pain killers to help me?/               |        |
| Doctor  | Yes but that will only work temporary.                            |        |
| Doctor  | So let's plan a scan at the hospital next Friday at 13:00?        |        |
| /Chris/ | /Yes, I will go then./                                            |        |
| Doctor  | I can give you some pain killers meanwhile.                       |        |
| /Chris/ | /Okay, thanks doctor/                                             |        |

\cleared
Conversation went according to script. 


# If we can ever figure out how to remove the name from this:
# https://stackoverflow.com/questions/2709898/change-list-of-listings-text
# * List of listings
# \listlessness

\newpage
* Ideas
:PROPERTIES:
:UNNUMBERED: t
:END:
\todo[inline]{To circumvent typing errors of users we can put input trough a spell checker taking the first correction}
\todo[inline]{How to deal with long inputs? I think sentence splitting was mentioned?}
\todo[inline]{Perhaps we can use argumentation research on top of the graph to figure out more semantics (this statment is attacking that or inquirying this)}
\todo[inline]{Extracting information from meanings isn't very DRY right now, for example saying how is your foot? Could perhaps be splitup into statusInquiry + foot. However I don't know how to do this better right now, perhaps it could be a natural result of dubble matching but we lose the order inforamtion.}
** Rough planning.
*** Report
     In thesis we should also mention the effects of values for functions

*** Make usable for other student
- Document about python scripts and shell scripts (how to use),
  make sure succerrer can take it on easily.
- Another student should be able to work with this,
  +so perhaps we should make a docker image for wildfly mysql etc?+
  What about dumping wildfly and mysql, don't use it anyway..
  Just create a stripped down version that starts the websocket and stops.
- You know, we should just test the idea by letting an other student execute the
  instructions I wrote.
- This probably also includes fixing recursive before, almost certain that doesn't work.
  (maybe include unit tests for that because its recursion which never works as expected)

*** Additional experimentation?
     For this I wanna setup an experiment like thing, where we research what
     the system does etc.
     + Perhaps we should look in what cases the deeper functions have effect (if any)
     + Are slight differences in order relevant? [Ne, Ti] vs [Ti, Ne]

    I'm pretty sure current design doesn't work that great with 'deeper' levels,
    because we assumed irir or riri,
    but now the theory says riir or irri.
    We should analyze this difference I think

** Random thoughts
+ Goals should perhaps be able to be finished?
  + Ti and Te shouldn't preffer this double
+ Manuel made the argument this isn't BDI because we don't use a rule based
  engine. We should find a theoretical source that mentions this and then attack
  it by saying that we use pure functions or something? Alternatively the result
  of each function gets inserted at each step in the rule engine,
  therefore we could argue that aside from the actual processing step it *is*
  BDI.
  The laborious approach would be to refactor all the code to be in drools.
+ Manuel also said that social practices may not fit with this.
  For example when you expect an event in a particular scene,
  but I don't think this isn't true either since at every step of deliberation
  the information gets reinserted.
+ We should note the utterance is used by goals a little weird in that
  percolutionary values aren't used.
  Actually goals need less information, so an idea would be to splitup
  Utterances, but the issue is what to name the splitup (protoutterance?)
+ Perhaps it shouldn't be possible to skip to a certain part of a dialogue
  without punishment?
  Although this is handy for debugging right now.
+ We should add support for start and terminal nodes in the connections.
  So that these siutation can be modelled gracefully.
+ So is our symbol graph something along the lines of connectionism?
  + Nodes are uniform in type, but not in value
  + https://en.wikipedia.org/wiki/Connectionism
+ Our connections are by default not allowed.
  + However once allowed they allow everything possible in that connection,
    unless specified differntly
  + I think talking about what is allowed and not allowed is the core of doing
    a description in logic.

** Tooling stuff
+ Protocol buffers could be used for protocol. Its strongly typed and has both
  C# and Java bindings
+ I think someone should work on better IDE support for drools.
  Intelij kindoff has support, but not for seperated import files, and it
  sometimes gets confused about syntax.
  This would be a time investment, but I think long term it could make
  developing sp's in drools much nicer.
** Security
+ Don't send passwords as plain text over the network.
+ Use SSL.
+ On release, should get a security expert to do an audit. I'm just vaguely
  aware of security issues, but I've seen several already (above for example)
** Protocol
+ Start game and new game could be merged?
+ Why logging towards the client? This seems like a security hole and a
  possible performance bottleneck. (it maybe was Lucas doing debugging)
+ Perhaps a command message should be added, in previous version just certain
  patterns were rigged to do commands (which isn't very pretty). With a
  separate message you could just create another client (or button) to send
  commands

** Thesis
+ Add UML references?
+ Add "architecture quality attribute" references?
+ Could try and figure out which symbol medhi's paper used and then use the same
  ones? I don't know, seems like a little wastefull
+ We could discuss the dilemma of representing values as either class or enum.
  keeping enum for now cause that's what I already have. However it maybecome a
  maintenance problem
** Extra
+ Replace java.util.logger* with slfj
+ Repalce all std.out with propper logging calls
  (not that it matters as long as java.util is used)
+ I get the regular out of memory exception when deploying, this probaly means
  that there is a memory leak which doesn't get cleaned up at redoploy

  

#  LocalWords:  DialogueTree PatternDatabase Immutablity Traum

